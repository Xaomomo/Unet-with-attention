{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Jn5xSoJOj_rW",
        "xlxeXobBj_ri",
        "1YHmUVqd3RQw",
        "NJJrRizneXMn",
        "-hiaYo2eJJHY",
        "yuU1I__9PLzd",
        "vUN1FbBxpx23"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMZa2FFsm/PGg0KjjcFs17l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f3b5e4f2d2c487f8601b403a54e5046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_035ec4218d314a3a816bef43e10adb30",
              "IPY_MODEL_100fa476123b4690914b8f40bc9076dd",
              "IPY_MODEL_5e133eeffbbc499fbb796dc03f9905f1"
            ],
            "layout": "IPY_MODEL_0164e99fbf2f4864b9f59203a20b86d9"
          }
        },
        "035ec4218d314a3a816bef43e10adb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dae9c02ed5d4dfda1807ec70009a140",
            "placeholder": "​",
            "style": "IPY_MODEL_c38e7e4a76ff40e6b0f2f6324b7cbcf8",
            "value": "Dl Completed...: 100%"
          }
        },
        "100fa476123b4690914b8f40bc9076dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6d5b3483fba4dcdafe6e122f058627d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ace08c073959455db39c3d1dff17504f",
            "value": 1
          }
        },
        "5e133eeffbbc499fbb796dc03f9905f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35cdae8482da42d5a0777113bbace3e9",
            "placeholder": "​",
            "style": "IPY_MODEL_efbd2ca747644cea8ec4eb94d4e14473",
            "value": " 2/2 [00:54&lt;00:00, 20.50s/ url]"
          }
        },
        "0164e99fbf2f4864b9f59203a20b86d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dae9c02ed5d4dfda1807ec70009a140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c38e7e4a76ff40e6b0f2f6324b7cbcf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6d5b3483fba4dcdafe6e122f058627d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ace08c073959455db39c3d1dff17504f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35cdae8482da42d5a0777113bbace3e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efbd2ca747644cea8ec4eb94d4e14473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "494e60d5e59c4e13831bc4746ff19f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67e568aaf2c845f88db810f917fbafa9",
              "IPY_MODEL_eaf3dedb159f4efd810db4be06f976ee",
              "IPY_MODEL_d191179789f345499270816f735b8055"
            ],
            "layout": "IPY_MODEL_3f3c3859b12e43c789f50de56423de73"
          }
        },
        "67e568aaf2c845f88db810f917fbafa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aec94e611c246aea347d251e4adb2bf",
            "placeholder": "​",
            "style": "IPY_MODEL_c06d7c37aaa649c88d15e917596c081e",
            "value": "Dl Size...: 100%"
          }
        },
        "eaf3dedb159f4efd810db4be06f976ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb6bace1ffa74a5fb2be91ef0b1b0ae4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba71fe83fb16495e8eb70944edc61af3",
            "value": 1
          }
        },
        "d191179789f345499270816f735b8055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9211dd22da4d598e145a5171220ad1",
            "placeholder": "​",
            "style": "IPY_MODEL_aea7831a9cd24c96883bf0d382e7363b",
            "value": " 773/773 [00:54&lt;00:00, 97.98 MiB/s]"
          }
        },
        "3f3c3859b12e43c789f50de56423de73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aec94e611c246aea347d251e4adb2bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c06d7c37aaa649c88d15e917596c081e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb6bace1ffa74a5fb2be91ef0b1b0ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ba71fe83fb16495e8eb70944edc61af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b9211dd22da4d598e145a5171220ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aea7831a9cd24c96883bf0d382e7363b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5fc13a434ba4e6294b3d80d736078b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_867450358a1a4497968787ba8cd4a218",
              "IPY_MODEL_90135e82928044b2b904f8d1c9bd15ef",
              "IPY_MODEL_2686ec51147948239e1d2b2f3f8e43c7"
            ],
            "layout": "IPY_MODEL_0883b6428e7a48d3b461b3258ed1e0de"
          }
        },
        "867450358a1a4497968787ba8cd4a218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f845de1037cc48009821e1d0868e06eb",
            "placeholder": "​",
            "style": "IPY_MODEL_7962438b4f424dc6b3203db35f633f1a",
            "value": "Extraction completed...: 100%"
          }
        },
        "90135e82928044b2b904f8d1c9bd15ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717752cbb1234ed8a59f9099d1ad6258",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_860d4e0f3fc94909a4bad21736397ebb",
            "value": 1
          }
        },
        "2686ec51147948239e1d2b2f3f8e43c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_527a637a0c88463cb391862efb8a1f4d",
            "placeholder": "​",
            "style": "IPY_MODEL_a970aa415afa4227b3d94c1c8643d350",
            "value": " 18473/18473 [00:55&lt;00:00, 1617.41 file/s]"
          }
        },
        "0883b6428e7a48d3b461b3258ed1e0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f845de1037cc48009821e1d0868e06eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7962438b4f424dc6b3203db35f633f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "717752cbb1234ed8a59f9099d1ad6258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "860d4e0f3fc94909a4bad21736397ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "527a637a0c88463cb391862efb8a1f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a970aa415afa4227b3d94c1c8643d350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60df039b0ad841e1a282fe6e04006e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_564013fb25e441a1a8d70a00b5451e50",
              "IPY_MODEL_ae4af8508026426cb41557a522deb22f",
              "IPY_MODEL_402b2874b35248edae173377aa94e878"
            ],
            "layout": "IPY_MODEL_3429c6fb197a471a915d0e1047fd9bda"
          }
        },
        "564013fb25e441a1a8d70a00b5451e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de17e617afd74c5caa46e2300fcac262",
            "placeholder": "​",
            "style": "IPY_MODEL_c23052b01bb6438d815d2a49e1c57097",
            "value": "Generating splits...: 100%"
          }
        },
        "ae4af8508026426cb41557a522deb22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfc0bd5b555e485284bd2ebed47aa771",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c922358b4c0c4e9abb1178bb5e51f584",
            "value": 2
          }
        },
        "402b2874b35248edae173377aa94e878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8848b47198c74726a044de92302ebda6",
            "placeholder": "​",
            "style": "IPY_MODEL_b87e396fddff4f3aabf51928da46c03c",
            "value": " 2/2 [00:05&lt;00:00,  2.69s/ splits]"
          }
        },
        "3429c6fb197a471a915d0e1047fd9bda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "de17e617afd74c5caa46e2300fcac262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c23052b01bb6438d815d2a49e1c57097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfc0bd5b555e485284bd2ebed47aa771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c922358b4c0c4e9abb1178bb5e51f584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8848b47198c74726a044de92302ebda6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87e396fddff4f3aabf51928da46c03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7068d5e63a074da1bf8c7b4d23f66fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3389572659a246239e82d45e773e5bd7",
              "IPY_MODEL_3516e6604fe3492292bb102020f1eb7f",
              "IPY_MODEL_3eef8027bc354923a5305a49cd4d1cd7"
            ],
            "layout": "IPY_MODEL_986c7c39b237424eb934fa6e0e3492a0"
          }
        },
        "3389572659a246239e82d45e773e5bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_726eece89ddf45259ae823050e870e28",
            "placeholder": "​",
            "style": "IPY_MODEL_e519faaf3a0f4bb98c417edf9ef5efd0",
            "value": "Generating train examples...: "
          }
        },
        "3516e6604fe3492292bb102020f1eb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_824506169efe4e239a350ed38b00d81a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_740039be75d941f790b87c14c17d112e",
            "value": 1
          }
        },
        "3eef8027bc354923a5305a49cd4d1cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f186b63dd2a345468a0436edf4aa3737",
            "placeholder": "​",
            "style": "IPY_MODEL_af98e12c6244474bbd0eb4e5986cf031",
            "value": " 3663/? [00:02&lt;00:00, 2119.59 examples/s]"
          }
        },
        "986c7c39b237424eb934fa6e0e3492a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "726eece89ddf45259ae823050e870e28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e519faaf3a0f4bb98c417edf9ef5efd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "824506169efe4e239a350ed38b00d81a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "740039be75d941f790b87c14c17d112e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f186b63dd2a345468a0436edf4aa3737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af98e12c6244474bbd0eb4e5986cf031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c4ac4f38c6c4183b5fad3fb1676f3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b06aab3fb69144b0ac57fd3c1d05e873",
              "IPY_MODEL_774538489a254fb99e6e94dc728e87f3",
              "IPY_MODEL_e2a1771b657240868f31111309f18ccb"
            ],
            "layout": "IPY_MODEL_efe61c2adf234aad8a7511a6619cbb21"
          }
        },
        "b06aab3fb69144b0ac57fd3c1d05e873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5394c18dd364d638a8fc4e326b38078",
            "placeholder": "​",
            "style": "IPY_MODEL_0a79d4fc7a0d41dd89ebe737b35d79b6",
            "value": "Shuffling /root/tensorflow_datasets/oxford_iiit_pet/3.2.0.incompleteWKTUVQ/oxford_iiit_pet-train.tfrecord*...:  95%"
          }
        },
        "774538489a254fb99e6e94dc728e87f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c4243121c54e3f83b28f473a6bc928",
            "max": 3680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c17b967c57f6411faafd5600abdbc4ae",
            "value": 3680
          }
        },
        "e2a1771b657240868f31111309f18ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2956c78411664700881d65ef50af7202",
            "placeholder": "​",
            "style": "IPY_MODEL_c13749e1f7854204b2d46acc8a543c48",
            "value": " 3490/3680 [00:00&lt;00:00, 5127.19 examples/s]"
          }
        },
        "efe61c2adf234aad8a7511a6619cbb21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b5394c18dd364d638a8fc4e326b38078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a79d4fc7a0d41dd89ebe737b35d79b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96c4243121c54e3f83b28f473a6bc928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c17b967c57f6411faafd5600abdbc4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2956c78411664700881d65ef50af7202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c13749e1f7854204b2d46acc8a543c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74e471e8ebc44afb9c0f96b9676e27fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d72192c159d447190958f031032ffb3",
              "IPY_MODEL_dcaae786cd954d57b812bfdd4dc37809",
              "IPY_MODEL_801919a9354541b2a05a81c6192d1abf"
            ],
            "layout": "IPY_MODEL_edd3df5158304ebd9f9f27fd497ffd30"
          }
        },
        "2d72192c159d447190958f031032ffb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_357b1d86b2f44bdc900220a7a0c51ed3",
            "placeholder": "​",
            "style": "IPY_MODEL_73ccf364e1ea484288463bf9804e8906",
            "value": "Generating test examples...: "
          }
        },
        "dcaae786cd954d57b812bfdd4dc37809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6e61a898e52439a9ff4de087352c11f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e06b1ccd4f714f5cb0417a83ccbeb23b",
            "value": 1
          }
        },
        "801919a9354541b2a05a81c6192d1abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0116b239cb4f4800a01c4541595056a2",
            "placeholder": "​",
            "style": "IPY_MODEL_1df54ed375d14bd0b34c4d5232fbe179",
            "value": " 3552/? [00:01&lt;00:00, 2230.60 examples/s]"
          }
        },
        "edd3df5158304ebd9f9f27fd497ffd30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "357b1d86b2f44bdc900220a7a0c51ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ccf364e1ea484288463bf9804e8906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6e61a898e52439a9ff4de087352c11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e06b1ccd4f714f5cb0417a83ccbeb23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0116b239cb4f4800a01c4541595056a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df54ed375d14bd0b34c4d5232fbe179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8de86a1a1c8044b9984c4d21699a4585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0927b5fa785543c3bc2443a0653ddf28",
              "IPY_MODEL_6934fa51a04746998e420153301738ba",
              "IPY_MODEL_188aedf1330f46d9bf277688c9c2668f"
            ],
            "layout": "IPY_MODEL_4f7235496b484afbb93469d709e6c39d"
          }
        },
        "0927b5fa785543c3bc2443a0653ddf28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56870b15e9874dda8d88c01bfc4c342b",
            "placeholder": "​",
            "style": "IPY_MODEL_f60671fdeca14523abfbed0905c2eb92",
            "value": "Shuffling /root/tensorflow_datasets/oxford_iiit_pet/3.2.0.incompleteWKTUVQ/oxford_iiit_pet-test.tfrecord*...:  88%"
          }
        },
        "6934fa51a04746998e420153301738ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fce2256e3b0a4538915048a3b696b5b3",
            "max": 3669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75a17a1609d7410dbd6214a44df144a7",
            "value": 3669
          }
        },
        "188aedf1330f46d9bf277688c9c2668f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb7251ba87641fb9e6377bdc3575c46",
            "placeholder": "​",
            "style": "IPY_MODEL_7fafeea773d4497594bafb791ebdd339",
            "value": " 3244/3669 [00:00&lt;00:00, 4399.81 examples/s]"
          }
        },
        "4f7235496b484afbb93469d709e6c39d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "56870b15e9874dda8d88c01bfc4c342b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f60671fdeca14523abfbed0905c2eb92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fce2256e3b0a4538915048a3b696b5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a17a1609d7410dbd6214a44df144a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbb7251ba87641fb9e6377bdc3575c46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fafeea773d4497594bafb791ebdd339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xaomomo/Unet-with-attention/blob/main/LSH_attention_Test_versions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1st attempt at LSH Attention using trax in conjunction with TF keras"
      ],
      "metadata": {
        "id": "Jn5xSoJOj_rW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se usara trax para intentar usar el concepto de LSH self attention, ya que esta libreria fue diseñada por google, los que propusieron el transformer en el paper del reformer."
      ],
      "metadata": {
        "id": "ot6nL2KkkSk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"1KJPU1D0ewHmU7Jzl1irq3Gb-JkUqV1VR&confirm=t\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b537fb-19c8-449c-bca8-8a279847f619",
        "id": "iaKNaN5nj_rX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KJPU1D0ewHmU7Jzl1irq3Gb-JkUqV1VR&confirm=t\n",
            "To: /content/input.zip\n",
            "100% 367M/367M [00:01<00:00, 250MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U trax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRqVr6_Hzori",
        "outputId": "89f99337-6738-493e-bcd6-861ef9f37aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.9/637.9 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U git+https://github.com/google/trax@master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHrZ1IGj8p_s",
        "outputId": "fbd55b5a-d03e-4d4e-f534-8cdb40952942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for trax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StCIlbhDj_rY"
      },
      "outputs": [],
      "source": [
        "!unzip -q input.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eEPw-wFj_rY"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QiDejXbj_rY"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "from nibabel.testing import data_path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio as iio\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "import PIL\n",
        "from PIL import Image\n",
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "X=np.zeros((len(glob.glob(src+imag+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  if x!=\"/content/input/train/images/coronacases_009_149.png\":\n",
        "    im=Image.open(x)\n",
        "    X[i,:,:,0]=im.resize((IMG_WIDTH,IMG_HEIGHT),resample=PIL.Image.NEAREST)\n",
        "mas=\"/Amasks/\"\n",
        "Y=np.zeros((len(glob.glob(src+mas+\"*.png\")),IMG_WIDTH,IMG_HEIGHT))\n",
        "for i,x in enumerate(sorted(glob.glob(src+mas+\"*.png\"))):\n",
        "  if x!=\"/content/input/train/Amasks/coronacases_009_149.png\":\n",
        "    im=Image.open(x)\n",
        "    im=np.array(im.resize((IMG_WIDTH,IMG_HEIGHT),resample=PIL.Image.NEAREST))\n",
        "    im[im==85]=1\n",
        "    im[im==170]=2\n",
        "    im[im==255]=3\n",
        "    Y[i,:,:]=im\n",
        "import tensorflow as tf\n",
        "print(Y.shape)\n",
        "print(np.unique(Y))\n",
        "Y=tf.keras.utils.to_categorical(Y)\n",
        "print(Y.shape)\n",
        "print(np.unique(Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45a04f5-1baf-4468-f565-4b6b69325a28",
        "id": "li3I8cSHj_rZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3520, 128, 128)\n",
            "[0. 1. 2. 3.]\n",
            "(3520, 128, 128, 4)\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4cf7ed-fdc4-4f03-e62f-ca2ffab86bb8",
        "id": "E4RQIO4bj_rZ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "002\n",
            "003\n",
            "004\n",
            "005\n",
            "006\n",
            "007\n",
            "008\n",
            "009\n",
            "010\n",
            "10_85902_1\n",
            "10_85902_3\n",
            "14_85914_0\n",
            "27_86410_0\n",
            "29_86490_1\n",
            "29_86491_1\n",
            "36_86526_0\n",
            "40_86625_0\n",
            "4_85506_1\n",
            "7_85703_0\n"
          ]
        }
      ],
      "source": [
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "Siz=0\n",
        "id=0\n",
        "ri=0\n",
        "metadat=[]\n",
        "c=\"001\"\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  if x.find(\"radiopaedia\") == -1:\n",
        "    x=x[x.find(\"_\")+1:]\n",
        "    x=x[:x.find(\"_\")]\n",
        "  else:\n",
        "    x=x[x.find(\"_\")+1:]\n",
        "    x=x[:x.find(\"_\",9)]\n",
        "  if c!=x:\n",
        "    print(x)\n",
        "    metadat.append([id,Siz,ri])\n",
        "    ri=i\n",
        "    c=x\n",
        "    id+=1\n",
        "    Siz=0\n",
        "  Siz+=1\n",
        "metadat.append([id,Siz,ri])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nO3GN-Sj_rZ"
      },
      "source": [
        "##New Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14f3aa7-fb9a-4ea9-c423-36813ba1b65d",
        "id": "EwPOpeJZj_ra"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  4  5  7  8  9 11 12 13 14 15 17 18 19] [ 3  6 10 16]\n",
            "[ 0  1  3  5  6  7  8  9 10 11 12 13 15 16 18 19] [ 2  4 14 17]\n",
            "[ 2  3  4  5  6  8  9 10 11 12 14 15 16 17 18 19] [ 0  1  7 13]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 16 17] [ 9 15 18 19]\n",
            "[ 0  1  2  3  4  6  7  9 10 13 14 15 16 17 18 19] [ 5  8 11 12]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "IDX=[x for x in range(10)]\n",
        "IDY=[x for x in range(10)]\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  print(train_index, val_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imjHDM4cj_ra"
      },
      "outputs": [],
      "source": [
        "for i,x in enumerate(train_index):\n",
        "  size=metadat[x][1]\n",
        "  ri=metadat[x][2]\n",
        "  if i == 0:\n",
        "    X_train=X[ri:ri+size]\n",
        "    Y_train=Y[ri:ri+size]\n",
        "  else:\n",
        "    X_train=np.concatenate((X_train,X[ri:ri+size]),axis=0)\n",
        "    Y_train=np.concatenate((Y_train,Y[ri:ri+size]),axis=0)\n",
        "for i,x in enumerate(val_index):\n",
        "  size=metadat[x][1]\n",
        "  ri=metadat[x][2]\n",
        "  if i == 0:\n",
        "    X_test=X[ri:ri+size]\n",
        "    Y_test=Y[ri:ri+size]\n",
        "  else:\n",
        "    X_test=np.concatenate((X_test,X[ri:ri+size]),axis=0)\n",
        "    Y_test=np.concatenate((Y_test,Y[ri:ri+size]),axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQgFZ8NWj_re"
      },
      "source": [
        "##Patch wise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/usr/local/lib/python3.9/dist-packages/trax/layers/research/efficient_attention.py"
      ],
      "metadata": {
        "id": "xgGMC1AH8v-2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPd9ikJpj_re"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "import trax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoOjBAKlj_rf"
      },
      "outputs": [],
      "source": [
        "def DiceMetric(y_true, y_pred):\n",
        "  smooth=1e-6\n",
        "  gama=2\n",
        "  y_true, y_pred = tf.cast(\n",
        "      y_true, dtype=tf.float32), tf.cast(y_pred, tf.float32)\n",
        "  nominator = 2 * \\\n",
        "      tf.reduce_sum(tf.multiply(y_pred, y_true)) + smooth\n",
        "  denominator = tf.reduce_sum(\n",
        "      y_pred ** gama) + tf.reduce_sum(y_true ** gama) + smooth\n",
        "  result = tf.divide(nominator, denominator)\n",
        "  return result\n",
        "def DiceLoss(y_true, y_pred):\n",
        "      result= 1- DiceMetric(y_true, y_pred)\n",
        "      return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CGRSgtAj_rf"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
        "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "  return iou\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "  union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "  dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
        "  return dice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef_multilabel(y_true, y_pred, smooth=1):\n",
        "    dice=0\n",
        "    numLabels=y_true.shape[3]\n",
        "    for index in range(numLabels):\n",
        "      #None,128,128,1\n",
        "      y_t=tf.expand_dims(y_true[:,:,:,index],axis=3)\n",
        "      #None,128,128\n",
        "      y_p=tf.expand_dims(y_pred[:,:,:,index],axis=3)\n",
        "      dice += dice_coef(y_t, y_p)\n",
        "    return dice/numLabels # taking average"
      ],
      "metadata": {
        "id": "hDwJ6-7ij_rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_coef_multilabel(y_true, y_pred, smooth=1):\n",
        "    dice=0\n",
        "    numLabels=y_true.shape[3]\n",
        "    for index in range(numLabels):\n",
        "      y_t=tf.expand_dims(y_true[:,:,:,index],axis=3)\n",
        "      y_p=tf.expand_dims(y_pred[:,:,:,index],axis=3)\n",
        "      dice += iou_coef(y_t, y_p)\n",
        "    return dice/numLabels # taking average"
      ],
      "metadata": {
        "id": "b2s4ld7Bj_rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHQDGpXgj_rg"
      },
      "outputs": [],
      "source": [
        "def conv_block(X,f,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (3, 3), kernel_initializer='he_normal', padding='same', groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  s = tf.keras.layers.Conv2D(f[1], (1, 1), kernel_initializer='he_normal', padding='same')(X)\n",
        "  s = tf.keras.layers.BatchNormalization(axis=3)(s)\n",
        "  c = tf.keras.layers.Add()([c,s])\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return c,c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "lxJkVfWIj_rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten(M):\n",
        "  s1=M.shape[1]\n",
        "  s2=M.shape[2]\n",
        "  s3=M.shape[3]\n",
        "  flat=s1*s2\n",
        "  M= tf.reshape(M,[-1,flat,s3])\n",
        "  return M,s1,s2,s3"
      ],
      "metadata": {
        "id": "c-orc5xwigoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trax.fastmath.set_backend('tensorflow-numpy')"
      ],
      "metadata": {
        "id": "hpvLO4Gd5cDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trax.fastmath.set_backend('numpy')"
      ],
      "metadata": {
        "id": "yeoKnkq3GNqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten_LSH(M,N,nheads,dimk,k=128):\n",
        "  M,s1,s2,s3= Flatten(M)\n",
        "  N,_,_,_= Flatten(N)\n",
        "  layer=trax.layers.PureLSHSelfAttention(n_heads=nheads,d_qk=dimk,d_v=dimk,mode=\"train\")\n",
        "  #dimk=s3\n",
        "  #print(M.dtype.as_numpy_dtype)\n",
        "  #layer.weights=(tf.random.uniform(shape=[dimk,dimk]),tf.random.uniform(shape=[dimk,dimk]),tf.random.uniform(shape=[dimk,dimk]))\n",
        "  layer=trax.AsKeras(layer,batch_size=16,dtype=tf.float64)\n",
        "  pm=layer((M,M))\n",
        "  pm=tf.reshape(pm,[-1,s1,s2,s3])\n",
        "  return pm"
      ],
      "metadata": {
        "id": "p2_jN5mpfzKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQrzUjByj_rg"
      },
      "outputs": [],
      "source": [
        "def vit(X,Y,n_heads=16,psize=16,k=256,dim=\"4D\"):\n",
        "  npatch=int(X.shape[1]/psize)\n",
        "  psizey=int(psize/2)\n",
        "  kdim=int(X.shape[3]/n_heads)\n",
        "  Y=tf.keras.layers.Dense(X.shape[3])(Y)\n",
        "  if npatch==0:\n",
        "    pm=Flatten_LSH(X,Y,n_heads,kdim,k)\n",
        "    return pm\n",
        "  for i in range(npatch):\n",
        "    st=i*psize\n",
        "    sty=i*psizey\n",
        "    end=st+psize\n",
        "    endy=sty+psizey\n",
        "    for j in range(npatch):\n",
        "      st2=j*psize\n",
        "      end2=st2+psize\n",
        "      sty2=j*psizey\n",
        "      endy2=sty2+psizey\n",
        "      patch= X[:,st:end,st2:end2,:]\n",
        "      patch2= Y[:,sty:endy,sty2:endy2,:]\n",
        "      pm=Flatten_LSH(patch,patch2,n_heads,kdim,k)\n",
        "      if j==0:\n",
        "        A=pm\n",
        "      else:\n",
        "        A=tf.concat([A,pm],2)\n",
        "    if i==0:\n",
        "      V=A\n",
        "    else:\n",
        "      V=tf.concat([V,A],1)\n",
        "  return V\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQGtnOKpj_rh"
      },
      "source": [
        "### Vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUG2WjKoj_rh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "  nheads=4\n",
        "  sizep=32\n",
        "  gr=4\n",
        "  kval=128\n",
        "  #Build the model\n",
        "  inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "  s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "  #s= inputs\n",
        "  #Contraction path\n",
        "  c1,z1 = conv_block(s,[16,16],group=1)\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "\n",
        "  c2,z2 = conv_block(p1,[32,32],group=gr)\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "  c3,z3 = conv_block(p2,[64,64],0.2,group=gr)\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "  c4,z4 = conv_block(p3,[128,128],0.2,group=gr)\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "  c5,z5 = conv_block(p4,[256,256],0.3,group=gr)\n",
        "\n",
        "  #Expansive path\n",
        "\n",
        "  m1= vit(z4,z5,nheads,sizep,k=kval)\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "  u6 = tf.keras.layers.concatenate([u6, m1])\n",
        "  c6,z6 = conv_block(u6,[128,128],0.2,group=gr)\n",
        "\n",
        "  m2= vit(z3,z6,nheads,sizep,k=kval)\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "  u7 = tf.keras.layers.concatenate([u7, m2])\n",
        "  c7,z7 = conv_block(u7,[64,64],0.2,group=gr)\n",
        "\n",
        "  m3= vit(z2,z7,nheads,sizep,k=kval)\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "  u8 = tf.keras.layers.concatenate([u8, m3])\n",
        "  c8,z8 = conv_block(u8,[32,32],group=gr)\n",
        "\n",
        "  m4= vit(z1,z8,nheads,sizep,k=kval)\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "  u9 = tf.keras.layers.concatenate([u9, m4], axis=3)\n",
        "  c9,_ = conv_block(u9,[16,16],group=gr)\n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(4, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',iou_coef_multilabel,dice_coef_multilabel])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSH without patches"
      ],
      "metadata": {
        "id": "xlxeXobBj_ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Linformer_lay(M,nheads,k=128):\n",
        "  s1=M.shape[1]\n",
        "  s2=M.shape[2]\n",
        "  s3=M.shape[3]\n",
        "  flat=s1*s2\n",
        "  M= tf.reshape(M,[-1,flat,s3])\n",
        "  kdim=int(s3/nheads)\n",
        "  layer=trax.layers.LSHSelfAttention(n_heads=nheads,d_qk=kdim,d_v=kdim,mode=\"train\")\n",
        "  layer=trax.AsKeras(layer,batch_size=16,dtype=tf.float64)\n",
        "  pm=layer((M,M))\n",
        "  pm=tf.reshape(pm,[-1,s1,s2,s3])\n",
        "  return pm"
      ],
      "metadata": {
        "id": "CW72vfYbj_ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82W_qe9Mj_ri"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "  nheads=16\n",
        "  sizep=32\n",
        "  gr=4\n",
        "\n",
        "  #Build the model\n",
        "  inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "  s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "  #s= inputs\n",
        "  #Contraction path\n",
        "  c1,z1 = conv_block(s,[16,16],group=1)\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "\n",
        "  c2,z2 = conv_block(p1,[32,32],group=gr)\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "  c3,z3 = conv_block(p2,[64,64],0.2,group=gr)\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "  c4,z4 = conv_block(p3,[128,128],0.2,group=gr)\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "  c5,z5 = conv_block(p4,[256,256],0.3,group=gr)\n",
        "\n",
        "  #Expansive path\n",
        "\n",
        "  m1= Linformer_lay(z4,nheads)\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "  u6 = tf.keras.layers.concatenate([u6, m1])\n",
        "  c6,z6 = conv_block(u6,[128,128],0.2,group=gr)\n",
        "\n",
        "  m2= Linformer_lay(z3,nheads)\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "  u7 = tf.keras.layers.concatenate([u7, m2])\n",
        "  c7,z7 = conv_block(u7,[64,64],0.2,group=gr)\n",
        "\n",
        "  m3= Linformer_lay(z2,nheads)\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "  u8 = tf.keras.layers.concatenate([u8, m3])\n",
        "  c8,z8 = conv_block(u8,[32,32],group=gr)\n",
        "\n",
        "  m4= Linformer_lay(z1,nheads)\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "  u9 = tf.keras.layers.concatenate([u9, m4], axis=3)\n",
        "  c9,_ = conv_block(u9,[16,16],group=gr)\n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(4, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',iou_coef_multilabel,dice_coef_multilabel])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test"
      ],
      "metadata": {
        "id": "AY7lXzX6j_rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=create_model()\n",
        "model.fit(X_train,Y_train,batch_size=16,epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9e1ea48-77de-4c30-f120-5c11b6382efa",
        "id": "RErtiy4Bj_rj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StagingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-c2b0b6d8d41f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-61faa5516bfe>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m#Expansive path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mm1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLinformer_lay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnheads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m   \u001b[0mu6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mu6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-7591d692fbc4>\u001b[0m in \u001b[0;36mLinformer_lay\u001b[0;34m(M, nheads, k)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSHSelfAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnheads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_qk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAsKeras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mpm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mpm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStagingError\u001b[0m: Exception encountered when calling layer \"as_keras_60\" (type AsKeras).\n\nin user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/trax/trax2keras.py\", line 184, in call  *\n        outputs, new_state = self._trax_layer.pure_fn(inputs, weights=weights,\n    File \"/usr/local/lib/python3.9/dist-packages/trax/layers/base.py\", line 605, in pure_fn  *\n        raise LayerError(name, 'pure_fn',\n\n    LayerError: Exception passing through layer LSHSelfAttention (in pure_fn):\n      layer created in file [...]/layers/research/efficient_attention.py, line 1751\n      layer input shapes: (ShapeDtype{shape:(16, 256, 128), dtype:<class 'numpy.float64'>}, ShapeDtype{shape:(16, 256, 128), dtype:<class 'numpy.float64'>})\n    \n      File [...]/autograph/operators/control_flow.py, line 1363, in if_stmt\n        _py_if_stmt(cond, body, orelse)\n    \n      File [...]/autograph/operators/control_flow.py, line 1416, in _py_if_stmt\n        return body() if cond else orelse()\n    \n      File [...]//tmp/__autograph_generated_filezn9h2mw3.py, line 88, in else_body_2\n        (outputs, s) = ag__.converted_call(ag__.ld(self)._do_custom_gradients, (ag__.ld(x),), None, fscope)\n    \n      File [...]/autograph/impl/api.py, line 441, in converted_call\n        result = converted_f(*effective_args)\n    \n      File [...]//tmp/__autograph_generated_filec538zywv.py, line 65, in tf___do_custom_gradients\n        (output, state) = ag__.converted_call(ag__.ld(do_forward), (ag__.ld(self).state, ag__.ld(self)._rng, ag__.ld(x), ag__.ld(self).weights), None, fscope)\n    \n      File [...]/autograph/impl/api.py, line 339, in converted_call\n        return _call_unconverted(f, args, kwargs, options)\n    \n      File [...]/autograph/impl/api.py, line 459, in _call_unconverted\n        return f(*args)\n    \n      File [...]//tmp/__autograph_generated_file1t_7cizk.py, line 160, in f_joint\n        retval__3 = ag__.converted_call(ag__.ld(f_diff_vjp), tuple(ag__.ld(args)[ag__.ld(counter) + 1:]), None, fscope_3)\n    \n      File [...]/autograph/impl/api.py, line 339, in converted_call\n        return _call_unconverted(f, args, kwargs, options)\n    \n      File [...]/autograph/impl/api.py, line 459, in _call_unconverted\n        return f(*args)\n    \n      File [...]//tmp/__autograph_generated_filegq45uvcz.py, line 74, in np_f\n        retval__3 = ag__.converted_call(ag__.ld(_tf_to_np), (ag__.converted_call(ag__.ld(tf_f), tuple(ag__.ld(args)), None, fscope_3),), dict(**ag__.ld(kwargs)), fscope_3)\n    \n      File [...]/autograph/impl/api.py, line 339, in converted_call\n        return _call_unconverted(f, args, kwargs, options)\n    \n      File [...]/autograph/impl/api.py, line 459, in _call_unconverted\n        return f(*args)\n    \n      File [...]/python/ops/custom_gradient.py, line 342, in __call__\n        return self._d(self._f, a, k)\n    \n      File [...]/python/ops/custom_gradient.py, line 298, in decorated\n        return _graph_mode_decorator(wrapped, args, kwargs)\n    \n      File [...]/python/ops/custom_gradient.py, line 424, in _graph_mode_decorator\n        result, grad_fn = f(*args)\n    \n      File [...]//tmp/__autograph_generated_filegq45uvcz.py, line 41, in tf_f\n        (np_y, np_vjp) = ag__.converted_call(ag__.ld(f_vjp), tuple(ag__.ld(np_args)), dict(**ag__.ld(np_kwargs)), fscope_1)\n    \n      File [...]/autograph/impl/api.py, line 339, in converted_call\n        return _call_unconverted(f, args, kwargs, options)\n    \n      File [...]/autograph/impl/api.py, line 458, in _call_unconverted\n        return f(*args, **kwargs)\n    \n      File [...]//tmp/__autograph_generated_file1t_7cizk.py, line 134, in f_vjp\n        (out, residual) = ag__.converted_call(ag__.ld(f_fwd), tuple(ag__.ld(args)), None, fscope_5)\n    \n      File [...]/autograph/impl/api.py, line 339, in converted_call\n        return _call_unconverted(f, args, kwargs, options)\n    \n      File [...]/autograph/impl/api.py, line 459, in _call_unconverted\n        return f(*args)\n    \n      File [...]//tmp/__autograph_generated_filec538zywv.py, line 37, in _f_fwd\n        res = ag__.converted_call(ag__.ld(self).forward, (ag__.ld(y),), None, fscope_2)\n    \n      File [...]/autograph/impl/api.py, line 441, in converted_call\n        result = converted_f(*effective_args)\n    \n      File [...]//tmp/__autograph_generated_fileom3v24__.py, line 185, in tf__forward\n        ag__.if_stmt(ag__.not_(ag__.ld(self)._use_reference_code), if_body_5, else_body_5, get_state_7, set_state_7, ('do_return', 'retval_', 'self.state', 'inputs', 'new_mem', 'new_mem_end', 'q_start', 'state'), 3)\n    \n      File [...]/autograph/operators/control_flow.py, line 1363, in if_stmt\n        _py_if_stmt(cond, body, orelse)\n    \n      File [...]/autograph/operators/control_flow.py, line 1416, in _py_if_stmt\n        return body() if cond else orelse()\n    \n      File [...]//tmp/__autograph_generated_fileom3v24__.py, line 29, in if_body_5\n        (output, new_state, _, _) = ag__.converted_call(ag__.ld(self).forward_and_or_backward, (ag__.ld(inputs), ag__.ld(weights), ag__.ld(state), ag__.ld(rng)), dict(compute_output=True, update_state=True), fscope)\n    \n      File [...]/autograph/impl/api.py, line 439, in converted_call\n        result = converted_f(*effective_args, **kwargs)\n    \n      File [...]//tmp/__autograph_generated_filedklozg43.py, line 734, in tf__forward_and_or_backward\n        ag__.if_stmt(ag__.or_(lambda : ag__.ld(self)._use_python_loop, lambda : ag__.ld(loop_hi) == 1), if_body_23, else_body_23, get_state_25, set_state_25, ('loop_val',), 1)\n    \n      File [...]/autograph/operators/control_flow.py, line 1363, in if_stmt\n        _py_if_stmt(cond, body, orelse)\n    \n      File [...]/autograph/operators/control_flow.py, line 1416, in _py_if_stmt\n        return body() if cond else orelse()\n    \n      File [...]//tmp/__autograph_generated_filedklozg43.py, line 732, in else_body_23\n        loop_val = ag__.converted_call(ag__.ld(fastmath).fori_loop, (0, ag__.ld(loop_hi), ag__.ld(run_inner), ag__.ld(loop_val)), None, fscope)\n    \n      File [...]/autograph/impl/api.py, line 441, in converted_call\n        result = converted_f(*effective_args)\n    \n      File [...]//tmp/__autograph_generated_fileri3j4rfh.py, line 72, in tf__fori_loop\n        ag__.if_stmt('fori_loop' in ag__.converted_call(ag__.ld(backend), (), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n    \n      File [...]/autograph/operators/control_flow.py, line 1363, in if_stmt\n        _py_if_stmt(cond, body, orelse)\n    \n      File [...]/autograph/operators/control_flow.py, line 1416, in _py_if_stmt\n        return body() if cond else orelse()\n    \n      File [...]//tmp/__autograph_generated_fileri3j4rfh.py, line 62, in else_body\n        ((_, result), _) = ag__.converted_call(ag__.ld(scan), (ag__.ld(scanned_fn), (ag__.ld(lower), ag__.ld(init_val)), None), dict(length=ag__.ld(upper) - ag__.ld(lower)), fscope)\n    \n      File [...]/autograph/impl/api.py, line 439, in converted_call\n        result = converted_f(*effective_args, **kwargs)\n    \n      File [...]//tmp/__autograph_generated_filejntpnko1.py, line 13, in tf__scan\n        retval_ = ag__.converted_call(ag__.converted_call(ag__.ld(backend), (), None, fscope)['scan'], tuple(ag__.ld(args)), dict(**ag__.ld(kwargs)), fscope)\n    \n      File [...]/autograph/impl/api.py, line 439, in converted_call\n        result = converted_f(*effective_args, **kwargs)\n    \n      File [...]//tmp/__autograph_generated_fileq3r2t0il.py, line 240, in tf__scan\n        (_, ys_spec) = ag__.converted_call(ag__.converted_call(ag__.ld(eval_on_shapes), (ag__.ld(f),), None, fscope), (ag__.ld(init), ag__.ld(xs_spec)), None, fscope)\n    \n      File [...]/autograph/impl/api.py, line 339, in converted_call\n        return _call_unconverted(f, args, kwargs, options)\n    \n      File [...]/autograph/impl/api.py, line 459, in _call_unconverted\n        return f(*args)\n    \n      File [...]//tmp/__autograph_generated_filevhhaumam.py, line 216, in f_return\n        cfun = ag__.converted_call(ag__.ld(tf_f).get_concrete_function, tuple(ag__.ld(new_args)), None, fscope_5)\n    \n      File [...]/autograph/impl/api.py, line 331, in converted_call\n        return _call_unconverted(f, args, kwargs, options, False)\n    \n      File [...]/autograph/impl/api.py, line 459, in _call_unconverted\n        return f(*args)\n    \n      File [...]/eager/polymorphic_function/polymorphic_function.py, line 1215, in get_concrete_function\n        concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\n    \n      File [...]/eager/polymorphic_function/polymorphic_function.py, line 1195, in _get_concrete_function_garbage_collected\n        self._initialize(args, kwargs, add_initializers_to=initializers)\n    \n      File [...]/eager/polymorphic_function/polymorphic_function.py, line 749, in _initialize\n        self._variable_creation_fn    # pylint: disable=protected-access\n    \n      File [...]/eager/polymorphic_function/tracing_compiler.py, line 162, in _get_concrete_function_internal_garbage_collected\n        concrete_function, _ = self._maybe_define_concrete_function(args, kwargs)\n    \n      File [...]/eager/polymorphic_function/tracing_compiler.py, line 157, in _maybe_define_concrete_function\n        return self._maybe_define_function(args, kwargs)\n    \n      File [...]/eager/polymorphic_function/tracing_compiler.py, line 360, in _maybe_define_function\n        concrete_function = self._create_concrete_function(args, kwargs)\n    \n      File [...]/eager/polymorphic_function/tracing_compiler.py, line 284, in _create_concrete_function\n        func_graph_module.func_graph_from_py_func(\n    \n      File [...]/python/framework/func_graph.py, line 1283, in func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    \n      File [...]/eager/polymorphic_function/polymorphic_function.py, line 645, in wrapped_fn\n        out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    \n      File [...]//tmp/__autograph_generated_filepqok7xve.py, line 152, in _tf_f\n        ag__.if_stmt(ag__.ld(xla_forced_compile), if_body_3, else_body_3, get_state_3, set_state_3, ('np_out', 'output_is_empty', 'output_is_list', 'output_structure'), 4)\n    \n      File [...]/autograph/operators/control_flow.py, line 1363, in if_stmt\n        _py_if_stmt(cond, body, orelse)\n    \n      File [...]/autograph/operators/control_flow.py, line 1416, in _py_if_stmt\n        return body() if cond else orelse()\n    \n      File [...]//tmp/__autograph_generated_filepqok7xve.py, line 145, in else_body_3\n        np_out = ag__.converted_call(ag__.ld(f), tuple(ag__.ld(np_args)), dict(**ag__.ld(kwargs)), fscope_1)\n    \n      File [...]/autograph/impl/api.py, line 335, in converted_call\n        return _call_unconverted(f, args, kwargs, options, False)\n    \n      File [...]/autograph/impl/api.py, line 458, in _call_unconverted\n        return f(*args, **kwargs)\n    \n      File [...]//tmp/__autograph_generated_fileri3j4rfh.py, line 57, in scanned_fn\n        retval__1 = ((ag__.ld(i) + 1, ag__.converted_call(ag__.ld(body_fn), (ag__.ld(i), ag__.ld(x)), None, fscope_1)), None)\n    \n      File [...]/autograph/impl/api.py, line 335, in converted_call\n        return _call_unconverted(f, args, kwargs, options, False)\n    \n      File [...]/autograph/impl/api.py, line 459, in _call_unconverted\n        return f(*args)\n    \n      File [...]//tmp/__autograph_generated_filedklozg43.py, line 307, in run_inner\n        ag__.if_stmt(ag__.ld(compute_grad), if_body_6, else_body_6, get_state_7, set_state_7, ('i_ct_h', 'o_h', 's_h', 'w_ct_h'), 4)\n    \n      File [...]/autograph/operators/control_flow.py, line 1363, in if_stmt\n        _py_if_stmt(cond, body, orelse)\n    \n      File [...]/autograph/operators/control_flow.py, line 1416, in _py_if_stmt\n        return body() if cond else orelse()\n    \n      File [...]//tmp/__autograph_generated_filedklozg43.py, line 301, in else_body_6\n        (o_h, s_h) = ag__.converted_call(ag__.ld(forward_fn), (ag__.ld(i_h), ag__.ld(w_h)), None, fscope_7)\n    \n      File [...]/autograph/impl/api.py, line 335, in converted_call\n        return _call_unconverted(f, args, kwargs, options, False)\n    \n      File [...]/autograph/impl/api.py, line 459, in _call_unconverted\n        return f(*args)\n    \n      File [...]//tmp/__autograph_generated_filedklozg43.py, line 279, in forward_fn\n        retval__8 = ag__.converted_call(ag__.ld(forward_unbatched), tuple(ag__.ld(i_h)), dict(weights=ag__.ld(w_h), state=ag__.converted_call(ag__.ld(fastmath).stop_gradient, (ag__.ld(s_h),), None, fscope_8)), fscope_8)\n    \n      File [...]/autograph/impl/api.py, line 335, in converted_call\n        return _call_unconverted(f, args, kwargs, options, False)\n    \n      File [...]/autograph/impl/api.py, line 458, in _call_unconverted\n        return f(*args, **kwargs)\n    \n      File [...]/layers/research/efficient_attention.py, line 1930, in forward_unbatched\n        buckets = self.hash_vectors(q, hash_subrng, mask)\n    \n      File [...]/layers/research/efficient_attention.py, line 1910, in hash_vectors\n        buckets = np.where(mask[None, :], buckets, n_buckets - 1)\n    \n      File [...]/ops/numpy_ops/np_array_ops.py, line 937, in where\n        return array_ops.where_v2(condition, x, y)\n    \n      File [...]/python/util/traceback_utils.py, line 153, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    \n      File [...]/python/framework/ops.py, line 1967, in _create_c_op\n        raise ValueError(e.message)\n    \n    ValueError: Dimensions must be equal, but are 128 and 256 for '{{node SelectV2}} = SelectV2[T=DT_INT32](Cast_31, Cast_30, Const_8)' with input shapes: [1,256,128], [1,256], [].\n\n\nCall arguments received by layer \"as_keras_60\" (type AsKeras):\n  • inputs=('tf.Tensor(shape=(16, 256, 128), dtype=float64)', 'tf.Tensor(shape=(16, 256, 128), dtype=float64)')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores= model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f'Score for fold {0}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400ebb13-8687-41a5-eb26-4c53075761ee",
        "id": "Q8kDA-zkj_rj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 0: loss of 0.02161642350256443; accuracy of 99.28983449935913% iou_coef_multilabel of 75.75774192810059% dice_coef_multilabel of 79.42734956741333%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch size=32 k=2:\n",
        "\n",
        "Score for fold 0: loss of 0.19930902123451233; accuracy of 94.81756091117859% iou_coef_multilabel of 67.01422333717346% dice_coef_multilabel of 75.7577657699585%\n"
      ],
      "metadata": {
        "id": "AHUl4onuj_rk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpGBcYq2j_rk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIbTYjOSj_rk"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Patch test 5D"
      ],
      "metadata": {
        "id": "445XQAsNj_rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=2"
      ],
      "metadata": {
        "id": "dSsM_wHAj_rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba206e9-b413-4d0c-8cd0-322bce3dfbc9",
        "id": "hD0dT6E_j_rl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.018923498690128326; accuracy of 99.33900833129883% iou_coef_multilabel of 76.09699368476868% dice_coef_multilabel of 79.55656051635742%\n",
            "Score for fold 2: loss of 0.02973838523030281; accuracy of 99.06825423240662% iou_coef_multilabel of 76.13354325294495% dice_coef_multilabel of 80.5853009223938%\n",
            "Score for fold 3: loss of 0.03030165657401085; accuracy of 99.11888837814331% iou_coef_multilabel of 75.47945976257324% dice_coef_multilabel of 79.76462244987488%\n",
            "Score for fold 4: loss of 0.027371248230338097; accuracy of 99.03544187545776% iou_coef_multilabel of 74.86760020256042% dice_coef_multilabel of 80.22578358650208%\n",
            "Score for fold 5: loss of 0.024255475029349327; accuracy of 99.22391176223755% iou_coef_multilabel of 75.09616017341614% dice_coef_multilabel of 78.89301180839539%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef91f29-5f9d-4d6d-ec06-7c2c39660489",
        "id": "wFAh1gP9j_rl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.01604907028377056; accuracy of 99.4849443435669% iou_coef_multilabel of 82.25744366645813% dice_coef_multilabel of 85.06359457969666%\n",
            "Score for fold 2: loss of 0.035502493381500244; accuracy of 98.98368120193481% iou_coef_multilabel of 81.15251660346985% dice_coef_multilabel of 85.50392389297485%\n",
            "Score for fold 3: loss of 0.03146236762404442; accuracy of 99.13598895072937% iou_coef_multilabel of 80.20720481872559% dice_coef_multilabel of 84.49628949165344%\n",
            "Score for fold 4: loss of 0.029628699645400047; accuracy of 98.99090528488159% iou_coef_multilabel of 80.18351197242737% dice_coef_multilabel of 85.33194661140442%\n",
            "Score for fold 5: loss of 0.025924744084477425; accuracy of 99.26274418830872% iou_coef_multilabel of 79.02063727378845% dice_coef_multilabel of 82.51100778579712%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test 1 25 epochs:\n",
        "\n",
        "Este test se diferencia de los siguientes porque la primera capa del decoder, tenia una falla en el skip connection, como lo estaba estructurando este toma key y query del output de la capa del nivel y la del anterior, pero sin darme cuenta deje esa, como dos del mismo nivel.\n",
        "\n",
        "Score for fold 1: loss of 0.01725444197654724; accuracy of 99.44809079170227% iou_coef_multilabel of 76.75567865371704% dice_coef_multilabel of 79.90655899047852%\n",
        "\n",
        "Score for fold 2: loss of 0.026257488876581192; accuracy of 99.15213584899902% iou_coef_multilabel of 77.25991010665894% dice_coef_multilabel of 81.667959690094%\n",
        "\n",
        "Score for fold 3: loss of 0.029813755303621292; accuracy of 99.0189254283905% iou_coef_multilabel of 73.47208261489868% dice_coef_multilabel of 77.98171043395996%\n",
        "\n",
        "Score for fold 4: loss of 0.028865722939372063; accuracy of 98.88771772384644% iou_coef_multilabel of 73.73278737068176% dice_coef_multilabel of 79.40745949745178%\n",
        "\n",
        "Score for fold 5: loss of 0.02384837530553341; accuracy of 99.24745559692383% iou_coef_multilabel of 72.86607623100281% dice_coef_multilabel of 76.55618190765381%\n",
        "\n",
        "test 1 50 epochs:\n",
        "\n",
        "Score for fold 1: loss of 0.01484227366745472; accuracy of 99.52776432037354% iou_coef_multilabel of 83.22951197624207% dice_coef_multilabel of 85.81125140190125%\n",
        "\n",
        "Score for fold 2: loss of 0.03430720046162605; accuracy of 99.037766456604% iou_coef_multilabel of 81.77401423454285% dice_coef_multilabel of 86.07376217842102%\n",
        "\n",
        "Score for fold 3: loss of 0.02642207406461239; accuracy of 99.15657639503479% iou_coef_multilabel of 79.4792652130127% dice_coef_multilabel of 83.80299210548401%\n",
        "\n",
        "Score for fold 4: loss of 0.03244418650865555; accuracy of 98.78917336463928% iou_coef_multilabel of 76.53632164001465% dice_coef_multilabel of 82.26258158683777%\n",
        "\n",
        "Score for fold 5: loss of 0.02530766651034355; accuracy of 99.25082325935364% iou_coef_multilabel of 77.88779139518738% dice_coef_multilabel of 81.41918778419495%\n",
        "\n",
        "test 2 25 epochs:\n",
        "Desde aqui estan los kfolds con las capas correctamente implementadas.\n",
        "\n",
        "Score for fold 1: loss of 0.015737926587462425; accuracy of 99.46310520172119% iou_coef_multilabel of 78.279709815979% dice_coef_multilabel of 81.3614547252655%\n",
        "\n",
        "Score for fold 2: loss of 0.03170934319496155; accuracy of 98.95466566085815% iou_coef_multilabel of 75.30025839805603% dice_coef_multilabel of 79.98074293136597%\n",
        "\n",
        "Score for fold 3: loss of 0.027374574914574623; accuracy of 99.1090476512909% iou_coef_multilabel of 75.07091164588928% dice_coef_multilabel of 79.41552400588989%\n",
        "\n",
        "Score for fold 4: loss of 0.03620793670415878; accuracy of 98.70395064353943% iou_coef_multilabel of 72.66994714736938% dice_coef_multilabel of 78.63662838935852%\n",
        "\n",
        "Score for fold 5: loss of 0.02868451550602913; accuracy of 99.15916919708252% iou_coef_multilabel of 77.30659246444702% dice_coef_multilabel of 80.87429404258728%\n",
        "\n",
        "test 2 50 epochs:\n",
        "\n",
        "Score for fold 1: loss of 0.017423078417778015; accuracy of 99.4379997253418% iou_coef_multilabel of 77.40354537963867% dice_coef_multilabel of 80.43342232704163%\n",
        "\n",
        "Score for fold 2: loss of 0.038378071039915085; accuracy of 98.94863367080688% iou_coef_multilabel of 79.24267053604126% dice_coef_multilabel of 83.60227346420288%\n",
        "\n",
        "Score for fold 3: loss of 0.028568308800458908; accuracy of 99.16971921920776% iou_coef_multilabel of 80.07370233535767% dice_coef_multilabel of 84.15423035621643%\n",
        "\n",
        "Score for fold 4: loss of 0.03010973334312439; accuracy of 99.00146722793579% iou_coef_multilabel of 80.8301031589508% dice_coef_multilabel of 85.89409589767456%\n",
        "\n",
        "Score for fold 5: loss of 0.02312619984149933; accuracy of 99.28799271583557% iou_coef_multilabel of 79.67525124549866% dice_coef_multilabel of 83.12292695045471%\n"
      ],
      "metadata": {
        "id": "nIij7A6Z__Pd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=256"
      ],
      "metadata": {
        "id": "j_dlWOw-j_rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328b22fc-64d7-4970-87da-2b9867e7d106",
        "id": "Ppbarv7Ej_rm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.016601325944066048; accuracy of 99.49246644973755% iou_coef_multilabel of 80.1440417766571% dice_coef_multilabel of 82.72783160209656%\n",
            "Score for fold 2: loss of 0.02792888507246971; accuracy of 99.11463856697083% iou_coef_multilabel of 77.49691009521484% dice_coef_multilabel of 81.86010122299194%\n",
            "Score for fold 3: loss of 0.033090461045503616; accuracy of 99.0357756614685% iou_coef_multilabel of 75.54389238357544% dice_coef_multilabel of 79.85571622848511%\n",
            "Score for fold 4: loss of 0.02735254541039467; accuracy of 99.02375340461731% iou_coef_multilabel of 75.38833618164062% dice_coef_multilabel of 80.59991002082825%\n",
            "Score for fold 5: loss of 0.02401789091527462; accuracy of 99.26612973213196% iou_coef_multilabel of 76.66497826576233% dice_coef_multilabel of 80.13312816619873%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "ee163453-4cde-4531-bfef-16e685603493",
        "id": "tS6QppYHj_rm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.01717947982251644; accuracy of 99.4581937789917% iou_coef_multilabel of 79.65168952941895% dice_coef_multilabel of 82.61964917182922%\n",
            "Score for fold 2: loss of 0.03299105167388916; accuracy of 99.06346797943115% iou_coef_multilabel of 78.3797025680542% dice_coef_multilabel of 82.73652791976929%\n",
            "Score for fold 3: loss of 0.034237224608659744; accuracy of 99.15516972541809% iou_coef_multilabel of 78.44327688217163% dice_coef_multilabel of 82.67260193824768%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-09b93a07fbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Second attempt at lsh attention, using the trax library"
      ],
      "metadata": {
        "id": "1YHmUVqd3RQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El problema que encontre en el uso de LSH Attention usando trax, es que despues de que logre que funcionara, este fue horrible en termino de tiempo de procesamiento. Una epoch duraba mas que un fold completo en los demas modelos, por lo que se decidio usar esta libreria, esperando que el problema de lo lento que era el modelo es solo culpa de AsKeras, que era la forma en que se traducia la capa de trax a keras."
      ],
      "metadata": {
        "id": "r5FupRBk3fPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q -U trax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2XGz1Kt7l-7",
        "outputId": "f2f9a729-2312-4a4d-ae50-715fb57f72e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.9/637.9 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import trax\n",
        "import numpy as np\n",
        "import trax.layers as tl\n",
        "from trax.fastmath import numpy as jnp"
      ],
      "metadata": {
        "id": "ZEm_0A4W7uHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Softmax():\n",
        "  r\"\"\"Returns a layer that computes the softmax function.\n",
        "  .. math::\n",
        "      f(x) = e^x\\sum(e^x)\n",
        "  \"\"\"\n",
        "  return tl.base.Fn('Softmax', lambda x: jnp.exp(x)/sum(jnp.exp(x)))"
      ],
      "metadata": {
        "id": "91Kw85g4VB_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()  # upload kaggle.json\n",
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "TgYpKO9ZP8VC",
        "outputId": "ac00112b-ce8e-4d34-9e9b-613a9123ebdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cda4874f-4f03-455f-8d9d-cfec95041cb3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cda4874f-4f03-455f-8d9d-cfec95041cb3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwmReB6mP-sQ",
        "outputId": "a3216804-b17a-4e63-82d4-d32607954a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                                title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-----------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "zusmani/pakistan-toshakhana-files                                  Pakistan ToshaKhana Files                             1MB  2023-03-15 16:25:43           2293         95  1.0              \n",
            "ramkrijal/tomato-daily-prices                                      Tomato Daily Prices                                  10KB  2023-03-10 15:39:14           1220         37  1.0              \n",
            "themrityunjaypathak/covid-cases-and-deaths-worldwide               Covid Cases and Deaths WorldWide                      8KB  2023-02-01 12:22:51          14181        467  1.0              \n",
            "datascientistanna/customers-dataset                                Shop Customer Data                                   23KB  2023-02-07 18:42:21          12692        282  1.0              \n",
            "priyankkhanna/flipkart-product-dataset-by-priyank-khanna           Flipkart Product Dataset                              2MB  2023-03-03 13:44:42            978         24  1.0              \n",
            "amaanansari09/most-streamed-songs-all-time                         Most Streamed Songs (All Time)                        8KB  2023-03-08 10:56:24           2174         58  1.0              \n",
            "utsh0dey/25k-movie-dataset                                         25k IMDb Movie Dataset                                5MB  2023-02-27 18:11:44            869         26  1.0              \n",
            "nidzsharma/covid-19-variant-data                                   COVID-19 Variant Data                                67KB  2023-03-12 14:07:53            657         28  1.0              \n",
            "rkiattisak/student-performance-in-mathematics                      Student performance prediction                        9KB  2023-03-12 04:32:56           2131         49  1.0              \n",
            "ashpalsingh1525/netflix                                            Netflix Cleaned Dataset                              86KB  2023-02-25 12:48:42           1016         35  1.0              \n",
            "imrulhasanrobi/world-population-all-countries-different-parameter  World Population all countries different parameter    8KB  2023-03-16 01:24:18            673         28  1.0              \n",
            "rayhan32/la-liga-player-status-season-2022-2023                    La Liga Player Status  Season 2022-2023              14KB  2023-03-15 19:52:19            531         29  1.0              \n",
            "thedevastator/airbnb-prices-in-european-cities                     Airbnb Prices in European Cities                      4MB  2023-02-20 09:48:04           4826         89  1.0              \n",
            "mirzahasnine/loan-data-set                                         Loan Data Set                                        11KB  2023-03-12 05:02:43            960         34  0.9411765        \n",
            "mehmettahiraslan/customer-shopping-dataset                         Customer Shopping Dataset - Retail Sales Data         2MB  2023-03-09 07:44:35           1384         54  1.0              \n",
            "ulrikthygepedersen/shark-tank-companies                            Shark Tank Companies                                 70KB  2023-03-02 12:05:27            688         33  1.0              \n",
            "tarique7/airline-incidents-safety-data                             Airline Incidents Safety Data                         7MB  2023-03-08 09:28:38            576         27  1.0              \n",
            "rkiattisak/traveler-trip-data                                      Traveler Trip Dataset                                 4KB  2023-03-06 07:11:05           1267         37  1.0              \n",
            "rkiattisak/salaly-prediction-for-beginer                           Salary Prediction dataset                             3KB  2023-03-07 02:45:11           1233         38  1.0              \n",
            "abdullahshahzad12345/ref-tk-data-02-to-22                          Gift Received by Pak Officials 2002-22 Tosha Khana  120KB  2023-03-14 15:49:14            164         24  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d dansbecker/cityscapes-image-pairs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRLTazVsQB2w",
        "outputId": "fdcb5448-dba4-4bf8-8dad-bca406217467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cityscapes-image-pairs.zip to /content\n",
            "100% 201M/202M [00:07<00:00, 29.4MB/s]\n",
            "100% 202M/202M [00:07<00:00, 26.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "competition_name = 'carvana-image-masking-challenge'"
      ],
      "metadata": {
        "id": "dGpo6ZBlZynZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip -q cityscapes-image-pairs.zip"
      ],
      "metadata": {
        "id": "d9HKkikdQGmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "njsSc0BZbAwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfds.list_builders()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43JtUQUnbK6I",
        "outputId": "06ef9ac4-da4b-4779-fb29-2f8bf593066b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abstract_reasoning',\n",
              " 'accentdb',\n",
              " 'aeslc',\n",
              " 'aflw2k3d',\n",
              " 'ag_news_subset',\n",
              " 'ai2_arc',\n",
              " 'ai2_arc_with_ir',\n",
              " 'amazon_us_reviews',\n",
              " 'anli',\n",
              " 'answer_equivalence',\n",
              " 'arc',\n",
              " 'asqa',\n",
              " 'asset',\n",
              " 'assin2',\n",
              " 'bair_robot_pushing_small',\n",
              " 'bccd',\n",
              " 'beans',\n",
              " 'bee_dataset',\n",
              " 'beir',\n",
              " 'big_patent',\n",
              " 'bigearthnet',\n",
              " 'billsum',\n",
              " 'binarized_mnist',\n",
              " 'binary_alpha_digits',\n",
              " 'ble_wind_field',\n",
              " 'blimp',\n",
              " 'booksum',\n",
              " 'bool_q',\n",
              " 'bucc',\n",
              " 'c4',\n",
              " 'c4_wsrs',\n",
              " 'caltech101',\n",
              " 'caltech_birds2010',\n",
              " 'caltech_birds2011',\n",
              " 'cardiotox',\n",
              " 'cars196',\n",
              " 'cassava',\n",
              " 'cats_vs_dogs',\n",
              " 'celeb_a',\n",
              " 'celeb_a_hq',\n",
              " 'cfq',\n",
              " 'cherry_blossoms',\n",
              " 'chexpert',\n",
              " 'cifar10',\n",
              " 'cifar100',\n",
              " 'cifar100_n',\n",
              " 'cifar10_1',\n",
              " 'cifar10_corrupted',\n",
              " 'cifar10_n',\n",
              " 'citrus_leaves',\n",
              " 'cityscapes',\n",
              " 'civil_comments',\n",
              " 'clevr',\n",
              " 'clic',\n",
              " 'clinc_oos',\n",
              " 'cmaterdb',\n",
              " 'cnn_dailymail',\n",
              " 'coco',\n",
              " 'coco_captions',\n",
              " 'coil100',\n",
              " 'colorectal_histology',\n",
              " 'colorectal_histology_large',\n",
              " 'common_voice',\n",
              " 'conll2002',\n",
              " 'conll2003',\n",
              " 'controlled_noisy_web_labels',\n",
              " 'coqa',\n",
              " 'cos_e',\n",
              " 'cosmos_qa',\n",
              " 'covid19',\n",
              " 'covid19sum',\n",
              " 'crema_d',\n",
              " 'criteo',\n",
              " 'cs_restaurants',\n",
              " 'curated_breast_imaging_ddsm',\n",
              " 'cycle_gan',\n",
              " 'd4rl_adroit_door',\n",
              " 'd4rl_adroit_hammer',\n",
              " 'd4rl_adroit_pen',\n",
              " 'd4rl_adroit_relocate',\n",
              " 'd4rl_antmaze',\n",
              " 'd4rl_mujoco_ant',\n",
              " 'd4rl_mujoco_halfcheetah',\n",
              " 'd4rl_mujoco_hopper',\n",
              " 'd4rl_mujoco_walker2d',\n",
              " 'dart',\n",
              " 'davis',\n",
              " 'deep1b',\n",
              " 'deep_weeds',\n",
              " 'definite_pronoun_resolution',\n",
              " 'dementiabank',\n",
              " 'diabetic_retinopathy_detection',\n",
              " 'diamonds',\n",
              " 'div2k',\n",
              " 'dmlab',\n",
              " 'doc_nli',\n",
              " 'dolphin_number_word',\n",
              " 'domainnet',\n",
              " 'downsampled_imagenet',\n",
              " 'drop',\n",
              " 'dsprites',\n",
              " 'dtd',\n",
              " 'duke_ultrasound',\n",
              " 'e2e_cleaned',\n",
              " 'efron_morris75',\n",
              " 'emnist',\n",
              " 'eraser_multi_rc',\n",
              " 'esnli',\n",
              " 'eurosat',\n",
              " 'fashion_mnist',\n",
              " 'flic',\n",
              " 'flores',\n",
              " 'food101',\n",
              " 'forest_fires',\n",
              " 'fuss',\n",
              " 'gap',\n",
              " 'geirhos_conflict_stimuli',\n",
              " 'gem',\n",
              " 'genomics_ood',\n",
              " 'german_credit_numeric',\n",
              " 'gigaword',\n",
              " 'glove100_angular',\n",
              " 'glue',\n",
              " 'goemotions',\n",
              " 'gov_report',\n",
              " 'gpt3',\n",
              " 'gref',\n",
              " 'groove',\n",
              " 'grounded_scan',\n",
              " 'gsm8k',\n",
              " 'gtzan',\n",
              " 'gtzan_music_speech',\n",
              " 'hellaswag',\n",
              " 'higgs',\n",
              " 'hillstrom',\n",
              " 'horses_or_humans',\n",
              " 'howell',\n",
              " 'i_naturalist2017',\n",
              " 'i_naturalist2018',\n",
              " 'i_naturalist2021',\n",
              " 'imagenet2012',\n",
              " 'imagenet2012_corrupted',\n",
              " 'imagenet2012_fewshot',\n",
              " 'imagenet2012_multilabel',\n",
              " 'imagenet2012_real',\n",
              " 'imagenet2012_subset',\n",
              " 'imagenet_a',\n",
              " 'imagenet_lt',\n",
              " 'imagenet_r',\n",
              " 'imagenet_resized',\n",
              " 'imagenet_sketch',\n",
              " 'imagenet_v2',\n",
              " 'imagenette',\n",
              " 'imagewang',\n",
              " 'imdb_reviews',\n",
              " 'irc_disentanglement',\n",
              " 'iris',\n",
              " 'istella',\n",
              " 'kddcup99',\n",
              " 'kitti',\n",
              " 'kmnist',\n",
              " 'laion400m',\n",
              " 'lambada',\n",
              " 'lfw',\n",
              " 'librispeech',\n",
              " 'librispeech_lm',\n",
              " 'libritts',\n",
              " 'ljspeech',\n",
              " 'lm1b',\n",
              " 'locomotion',\n",
              " 'lost_and_found',\n",
              " 'lsun',\n",
              " 'lvis',\n",
              " 'malaria',\n",
              " 'math_dataset',\n",
              " 'math_qa',\n",
              " 'mctaco',\n",
              " 'media_sum',\n",
              " 'mlqa',\n",
              " 'mnist',\n",
              " 'mnist_corrupted',\n",
              " 'movie_lens',\n",
              " 'movie_rationales',\n",
              " 'movielens',\n",
              " 'moving_mnist',\n",
              " 'mrqa',\n",
              " 'mslr_web',\n",
              " 'mt_opt',\n",
              " 'mtnt',\n",
              " 'multi_news',\n",
              " 'multi_nli',\n",
              " 'multi_nli_mismatch',\n",
              " 'natural_instructions',\n",
              " 'natural_questions',\n",
              " 'natural_questions_open',\n",
              " 'newsroom',\n",
              " 'nsynth',\n",
              " 'nyu_depth_v2',\n",
              " 'ogbg_molpcba',\n",
              " 'omniglot',\n",
              " 'open_images_challenge2019_detection',\n",
              " 'open_images_v4',\n",
              " 'openbookqa',\n",
              " 'opinion_abstracts',\n",
              " 'opinosis',\n",
              " 'opus',\n",
              " 'oxford_flowers102',\n",
              " 'oxford_iiit_pet',\n",
              " 'para_crawl',\n",
              " 'pass',\n",
              " 'patch_camelyon',\n",
              " 'paws_wiki',\n",
              " 'paws_x_wiki',\n",
              " 'penguins',\n",
              " 'pet_finder',\n",
              " 'pg19',\n",
              " 'piqa',\n",
              " 'places365_small',\n",
              " 'placesfull',\n",
              " 'plant_leaves',\n",
              " 'plant_village',\n",
              " 'plantae_k',\n",
              " 'protein_net',\n",
              " 'q_re_cc',\n",
              " 'qa4mre',\n",
              " 'qasc',\n",
              " 'quac',\n",
              " 'quality',\n",
              " 'quickdraw_bitmap',\n",
              " 'race',\n",
              " 'radon',\n",
              " 'reddit',\n",
              " 'reddit_disentanglement',\n",
              " 'reddit_tifu',\n",
              " 'ref_coco',\n",
              " 'resisc45',\n",
              " 'rlu_atari',\n",
              " 'rlu_atari_checkpoints',\n",
              " 'rlu_atari_checkpoints_ordered',\n",
              " 'rlu_control_suite',\n",
              " 'rlu_dmlab_explore_object_rewards_few',\n",
              " 'rlu_dmlab_explore_object_rewards_many',\n",
              " 'rlu_dmlab_rooms_select_nonmatching_object',\n",
              " 'rlu_dmlab_rooms_watermaze',\n",
              " 'rlu_dmlab_seekavoid_arena01',\n",
              " 'rlu_locomotion',\n",
              " 'rlu_rwrl',\n",
              " 'robomimic_ph',\n",
              " 'robonet',\n",
              " 'robosuite_panda_pick_place_can',\n",
              " 'rock_paper_scissors',\n",
              " 'rock_you',\n",
              " 's3o4d',\n",
              " 'salient_span_wikipedia',\n",
              " 'samsum',\n",
              " 'savee',\n",
              " 'scan',\n",
              " 'scene_parse150',\n",
              " 'schema_guided_dialogue',\n",
              " 'sci_tail',\n",
              " 'scicite',\n",
              " 'scientific_papers',\n",
              " 'scrolls',\n",
              " 'sentiment140',\n",
              " 'shapes3d',\n",
              " 'sift1m',\n",
              " 'simpte',\n",
              " 'siscore',\n",
              " 'smallnorb',\n",
              " 'smartwatch_gestures',\n",
              " 'snli',\n",
              " 'so2sat',\n",
              " 'speech_commands',\n",
              " 'spoken_digit',\n",
              " 'squad',\n",
              " 'squad_question_generation',\n",
              " 'stanford_dogs',\n",
              " 'stanford_online_products',\n",
              " 'star_cfq',\n",
              " 'starcraft_video',\n",
              " 'stl10',\n",
              " 'story_cloze',\n",
              " 'summscreen',\n",
              " 'sun397',\n",
              " 'super_glue',\n",
              " 'svhn_cropped',\n",
              " 'symmetric_solids',\n",
              " 'tao',\n",
              " 'tatoeba',\n",
              " 'ted_hrlr_translate',\n",
              " 'ted_multi_translate',\n",
              " 'tedlium',\n",
              " 'tf_flowers',\n",
              " 'the300w_lp',\n",
              " 'tiny_shakespeare',\n",
              " 'titanic',\n",
              " 'trec',\n",
              " 'trivia_qa',\n",
              " 'tydi_qa',\n",
              " 'uc_merced',\n",
              " 'ucf101',\n",
              " 'unified_qa',\n",
              " 'universal_dependencies',\n",
              " 'unnatural_instructions',\n",
              " 'user_libri_audio',\n",
              " 'user_libri_text',\n",
              " 'vctk',\n",
              " 'visual_domain_decathlon',\n",
              " 'voc',\n",
              " 'voxceleb',\n",
              " 'voxforge',\n",
              " 'waymo_open_dataset',\n",
              " 'web_graph',\n",
              " 'web_nlg',\n",
              " 'web_questions',\n",
              " 'wider_face',\n",
              " 'wiki40b',\n",
              " 'wiki_auto',\n",
              " 'wiki_bio',\n",
              " 'wiki_dialog',\n",
              " 'wiki_table_questions',\n",
              " 'wiki_table_text',\n",
              " 'wikiann',\n",
              " 'wikihow',\n",
              " 'wikipedia',\n",
              " 'wikipedia_toxicity_subtypes',\n",
              " 'wine_quality',\n",
              " 'winogrande',\n",
              " 'wit',\n",
              " 'wit_kaggle',\n",
              " 'wmt13_translate',\n",
              " 'wmt14_translate',\n",
              " 'wmt15_translate',\n",
              " 'wmt16_translate',\n",
              " 'wmt17_translate',\n",
              " 'wmt18_translate',\n",
              " 'wmt19_translate',\n",
              " 'wmt_t2t_translate',\n",
              " 'wmt_translate',\n",
              " 'wordnet',\n",
              " 'wsc273',\n",
              " 'xnli',\n",
              " 'xquad',\n",
              " 'xsum',\n",
              " 'xtreme_pawsx',\n",
              " 'xtreme_pos',\n",
              " 'xtreme_s',\n",
              " 'xtreme_xnli',\n",
              " 'yahoo_ltrc',\n",
              " 'yelp_polarity_reviews',\n",
              " 'yes_no',\n",
              " 'youtube_vis',\n",
              " 'huggingface:acronym_identification',\n",
              " 'huggingface:ade_corpus_v2',\n",
              " 'huggingface:adv_glue',\n",
              " 'huggingface:adversarial_qa',\n",
              " 'huggingface:aeslc',\n",
              " 'huggingface:afrikaans_ner_corpus',\n",
              " 'huggingface:ag_news',\n",
              " 'huggingface:ai2_arc',\n",
              " 'huggingface:air_dialogue',\n",
              " 'huggingface:ajgt_twitter_ar',\n",
              " 'huggingface:allegro_reviews',\n",
              " 'huggingface:allocine',\n",
              " 'huggingface:alt',\n",
              " 'huggingface:amazon_polarity',\n",
              " 'huggingface:amazon_reviews_multi',\n",
              " 'huggingface:amazon_us_reviews',\n",
              " 'huggingface:ambig_qa',\n",
              " 'huggingface:americas_nli',\n",
              " 'huggingface:ami',\n",
              " 'huggingface:amttl',\n",
              " 'huggingface:anli',\n",
              " 'huggingface:app_reviews',\n",
              " 'huggingface:aqua_rat',\n",
              " 'huggingface:aquamuse',\n",
              " 'huggingface:ar_cov19',\n",
              " 'huggingface:ar_res_reviews',\n",
              " 'huggingface:ar_sarcasm',\n",
              " 'huggingface:arabic_billion_words',\n",
              " 'huggingface:arabic_pos_dialect',\n",
              " 'huggingface:arabic_speech_corpus',\n",
              " 'huggingface:arcd',\n",
              " 'huggingface:arsentd_lev',\n",
              " 'huggingface:art',\n",
              " 'huggingface:arxiv_dataset',\n",
              " 'huggingface:ascent_kb',\n",
              " 'huggingface:aslg_pc12',\n",
              " 'huggingface:asnq',\n",
              " 'huggingface:asset',\n",
              " 'huggingface:assin',\n",
              " 'huggingface:assin2',\n",
              " 'huggingface:atomic',\n",
              " 'huggingface:autshumato',\n",
              " 'huggingface:babi_qa',\n",
              " 'huggingface:banking77',\n",
              " 'huggingface:bbaw_egyptian',\n",
              " 'huggingface:bbc_hindi_nli',\n",
              " 'huggingface:bc2gm_corpus',\n",
              " 'huggingface:beans',\n",
              " 'huggingface:best2009',\n",
              " 'huggingface:bianet',\n",
              " 'huggingface:bible_para',\n",
              " 'huggingface:big_patent',\n",
              " 'huggingface:bigbench',\n",
              " 'huggingface:billsum',\n",
              " 'huggingface:bing_coronavirus_query_set',\n",
              " 'huggingface:biomrc',\n",
              " 'huggingface:biosses',\n",
              " 'huggingface:biwi_kinect_head_pose',\n",
              " 'huggingface:blbooks',\n",
              " 'huggingface:blbooksgenre',\n",
              " 'huggingface:blended_skill_talk',\n",
              " 'huggingface:blimp',\n",
              " 'huggingface:blog_authorship_corpus',\n",
              " 'huggingface:bn_hate_speech',\n",
              " 'huggingface:bnl_newspapers',\n",
              " 'huggingface:bookcorpus',\n",
              " 'huggingface:bookcorpusopen',\n",
              " 'huggingface:boolq',\n",
              " 'huggingface:bprec',\n",
              " 'huggingface:break_data',\n",
              " 'huggingface:brwac',\n",
              " 'huggingface:bsd_ja_en',\n",
              " 'huggingface:bswac',\n",
              " 'huggingface:c3',\n",
              " 'huggingface:c4',\n",
              " 'huggingface:cail2018',\n",
              " 'huggingface:caner',\n",
              " 'huggingface:capes',\n",
              " 'huggingface:casino',\n",
              " 'huggingface:catalonia_independence',\n",
              " 'huggingface:cats_vs_dogs',\n",
              " 'huggingface:cawac',\n",
              " 'huggingface:cbt',\n",
              " 'huggingface:cc100',\n",
              " 'huggingface:cc_news',\n",
              " 'huggingface:ccaligned_multilingual',\n",
              " 'huggingface:cdsc',\n",
              " 'huggingface:cdt',\n",
              " 'huggingface:cedr',\n",
              " 'huggingface:cfq',\n",
              " 'huggingface:chr_en',\n",
              " 'huggingface:cifar10',\n",
              " 'huggingface:cifar100',\n",
              " 'huggingface:circa',\n",
              " 'huggingface:civil_comments',\n",
              " 'huggingface:clickbait_news_bg',\n",
              " 'huggingface:climate_fever',\n",
              " 'huggingface:clinc_oos',\n",
              " 'huggingface:clue',\n",
              " 'huggingface:cmrc2018',\n",
              " 'huggingface:cmu_hinglish_dog',\n",
              " 'huggingface:cnn_dailymail',\n",
              " 'huggingface:coached_conv_pref',\n",
              " 'huggingface:coarse_discourse',\n",
              " 'huggingface:codah',\n",
              " 'huggingface:code_search_net',\n",
              " 'huggingface:code_x_glue_cc_clone_detection_big_clone_bench',\n",
              " 'huggingface:code_x_glue_cc_clone_detection_poj104',\n",
              " 'huggingface:code_x_glue_cc_cloze_testing_all',\n",
              " 'huggingface:code_x_glue_cc_cloze_testing_maxmin',\n",
              " 'huggingface:code_x_glue_cc_code_completion_line',\n",
              " 'huggingface:code_x_glue_cc_code_completion_token',\n",
              " 'huggingface:code_x_glue_cc_code_refinement',\n",
              " 'huggingface:code_x_glue_cc_code_to_code_trans',\n",
              " 'huggingface:code_x_glue_cc_defect_detection',\n",
              " 'huggingface:code_x_glue_ct_code_to_text',\n",
              " 'huggingface:code_x_glue_tc_nl_code_search_adv',\n",
              " 'huggingface:code_x_glue_tc_text_to_code',\n",
              " 'huggingface:code_x_glue_tt_text_to_text',\n",
              " 'huggingface:com_qa',\n",
              " 'huggingface:common_gen',\n",
              " 'huggingface:common_language',\n",
              " 'huggingface:common_voice',\n",
              " 'huggingface:commonsense_qa',\n",
              " 'huggingface:competition_math',\n",
              " 'huggingface:compguesswhat',\n",
              " 'huggingface:conceptnet5',\n",
              " 'huggingface:conceptual_12m',\n",
              " 'huggingface:conceptual_captions',\n",
              " 'huggingface:conll2000',\n",
              " 'huggingface:conll2002',\n",
              " 'huggingface:conll2003',\n",
              " 'huggingface:conll2012_ontonotesv5',\n",
              " 'huggingface:conllpp',\n",
              " 'huggingface:consumer-finance-complaints',\n",
              " 'huggingface:conv_ai',\n",
              " 'huggingface:conv_ai_2',\n",
              " 'huggingface:conv_ai_3',\n",
              " 'huggingface:conv_questions',\n",
              " 'huggingface:coqa',\n",
              " 'huggingface:cord19',\n",
              " 'huggingface:cornell_movie_dialog',\n",
              " 'huggingface:cos_e',\n",
              " 'huggingface:cosmos_qa',\n",
              " 'huggingface:counter',\n",
              " 'huggingface:covid_qa_castorini',\n",
              " 'huggingface:covid_qa_deepset',\n",
              " 'huggingface:covid_qa_ucsd',\n",
              " 'huggingface:covid_tweets_japanese',\n",
              " 'huggingface:covost2',\n",
              " 'huggingface:cppe-5',\n",
              " 'huggingface:craigslist_bargains',\n",
              " 'huggingface:crawl_domain',\n",
              " 'huggingface:crd3',\n",
              " 'huggingface:crime_and_punish',\n",
              " 'huggingface:crows_pairs',\n",
              " 'huggingface:cryptonite',\n",
              " 'huggingface:cs_restaurants',\n",
              " 'huggingface:cuad',\n",
              " 'huggingface:curiosity_dialogs',\n",
              " 'huggingface:daily_dialog',\n",
              " 'huggingface:dane',\n",
              " 'huggingface:danish_political_comments',\n",
              " 'huggingface:dart',\n",
              " 'huggingface:datacommons_factcheck',\n",
              " 'huggingface:dbpedia_14',\n",
              " 'huggingface:dbrd',\n",
              " 'huggingface:deal_or_no_dialog',\n",
              " 'huggingface:definite_pronoun_resolution',\n",
              " 'huggingface:dengue_filipino',\n",
              " 'huggingface:dialog_re',\n",
              " 'huggingface:diplomacy_detection',\n",
              " 'huggingface:disaster_response_messages',\n",
              " 'huggingface:discofuse',\n",
              " 'huggingface:discovery',\n",
              " 'huggingface:disfl_qa',\n",
              " 'huggingface:doc2dial',\n",
              " 'huggingface:docred',\n",
              " 'huggingface:doqa',\n",
              " 'huggingface:dream',\n",
              " 'huggingface:drop',\n",
              " 'huggingface:duorc',\n",
              " 'huggingface:dutch_social',\n",
              " 'huggingface:dyk',\n",
              " 'huggingface:e2e_nlg',\n",
              " 'huggingface:e2e_nlg_cleaned',\n",
              " 'huggingface:ecb',\n",
              " 'huggingface:ecthr_cases',\n",
              " 'huggingface:eduge',\n",
              " 'huggingface:ehealth_kd',\n",
              " 'huggingface:eitb_parcc',\n",
              " 'huggingface:electricity_load_diagrams',\n",
              " 'huggingface:eli5',\n",
              " 'huggingface:eli5_category',\n",
              " 'huggingface:elkarhizketak',\n",
              " 'huggingface:emea',\n",
              " 'huggingface:emo',\n",
              " 'huggingface:emotion',\n",
              " 'huggingface:emotone_ar',\n",
              " 'huggingface:empathetic_dialogues',\n",
              " 'huggingface:enriched_web_nlg',\n",
              " 'huggingface:enwik8',\n",
              " 'huggingface:eraser_multi_rc',\n",
              " 'huggingface:esnli',\n",
              " 'huggingface:eth_py150_open',\n",
              " 'huggingface:ethos',\n",
              " 'huggingface:ett',\n",
              " 'huggingface:eu_regulatory_ir',\n",
              " 'huggingface:eurlex',\n",
              " 'huggingface:euronews',\n",
              " 'huggingface:europa_eac_tm',\n",
              " 'huggingface:europa_ecdc_tm',\n",
              " 'huggingface:europarl_bilingual',\n",
              " 'huggingface:event2Mind',\n",
              " 'huggingface:evidence_infer_treatment',\n",
              " 'huggingface:exams',\n",
              " 'huggingface:factckbr',\n",
              " 'huggingface:fake_news_english',\n",
              " 'huggingface:fake_news_filipino',\n",
              " 'huggingface:farsi_news',\n",
              " 'huggingface:fashion_mnist',\n",
              " 'huggingface:fever',\n",
              " 'huggingface:few_rel',\n",
              " 'huggingface:financial_phrasebank',\n",
              " 'huggingface:finer',\n",
              " 'huggingface:flores',\n",
              " 'huggingface:flue',\n",
              " 'huggingface:food101',\n",
              " 'huggingface:fquad',\n",
              " 'huggingface:freebase_qa',\n",
              " 'huggingface:gap',\n",
              " 'huggingface:gem',\n",
              " 'huggingface:generated_reviews_enth',\n",
              " 'huggingface:generics_kb',\n",
              " 'huggingface:german_legal_entity_recognition',\n",
              " 'huggingface:germaner',\n",
              " 'huggingface:germeval_14',\n",
              " 'huggingface:giga_fren',\n",
              " 'huggingface:gigaword',\n",
              " 'huggingface:glucose',\n",
              " 'huggingface:glue',\n",
              " 'huggingface:gnad10',\n",
              " 'huggingface:go_emotions',\n",
              " 'huggingface:gooaq',\n",
              " 'huggingface:google_wellformed_query',\n",
              " 'huggingface:grail_qa',\n",
              " 'huggingface:great_code',\n",
              " 'huggingface:greek_legal_code',\n",
              " 'huggingface:gsm8k',\n",
              " 'huggingface:guardian_authorship',\n",
              " 'huggingface:gutenberg_time',\n",
              " 'huggingface:hans',\n",
              " 'huggingface:hansards',\n",
              " 'huggingface:hard',\n",
              " 'huggingface:harem',\n",
              " 'huggingface:has_part',\n",
              " 'huggingface:hate_offensive',\n",
              " 'huggingface:hate_speech18',\n",
              " 'huggingface:hate_speech_filipino',\n",
              " 'huggingface:hate_speech_offensive',\n",
              " 'huggingface:hate_speech_pl',\n",
              " 'huggingface:hate_speech_portuguese',\n",
              " 'huggingface:hatexplain',\n",
              " 'huggingface:hausa_voa_ner',\n",
              " 'huggingface:hausa_voa_topics',\n",
              " 'huggingface:hda_nli_hindi',\n",
              " 'huggingface:head_qa',\n",
              " 'huggingface:health_fact',\n",
              " 'huggingface:hebrew_projectbenyehuda',\n",
              " 'huggingface:hebrew_sentiment',\n",
              " 'huggingface:hebrew_this_world',\n",
              " 'huggingface:hellaswag',\n",
              " 'huggingface:hendrycks_test',\n",
              " 'huggingface:hind_encorp',\n",
              " 'huggingface:hindi_discourse',\n",
              " 'huggingface:hippocorpus',\n",
              " 'huggingface:hkcancor',\n",
              " 'huggingface:hlgd',\n",
              " 'huggingface:hope_edi',\n",
              " 'huggingface:hotpot_qa',\n",
              " 'huggingface:hover',\n",
              " 'huggingface:hrenwac_para',\n",
              " 'huggingface:hrwac',\n",
              " 'huggingface:humicroedit',\n",
              " 'huggingface:hybrid_qa',\n",
              " 'huggingface:hyperpartisan_news_detection',\n",
              " 'huggingface:iapp_wiki_qa_squad',\n",
              " 'huggingface:id_clickbait',\n",
              " 'huggingface:id_liputan6',\n",
              " 'huggingface:id_nergrit_corpus',\n",
              " 'huggingface:id_newspapers_2018',\n",
              " 'huggingface:id_panl_bppt',\n",
              " 'huggingface:id_puisi',\n",
              " 'huggingface:igbo_english_machine_translation',\n",
              " 'huggingface:igbo_monolingual',\n",
              " 'huggingface:igbo_ner',\n",
              " 'huggingface:ilist',\n",
              " 'huggingface:imagenet-1k',\n",
              " 'huggingface:imagenet_sketch',\n",
              " 'huggingface:imdb',\n",
              " 'huggingface:imdb_urdu_reviews',\n",
              " 'huggingface:imppres',\n",
              " 'huggingface:indic_glue',\n",
              " 'huggingface:indonli',\n",
              " 'huggingface:indonlu',\n",
              " 'huggingface:inquisitive_qg',\n",
              " 'huggingface:interpress_news_category_tr',\n",
              " 'huggingface:interpress_news_category_tr_lite',\n",
              " 'huggingface:irc_disentangle',\n",
              " 'huggingface:isixhosa_ner_corpus',\n",
              " 'huggingface:isizulu_ner_corpus',\n",
              " 'huggingface:iwslt2017',\n",
              " 'huggingface:jeopardy',\n",
              " 'huggingface:jfleg',\n",
              " 'huggingface:jigsaw_toxicity_pred',\n",
              " 'huggingface:jigsaw_unintended_bias',\n",
              " 'huggingface:jnlpba',\n",
              " 'huggingface:journalists_questions',\n",
              " 'huggingface:kan_hope',\n",
              " 'huggingface:kannada_news',\n",
              " 'huggingface:kd_conv',\n",
              " 'huggingface:kde4',\n",
              " 'huggingface:kelm',\n",
              " 'huggingface:kilt_tasks',\n",
              " 'huggingface:kilt_wikipedia',\n",
              " 'huggingface:kinnews_kirnews',\n",
              " 'huggingface:klue',\n",
              " 'huggingface:kor_3i4k',\n",
              " 'huggingface:kor_hate',\n",
              " 'huggingface:kor_ner',\n",
              " 'huggingface:kor_nli',\n",
              " 'huggingface:kor_nlu',\n",
              " 'huggingface:kor_qpair',\n",
              " 'huggingface:kor_sae',\n",
              " 'huggingface:kor_sarcasm',\n",
              " 'huggingface:labr',\n",
              " 'huggingface:lama',\n",
              " 'huggingface:lambada',\n",
              " 'huggingface:large_spanish_corpus',\n",
              " 'huggingface:laroseda',\n",
              " 'huggingface:lc_quad',\n",
              " 'huggingface:lccc',\n",
              " 'huggingface:lener_br',\n",
              " 'huggingface:lex_glue',\n",
              " 'huggingface:liar',\n",
              " 'huggingface:librispeech_asr',\n",
              " 'huggingface:librispeech_lm',\n",
              " 'huggingface:limit',\n",
              " 'huggingface:lince',\n",
              " 'huggingface:linnaeus',\n",
              " 'huggingface:liveqa',\n",
              " 'huggingface:lj_speech',\n",
              " 'huggingface:lm1b',\n",
              " 'huggingface:lst20',\n",
              " 'huggingface:m_lama',\n",
              " 'huggingface:mac_morpho',\n",
              " 'huggingface:makhzan',\n",
              " 'huggingface:masakhaner',\n",
              " 'huggingface:math_dataset',\n",
              " 'huggingface:math_qa',\n",
              " 'huggingface:matinf',\n",
              " 'huggingface:mbpp',\n",
              " 'huggingface:mc4',\n",
              " 'huggingface:mc_taco',\n",
              " 'huggingface:md_gender_bias',\n",
              " 'huggingface:mdd',\n",
              " 'huggingface:med_hop',\n",
              " 'huggingface:medal',\n",
              " 'huggingface:medical_dialog',\n",
              " 'huggingface:medical_questions_pairs',\n",
              " 'huggingface:medmcqa',\n",
              " 'huggingface:menyo20k_mt',\n",
              " 'huggingface:meta_woz',\n",
              " 'huggingface:metashift',\n",
              " 'huggingface:metooma',\n",
              " 'huggingface:metrec',\n",
              " 'huggingface:miam',\n",
              " 'huggingface:mkb',\n",
              " 'huggingface:mkqa',\n",
              " 'huggingface:mlqa',\n",
              " 'huggingface:mlsum',\n",
              " 'huggingface:mnist',\n",
              " 'huggingface:mocha',\n",
              " 'huggingface:monash_tsf',\n",
              " 'huggingface:moroco',\n",
              " 'huggingface:movie_rationales',\n",
              " 'huggingface:mrqa',\n",
              " 'huggingface:ms_marco',\n",
              " 'huggingface:ms_terms',\n",
              " 'huggingface:msr_genomics_kbcomp',\n",
              " 'huggingface:msr_sqa',\n",
              " 'huggingface:msr_text_compression',\n",
              " 'huggingface:msr_zhen_translation_parity',\n",
              " 'huggingface:msra_ner',\n",
              " 'huggingface:mt_eng_vietnamese',\n",
              " 'huggingface:muchocine',\n",
              " 'huggingface:multi_booked',\n",
              " 'huggingface:multi_eurlex',\n",
              " 'huggingface:multi_news',\n",
              " 'huggingface:multi_nli',\n",
              " 'huggingface:multi_nli_mismatch',\n",
              " 'huggingface:multi_para_crawl',\n",
              " 'huggingface:multi_re_qa',\n",
              " 'huggingface:multi_woz_v22',\n",
              " 'huggingface:multi_x_science_sum',\n",
              " 'huggingface:multidoc2dial',\n",
              " 'huggingface:multilingual_librispeech',\n",
              " 'huggingface:mutual_friends',\n",
              " 'huggingface:mwsc',\n",
              " 'huggingface:myanmar_news',\n",
              " 'huggingface:narrativeqa',\n",
              " 'huggingface:narrativeqa_manual',\n",
              " 'huggingface:natural_questions',\n",
              " 'huggingface:ncbi_disease',\n",
              " 'huggingface:nchlt',\n",
              " 'huggingface:ncslgr',\n",
              " 'huggingface:nell',\n",
              " 'huggingface:neural_code_search',\n",
              " 'huggingface:news_commentary',\n",
              " 'huggingface:newsgroup',\n",
              " 'huggingface:newsph',\n",
              " 'huggingface:newsph_nli',\n",
              " 'huggingface:newspop',\n",
              " 'huggingface:newsqa',\n",
              " 'huggingface:newsroom',\n",
              " 'huggingface:nkjp-ner',\n",
              " 'huggingface:nli_tr',\n",
              " 'huggingface:nlu_evaluation_data',\n",
              " 'huggingface:norec',\n",
              " 'huggingface:norne',\n",
              " 'huggingface:norwegian_ner',\n",
              " 'huggingface:nq_open',\n",
              " 'huggingface:nsmc',\n",
              " 'huggingface:numer_sense',\n",
              " 'huggingface:numeric_fused_head',\n",
              " 'huggingface:oclar',\n",
              " 'huggingface:offcombr',\n",
              " 'huggingface:offenseval2020_tr',\n",
              " 'huggingface:offenseval_dravidian',\n",
              " 'huggingface:ofis_publik',\n",
              " 'huggingface:ohsumed',\n",
              " 'huggingface:ollie',\n",
              " 'huggingface:omp',\n",
              " 'huggingface:onestop_english',\n",
              " 'huggingface:onestop_qa',\n",
              " 'huggingface:open_subtitles',\n",
              " 'huggingface:openai_humaneval',\n",
              " 'huggingface:openbookqa',\n",
              " 'huggingface:openslr',\n",
              " 'huggingface:openwebtext',\n",
              " 'huggingface:opinosis',\n",
              " 'huggingface:opus100',\n",
              " 'huggingface:opus_books',\n",
              " 'huggingface:opus_dgt',\n",
              " 'huggingface:opus_dogc',\n",
              " 'huggingface:opus_elhuyar',\n",
              " 'huggingface:opus_euconst',\n",
              " 'huggingface:opus_finlex',\n",
              " 'huggingface:opus_fiskmo',\n",
              " 'huggingface:opus_gnome',\n",
              " 'huggingface:opus_infopankki',\n",
              " 'huggingface:opus_memat',\n",
              " 'huggingface:opus_montenegrinsubs',\n",
              " 'huggingface:opus_openoffice',\n",
              " 'huggingface:opus_paracrawl',\n",
              " 'huggingface:opus_rf',\n",
              " 'huggingface:opus_tedtalks',\n",
              " 'huggingface:opus_ubuntu',\n",
              " 'huggingface:opus_wikipedia',\n",
              " 'huggingface:opus_xhosanavy',\n",
              " 'huggingface:orange_sum',\n",
              " 'huggingface:oscar',\n",
              " 'huggingface:para_crawl',\n",
              " 'huggingface:para_pat',\n",
              " 'huggingface:parsinlu_reading_comprehension',\n",
              " 'huggingface:pass',\n",
              " 'huggingface:paws',\n",
              " 'huggingface:paws-x',\n",
              " 'huggingface:pec',\n",
              " 'huggingface:peer_read',\n",
              " 'huggingface:peoples_daily_ner',\n",
              " 'huggingface:per_sent',\n",
              " 'huggingface:persian_ner',\n",
              " 'huggingface:pg19',\n",
              " 'huggingface:php',\n",
              " 'huggingface:piaf',\n",
              " 'huggingface:pib',\n",
              " 'huggingface:piqa',\n",
              " 'huggingface:pn_summary',\n",
              " 'huggingface:poem_sentiment',\n",
              " 'huggingface:polemo2',\n",
              " 'huggingface:poleval2019_cyberbullying',\n",
              " 'huggingface:poleval2019_mt',\n",
              " 'huggingface:polsum',\n",
              " 'huggingface:polyglot_ner',\n",
              " 'huggingface:prachathai67k',\n",
              " 'huggingface:pragmeval',\n",
              " 'huggingface:proto_qa',\n",
              " 'huggingface:psc',\n",
              " 'huggingface:ptb_text_only',\n",
              " 'huggingface:pubmed',\n",
              " 'huggingface:pubmed_qa',\n",
              " 'huggingface:py_ast',\n",
              " 'huggingface:qa4mre',\n",
              " 'huggingface:qa_srl',\n",
              " 'huggingface:qa_zre',\n",
              " 'huggingface:qangaroo',\n",
              " 'huggingface:qanta',\n",
              " 'huggingface:qasc',\n",
              " 'huggingface:qasper',\n",
              " 'huggingface:qed',\n",
              " 'huggingface:qed_amara',\n",
              " 'huggingface:quac',\n",
              " 'huggingface:quail',\n",
              " 'huggingface:quarel',\n",
              " 'huggingface:quartz',\n",
              " 'huggingface:quickdraw',\n",
              " 'huggingface:quora',\n",
              " 'huggingface:quoref',\n",
              " 'huggingface:race',\n",
              " 'huggingface:re_dial',\n",
              " 'huggingface:reasoning_bg',\n",
              " 'huggingface:recipe_nlg',\n",
              " 'huggingface:reclor',\n",
              " 'huggingface:red_caps',\n",
              " 'huggingface:reddit',\n",
              " 'huggingface:reddit_tifu',\n",
              " 'huggingface:refresd',\n",
              " 'huggingface:reuters21578',\n",
              " 'huggingface:riddle_sense',\n",
              " 'huggingface:ro_sent',\n",
              " 'huggingface:ro_sts',\n",
              " 'huggingface:ro_sts_parallel',\n",
              " 'huggingface:roman_urdu',\n",
              " 'huggingface:roman_urdu_hate_speech',\n",
              " 'huggingface:ronec',\n",
              " 'huggingface:ropes',\n",
              " 'huggingface:rotten_tomatoes',\n",
              " 'huggingface:russian_super_glue',\n",
              " 'huggingface:rvl_cdip',\n",
              " 'huggingface:s2orc',\n",
              " 'huggingface:samsum',\n",
              " 'huggingface:sanskrit_classic',\n",
              " 'huggingface:saudinewsnet',\n",
              " 'huggingface:sberquad',\n",
              " 'huggingface:sbu_captions',\n",
              " 'huggingface:scan',\n",
              " 'huggingface:scb_mt_enth_2020',\n",
              " 'huggingface:scene_parse_150',\n",
              " 'huggingface:schema_guided_dstc8',\n",
              " 'huggingface:scicite',\n",
              " 'huggingface:scielo',\n",
              " 'huggingface:scientific_papers',\n",
              " 'huggingface:scifact',\n",
              " 'huggingface:sciq',\n",
              " 'huggingface:scitail',\n",
              " 'huggingface:scitldr',\n",
              " 'huggingface:search_qa',\n",
              " 'huggingface:sede',\n",
              " 'huggingface:selqa',\n",
              " 'huggingface:sem_eval_2010_task_8',\n",
              " 'huggingface:sem_eval_2014_task_1',\n",
              " 'huggingface:sem_eval_2018_task_1',\n",
              " 'huggingface:sem_eval_2020_task_11',\n",
              " 'huggingface:sent_comp',\n",
              " 'huggingface:senti_lex',\n",
              " 'huggingface:senti_ws',\n",
              " 'huggingface:sentiment140',\n",
              " 'huggingface:sepedi_ner',\n",
              " 'huggingface:sesotho_ner_corpus',\n",
              " 'huggingface:setimes',\n",
              " 'huggingface:setswana_ner_corpus',\n",
              " 'huggingface:sharc',\n",
              " 'huggingface:sharc_modified',\n",
              " 'huggingface:sick',\n",
              " 'huggingface:silicone',\n",
              " 'huggingface:simple_questions_v2',\n",
              " 'huggingface:siswati_ner_corpus',\n",
              " 'huggingface:smartdata',\n",
              " 'huggingface:sms_spam',\n",
              " 'huggingface:snips_built_in_intents',\n",
              " 'huggingface:snli',\n",
              " 'huggingface:snow_simplified_japanese_corpus',\n",
              " 'huggingface:so_stacksample',\n",
              " 'huggingface:social_bias_frames',\n",
              " 'huggingface:social_i_qa',\n",
              " 'huggingface:sofc_materials_articles',\n",
              " 'huggingface:sogou_news',\n",
              " 'huggingface:spanish_billion_words',\n",
              " 'huggingface:spc',\n",
              " 'huggingface:species_800',\n",
              " 'huggingface:speech_commands',\n",
              " 'huggingface:spider',\n",
              " 'huggingface:squad',\n",
              " 'huggingface:squad_adversarial',\n",
              " 'huggingface:squad_es',\n",
              " 'huggingface:squad_it',\n",
              " 'huggingface:squad_kor_v1',\n",
              " 'huggingface:squad_kor_v2',\n",
              " 'huggingface:squad_v1_pt',\n",
              " 'huggingface:squad_v2',\n",
              " 'huggingface:squadshifts',\n",
              " 'huggingface:srwac',\n",
              " 'huggingface:sst',\n",
              " 'huggingface:stereoset',\n",
              " 'huggingface:story_cloze',\n",
              " 'huggingface:stsb_mt_sv',\n",
              " 'huggingface:stsb_multi_mt',\n",
              " 'huggingface:style_change_detection',\n",
              " 'huggingface:subjqa',\n",
              " 'huggingface:super_glue',\n",
              " 'huggingface:superb',\n",
              " 'huggingface:svhn',\n",
              " 'huggingface:swag',\n",
              " 'huggingface:swahili',\n",
              " 'huggingface:swahili_news',\n",
              " 'huggingface:swda',\n",
              " 'huggingface:swedish_medical_ner',\n",
              " 'huggingface:swedish_ner_corpus',\n",
              " 'huggingface:swedish_reviews',\n",
              " 'huggingface:swiss_judgment_prediction',\n",
              " 'huggingface:tab_fact',\n",
              " 'huggingface:tamilmixsentiment',\n",
              " 'huggingface:tanzil',\n",
              " 'huggingface:tapaco',\n",
              " 'huggingface:tashkeela',\n",
              " 'huggingface:taskmaster1',\n",
              " 'huggingface:taskmaster2',\n",
              " 'huggingface:taskmaster3',\n",
              " 'huggingface:tatoeba',\n",
              " 'huggingface:ted_hrlr',\n",
              " 'huggingface:ted_iwlst2013',\n",
              " 'huggingface:ted_multi',\n",
              " 'huggingface:ted_talks_iwslt',\n",
              " 'huggingface:telugu_books',\n",
              " 'huggingface:telugu_news',\n",
              " 'huggingface:tep_en_fa_para',\n",
              " 'huggingface:text2log',\n",
              " 'huggingface:textvqa',\n",
              " 'huggingface:thai_toxicity_tweet',\n",
              " 'huggingface:thainer',\n",
              " 'huggingface:thaiqa_squad',\n",
              " 'huggingface:thaisum',\n",
              " 'huggingface:the_pile',\n",
              " 'huggingface:the_pile_books3',\n",
              " 'huggingface:the_pile_openwebtext2',\n",
              " 'huggingface:the_pile_stack_exchange',\n",
              " 'huggingface:tilde_model',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "2f3b5e4f2d2c487f8601b403a54e5046",
            "035ec4218d314a3a816bef43e10adb30",
            "100fa476123b4690914b8f40bc9076dd",
            "5e133eeffbbc499fbb796dc03f9905f1",
            "0164e99fbf2f4864b9f59203a20b86d9",
            "7dae9c02ed5d4dfda1807ec70009a140",
            "c38e7e4a76ff40e6b0f2f6324b7cbcf8",
            "b6d5b3483fba4dcdafe6e122f058627d",
            "ace08c073959455db39c3d1dff17504f",
            "35cdae8482da42d5a0777113bbace3e9",
            "efbd2ca747644cea8ec4eb94d4e14473",
            "494e60d5e59c4e13831bc4746ff19f63",
            "67e568aaf2c845f88db810f917fbafa9",
            "eaf3dedb159f4efd810db4be06f976ee",
            "d191179789f345499270816f735b8055",
            "3f3c3859b12e43c789f50de56423de73",
            "1aec94e611c246aea347d251e4adb2bf",
            "c06d7c37aaa649c88d15e917596c081e",
            "cb6bace1ffa74a5fb2be91ef0b1b0ae4",
            "ba71fe83fb16495e8eb70944edc61af3",
            "7b9211dd22da4d598e145a5171220ad1",
            "aea7831a9cd24c96883bf0d382e7363b",
            "a5fc13a434ba4e6294b3d80d736078b8",
            "867450358a1a4497968787ba8cd4a218",
            "90135e82928044b2b904f8d1c9bd15ef",
            "2686ec51147948239e1d2b2f3f8e43c7",
            "0883b6428e7a48d3b461b3258ed1e0de",
            "f845de1037cc48009821e1d0868e06eb",
            "7962438b4f424dc6b3203db35f633f1a",
            "717752cbb1234ed8a59f9099d1ad6258",
            "860d4e0f3fc94909a4bad21736397ebb",
            "527a637a0c88463cb391862efb8a1f4d",
            "a970aa415afa4227b3d94c1c8643d350",
            "60df039b0ad841e1a282fe6e04006e8a",
            "564013fb25e441a1a8d70a00b5451e50",
            "ae4af8508026426cb41557a522deb22f",
            "402b2874b35248edae173377aa94e878",
            "3429c6fb197a471a915d0e1047fd9bda",
            "de17e617afd74c5caa46e2300fcac262",
            "c23052b01bb6438d815d2a49e1c57097",
            "dfc0bd5b555e485284bd2ebed47aa771",
            "c922358b4c0c4e9abb1178bb5e51f584",
            "8848b47198c74726a044de92302ebda6",
            "b87e396fddff4f3aabf51928da46c03c",
            "7068d5e63a074da1bf8c7b4d23f66fba",
            "3389572659a246239e82d45e773e5bd7",
            "3516e6604fe3492292bb102020f1eb7f",
            "3eef8027bc354923a5305a49cd4d1cd7",
            "986c7c39b237424eb934fa6e0e3492a0",
            "726eece89ddf45259ae823050e870e28",
            "e519faaf3a0f4bb98c417edf9ef5efd0",
            "824506169efe4e239a350ed38b00d81a",
            "740039be75d941f790b87c14c17d112e",
            "f186b63dd2a345468a0436edf4aa3737",
            "af98e12c6244474bbd0eb4e5986cf031",
            "5c4ac4f38c6c4183b5fad3fb1676f3fb",
            "b06aab3fb69144b0ac57fd3c1d05e873",
            "774538489a254fb99e6e94dc728e87f3",
            "e2a1771b657240868f31111309f18ccb",
            "efe61c2adf234aad8a7511a6619cbb21",
            "b5394c18dd364d638a8fc4e326b38078",
            "0a79d4fc7a0d41dd89ebe737b35d79b6",
            "96c4243121c54e3f83b28f473a6bc928",
            "c17b967c57f6411faafd5600abdbc4ae",
            "2956c78411664700881d65ef50af7202",
            "c13749e1f7854204b2d46acc8a543c48",
            "74e471e8ebc44afb9c0f96b9676e27fa",
            "2d72192c159d447190958f031032ffb3",
            "dcaae786cd954d57b812bfdd4dc37809",
            "801919a9354541b2a05a81c6192d1abf",
            "edd3df5158304ebd9f9f27fd497ffd30",
            "357b1d86b2f44bdc900220a7a0c51ed3",
            "73ccf364e1ea484288463bf9804e8906",
            "a6e61a898e52439a9ff4de087352c11f",
            "e06b1ccd4f714f5cb0417a83ccbeb23b",
            "0116b239cb4f4800a01c4541595056a2",
            "1df54ed375d14bd0b34c4d5232fbe179",
            "8de86a1a1c8044b9984c4d21699a4585",
            "0927b5fa785543c3bc2443a0653ddf28",
            "6934fa51a04746998e420153301738ba",
            "188aedf1330f46d9bf277688c9c2668f",
            "4f7235496b484afbb93469d709e6c39d",
            "56870b15e9874dda8d88c01bfc4c342b",
            "f60671fdeca14523abfbed0905c2eb92",
            "fce2256e3b0a4538915048a3b696b5b3",
            "75a17a1609d7410dbd6214a44df144a7",
            "dbb7251ba87641fb9e6377bdc3575c46",
            "7fafeea773d4497594bafb791ebdd339"
          ]
        },
        "id": "NFE4vk77bWDi",
        "outputId": "21105882-fd09-4ec9-d788-52344c16e056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f3b5e4f2d2c487f8601b403a54e5046"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "494e60d5e59c4e13831bc4746ff19f63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5fc13a434ba4e6294b3d80d736078b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60df039b0ad841e1a282fe6e04006e8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train examples...: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7068d5e63a074da1bf8c7b4d23f66fba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/oxford_iiit_pet/3.2.0.incompleteWKTUVQ/oxford_iiit_pet-train.tfrecord*...:…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c4ac4f38c6c4183b5fad3fb1676f3fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test examples...: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74e471e8ebc44afb9c0f96b9676e27fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/oxford_iiit_pet/3.2.0.incompleteWKTUVQ/oxford_iiit_pet-test.tfrecord*...: …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8de86a1a1c8044b9984c4d21699a4585"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset oxford_iiit_pet downloaded and prepared to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -= 1\n",
        "  return input_image, input_mask\n",
        "def load_image(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(\n",
        "    datapoint['segmentation_mask'],\n",
        "    (128, 128),\n",
        "    method = tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n",
        "  )\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "metadata": {
        "id": "BAReYYo7bqvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "l0UXvgzIb-JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trax.fastmath.set_backend('numpy')"
      ],
      "metadata": {
        "id": "E2ZDazIDv1cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trax.fastmath.set_backend('tensorflow-numpy')"
      ],
      "metadata": {
        "id": "JZwZUhX7Jwa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqAtvD_Xf3JK",
        "outputId": "091cf589-7428-47ae-abbf-75141982dd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='oxford_iiit_pet',\n",
            "    full_name='oxford_iiit_pet/3.2.0',\n",
            "    description=\"\"\"\n",
            "    The Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200\n",
            "    images for each class. The images have large variations in scale, pose and\n",
            "    lighting. All images have an associated ground truth annotation of breed.\n",
            "    \"\"\",\n",
            "    homepage='http://www.robots.ox.ac.uk/~vgg/data/pets/',\n",
            "    data_path='/root/tensorflow_datasets/oxford_iiit_pet/3.2.0',\n",
            "    file_format=tfrecord,\n",
            "    download_size=773.52 MiB,\n",
            "    dataset_size=774.69 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'file_name': Text(shape=(), dtype=string),\n",
            "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=int64, num_classes=37),\n",
            "        'segmentation_mask': Image(shape=(None, None, 1), dtype=uint8),\n",
            "        'species': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
            "    }),\n",
            "    supervised_keys=('image', 'label'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'test': <SplitInfo num_examples=3669, num_shards=4>,\n",
            "        'train': <SplitInfo num_examples=3680, num_shards=4>,\n",
            "    },\n",
            "    citation=\"\"\"@InProceedings{parkhi12a,\n",
            "      author       = \"Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C.~V.\",\n",
            "      title        = \"Cats and Dogs\",\n",
            "      booktitle    = \"IEEE Conference on Computer Vision and Pattern Recognition\",\n",
            "      year         = \"2012\",\n",
            "    }\"\"\",\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nnPvbIQ5hjU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's fix batch size\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "Y1GCCbZYWndF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trax import data\n",
        "\n",
        "inputs = data.inputs.Serial(\n",
        "  data.TFDS('oxford_iiit_pet:3.*.*', keys=('image', 'segmentation_mask'), train=True),\n",
        "  data.Shuffle(),\n",
        "  trax.data.Batch(batch_size),\n",
        "  lambda g: map(lambda p: (p[0].astype(np.float32), jnp.squeeze(p[1],axis=3)), g)\n",
        ")\n",
        "val=data.inputs.Serial(\n",
        "  data.tf_inputs.TFDS('oxford_iiit_pet:3.*.*', keys=('image', 'segmentation_mask'), train=False),\n",
        "  trax.data.Batch(batch_size),\n",
        "  lambda g: map(lambda p: (p[0].astype(np.float32), jnp.squeeze(p[1],axis=3)), g)\n",
        ")"
      ],
      "metadata": {
        "id": "wS2rNYpUfh45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07caca44-e57c-44ee-94f9-89f339015467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/jax/_src/xla_bridge.py:613: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDPEwPoXgQTw",
        "outputId": "e4aacf0b-a0bb-4b4c-b609-1b23d21f6cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "function"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "from PIL import Image\n",
        "from itertools import cycle\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "gvbCVfkCWd93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def color_kmean(root):\n",
        "  \"\"\" creates a k-means objects that recognizes all 13 colors of dataset. \"\"\"\n",
        "\n",
        "  # take 10 first images\n",
        "  files = os.listdir(root)[:10]\n",
        "  colors = list()\n",
        "  for f in files:\n",
        "    img = load_image(osp.join(root, f))\n",
        "    # total width\n",
        "    w = img.shape[2]\n",
        "    # get the right half of image, which is the label image\n",
        "    img = img[:, w:, :]\n",
        "    # collect all the colors present in label image\n",
        "    colors.append(img.reshape(-1, 3))\n",
        "\n",
        "  colors = np.array(colors)\n",
        "  colors = colors.reshape(-1, 3)\n",
        "\n",
        "  # finally, fit all the colors into the KMeans\n",
        "  kmeans = KMeans(13)\n",
        "  kmeans.fit(colors)\n",
        "\n",
        "  return kmeans\n",
        "\n",
        "def load_image(path):\n",
        "  \"\"\" loading an image. \"\"\"\n",
        "\n",
        "  assert osp.exists(path), path + \" not found\"\n",
        "  image = Image.open(path)\n",
        "  image = np.asarray(image)\n",
        "  return image\n",
        "\n",
        "def color2class(segs, km):\n",
        "  \"\"\"\n",
        "  given an label image, convert it to class matrix,\n",
        "  which is a 2D matrix of class labels (scalars).\n",
        "  \"\"\"\n",
        "\n",
        "  h, w, c = segs.shape\n",
        "  segs = segs.reshape((-1, 3))\n",
        "  segs = km.predict(segs)\n",
        "  segs = segs.reshape((h, w, 1))\n",
        "  return segs\n",
        "\n",
        "def load_dataset(root, km):\n",
        "  \"\"\" load dataset. \"\"\"\n",
        "  index = 0\n",
        "  imgs_path = [osp.join(root, f) for f in os.listdir(root)]\n",
        "\n",
        "  # load images one by one, finally, and image and\n",
        "  # its label matrix is returned\n",
        "  while True:\n",
        "    img = load_image(imgs_path[index])\n",
        "    w = img.shape[1] // 2\n",
        "    img, seg = img[:, :w, :], img[:, w:, :]\n",
        "\n",
        "    seg = color2class(seg, km)\n",
        "\n",
        "    seg = seg.reshape(-1)\n",
        "    assert img.shape == (256, 256, 3), img.shape\n",
        "    assert seg.shape == (256 * 256,), seg.shape\n",
        "    yield img, seg\n",
        "\n",
        "    index = (index + 1) % len(imgs_path)"
      ],
      "metadata": {
        "id": "Bebi5wnoWjr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = 'cityscapes_data'\n",
        "\n",
        "trainset_path = osp.join(root, 'train')\n",
        "valset_path = osp.join(root, 'val')\n",
        "\n",
        "km = color_kmean(trainset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoKlDr8nWoMu",
        "outputId": "1675cfe4-796c-45c1-fbb1-9ba19627dd12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = load_dataset(trainset_path, km)\n",
        "val_dataset = load_dataset(valset_path, km)\n",
        "print(type(train_dataset))\n",
        "train_transforms = trax.data.Serial(\n",
        "    trax.data.Shuffle(),\n",
        "    trax.data.Batch(batch_size),\n",
        "    lambda g: map(lambda p: (p[0].astype(np.float32), p[1]), g),\n",
        ")\n",
        "val_transforms = trax.data.Serial(\n",
        "    trax.data.Batch(batch_size),\n",
        "    lambda g: map(lambda p: (p[0].astype(np.float32), p[1]), g),\n",
        ")\n",
        "\n",
        "train_dataset = train_transforms(train_dataset)\n",
        "val_dataset = val_transforms(val_dataset)"
      ],
      "metadata": {
        "id": "f02_xak_W0Z9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a3f2dac9-95bb-4a6f-ae66-5d87efac2479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5e3f0ed40b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m train_transforms = trax.data.Serial(\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mShuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlOhAl7ZdVOg",
        "outputId": "c5ed15a6-25e5-43c3-dcf9-7d266d586a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "map"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CrossEntropy3d(criterion_2d):\n",
        "  \"\"\" returns 3D cross entropy loss function \"\"\"\n",
        "  def _loss_fn(output, target):\n",
        "    output = output.reshape(-1, 1)\n",
        "    target = target.reshape(-1,)\n",
        "    loss = criterion_2d((output, target))\n",
        "    return loss\n",
        "  return _loss_fn\n",
        "\n",
        "# check dataset\n",
        "x, y = next(train_dataset)\n",
        "print(x.shape, y.shape)\n",
        "print(x.dtype, y.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "IVJfQ-hPW3q5",
        "outputId": "c6c950e2-47f8-4d5a-8086-0fdaedf573dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0de67ed60db4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# check dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(inputs)\n",
        "print(x.shape, y.shape)\n",
        "print(x.dtype, y.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "-CiY3iENqT_B",
        "outputId": "7998b88f-1b87-4306-f4ff-85b930498e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-594c3958b6f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'function' object is not an iterator"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set learning rate\n",
        "lr = 1e-2\n",
        "\n",
        "# create new trax Fn for new loss fn, and provide it a name\n",
        "#criterion = trax.layers.base.Fn(\"CrossEntropy3d\",\n",
        "#                                CrossEntropy3d(tl.CategoryCrossEntropy())                                )\n",
        "criterion = tl.CrossEntropyLoss()\n",
        "# create TrainTask\n",
        "train_task = trax.supervised.training.TrainTask(\n",
        "    labeled_data=inputs(),\n",
        "    loss_layer=criterion,\n",
        "    optimizer=trax.optimizers.Adam(),\n",
        "    n_steps_per_checkpoint=50\n",
        ")\n",
        "\n",
        "# create EvalTask\n",
        "eval_task = trax.supervised.training.EvalTask(\n",
        "    labeled_data=val(),\n",
        "    metrics=[criterion]\n",
        ")"
      ],
      "metadata": {
        "id": "POvvkp85XE79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ConvBlock(kernel_size, filters, norm, non_linearity=tl.Relu,\n",
        "              mode='train'):\n",
        "  \"\"\"ResNet convolutional striding block.\"\"\"\n",
        "  ks = kernel_size\n",
        "  filters1, filters2, filters3 = filters\n",
        "  main = [\n",
        "      tl.Conv(filters1, (1, 1),padding='SAME'),\n",
        "      norm(mode=mode),\n",
        "      non_linearity(),\n",
        "      tl.Conv(filters2, (ks, ks), padding='SAME'),\n",
        "      norm(mode=mode),\n",
        "      non_linearity(),\n",
        "      tl.Conv(filters3, (1, 1),padding='SAME'),\n",
        "      norm(mode=mode),\n",
        "  ]\n",
        "  shortcut = [\n",
        "      tl.Conv(filters3, (1, 1)),\n",
        "      norm(mode=mode),\n",
        "  ]\n",
        "  return [\n",
        "      tl.Residual(main, shortcut=shortcut),\n",
        "      non_linearity()\n",
        "  ]"
      ],
      "metadata": {
        "id": "XpqQFstqt89q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ConvBlock(kernel_size, filters, norm, non_linearity=tl.Relu,\n",
        "              mode='train'):\n",
        "  filters1, filters2, filters3 = filters\n",
        "  return tl.Serial(\n",
        "      tl.Conv(filters1, (2, 2),padding='SAME'),\n",
        "      non_linearity(),\n",
        "      tl.Conv(filters1, (2, 2),padding='SAME'),\n",
        "      non_linearity(),\n",
        "  )"
      ],
      "metadata": {
        "id": "U-wcGYwlu9mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Unet(kernel_size, filter, norm=tl.BatchNorm, non_linearity=tl.Relu,\n",
        "              mode='train',steps=5):\n",
        "  f1=filter[steps-1]\n",
        "  f2=filter[steps-1]\n",
        "  f3=filter[steps-1]\n",
        "  filters=[f1,f2,f3]\n",
        "  if steps==1:\n",
        "    return [tl.pooling.MaxPool((2,2),padding=\"SAME\"),\n",
        "            ConvBlock(kernel_size, filters, norm, non_linearity,\n",
        "              mode='train')]\n",
        "  shortcut=None\n",
        "  return tl.Serial(tl.pooling.MaxPool((2,2),padding=\"SAME\"),\n",
        "                   ConvBlock(kernel_size, filters, norm, non_linearity,mode='train'),\n",
        "                   tl.combinators.Branch(Unet(kernel_size, filter, norm, non_linearity,mode='train',steps=steps-1),shortcut),\n",
        "                   tl.deconvolution.ConvTranspose(filter[steps-1],(2,2),padding=\"SAME\"),\n",
        "                   tl.combinators.Concatenate(n_items=2,axis=3),\n",
        "                   ConvBlock(kernel_size, filters, norm, non_linearity,mode='train'))\n"
      ],
      "metadata": {
        "id": "wUirbhmWtNdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NTY463UvgREa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tl.Serial(\n",
        "    Unet(3,[256,128,64,32,16],mode=\"train\",steps=4),\n",
        "    tl.Conv(1, (1, 1)),\n",
        "    tl.core.Softmax()\n",
        ")"
      ],
      "metadata": {
        "id": "LAfBLtqw7j5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop = trax.supervised.training.Loop(\n",
        "    model,\n",
        "    train_task,\n",
        "    eval_tasks=[eval_task],\n",
        "    output_dir=None\n",
        ")\n",
        "\n",
        "training_loop.run(500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "KS-Wt7jQXJa_",
        "outputId": "ae0c3af2-3b86-4267-f360-443db4e681a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LayerError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLayerError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e1bd48367c31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_loop = trax.supervised.training.Loop(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_task\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0meval_tasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_task\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/trax/supervised/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tasks, eval_model, eval_tasks, output_dir, checkpoint_at, checkpoint_low_metric, checkpoint_high_metric, permanent_checkpoint_at, eval_at, which_task, n_devices, random_seed, loss_chunk_size, use_memory_efficient_trainer, adasum, callbacks)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;31m# Create the optimizer for the training loss function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer_per_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;31m# Sync layers weights/state in memory effcient trainer layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/trax/supervised/training.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;31m# Create the optimizer for the training loss function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer_per_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;31m# Sync layers weights/state in memory effcient trainer layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/trax/supervised/training.py\u001b[0m in \u001b[0;36m_init_trainer\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# Build the per-task model, sharing weights with other tasks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_memory_efficient_trainer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m       model_in_training = _model_with_ends(\n\u001b[0m\u001b[1;32m    339\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m           \u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/trax/supervised/training.py\u001b[0m in \u001b[0;36m_model_with_ends\u001b[0;34m(model, end_layers, batch_signature)\u001b[0m\n\u001b[1;32m   1028\u001b[0m   \u001b[0;31m# TODO(jonni): Redo this function as part of an initialization refactor?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m   \u001b[0mmetrics_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mend_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m   \u001b[0mmetrics_input_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_input_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/trax/layers/base.py\u001b[0m in \u001b[0;36moutput_signature\u001b[0;34m(self, input_signature)\u001b[0m\n\u001b[1;32m    608\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;34m\"\"\"Returns output signature this layer would give for `input_signature`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_abstract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output only, not state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_forward_abstract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/trax/layers/base.py\u001b[0m in \u001b[0;36m_forward_abstract\u001b[0;34m(self, input_signature)\u001b[0m\n\u001b[1;32m    639\u001b[0m       \u001b[0;31m# Skipping 7 lines which are all JAX abstract'ifying wrappers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_short_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m       raise LayerError(name, '_forward_abstract', self._caller, input_signature,\n\u001b[0m\u001b[1;32m    642\u001b[0m                        trace) from None\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLayerError\u001b[0m: Exception passing through layer Serial (in _forward_abstract):\n  layer created in file [...]/<ipython-input-10-89a9bb3c670a>, line 1\n  layer input shapes: (ShapeDtype{shape:(32, 577, 800, 3), dtype:float32}, ShapeDtype{shape:(32, 577, 800), dtype:uint8})\n\nLayerError: Exception passing through layer Serial (in pure_fn):\n  layer created in file [...]/<ipython-input-10-89a9bb3c670a>, line 1\n  layer input shapes: (ShapeDtype{shape:(32, 577, 800, 3), dtype:float32}, ShapeDtype{shape:(32, 577, 800), dtype:uint8})\n\n  File [...]/trax/layers/combinators.py, line 90, in forward\n    outputs, s = layer.pure_fn(inputs, w, s, rng, use_cache=True)\n\nLayerError: Exception passing through layer Serial (in pure_fn):\n  layer created in file [...]/<ipython-input-9-8328abd6df72>, line 12\n  layer input shapes: ShapeDtype{shape:(32, 577, 800, 3), dtype:float32}\n\n  File [...]/trax/layers/combinators.py, line 90, in forward\n    outputs, s = layer.pure_fn(inputs, w, s, rng, use_cache=True)\n\nLayerError: Exception passing through layer MaxPool(2,2) (in pure_fn):\n  layer created in file [...]/<ipython-input-9-8328abd6df72>, line 12\n  layer input shapes: ShapeDtype{shape:(32, 577, 800, 3), dtype:float32}\n\n  File [...]/trax/layers/base.py, line 743, in forward\n    raw_output = self._forward_fn(inputs)\n\n  File [...]/trax/layers/base.py, line 784, in _forward\n    return f(*xs)\n\n  File [...]/trax/layers/pooling.py, line 52, in f\n    return fastmath.max_pool(\n\n  File [...]/trax/fastmath/ops.py, line 124, in max_pool\n    return backend()['max_pool'](*args, **kwargs)\n\nKeyError: 'max_pool'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3rd attempt at LSH Attention using full tensorflow"
      ],
      "metadata": {
        "id": "JYg_uh51eXMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El problema fue que trax no funcionaba eficientemente en terminos de ram, considerando la dificultad del modelo."
      ],
      "metadata": {
        "id": "TEiDid87eXMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"1KJPU1D0ewHmU7Jzl1irq3Gb-JkUqV1VR&confirm=t\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c768621-2121-46c2-b091-0defa3a68d77",
        "id": "GmzFGWeieXMb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KJPU1D0ewHmU7Jzl1irq3Gb-JkUqV1VR&confirm=t\n",
            "To: /content/input.zip\n",
            "100% 367M/367M [00:01<00:00, 203MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cerebroai/reformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ90JM8eeltk",
        "outputId": "1b973e95-ac44-4514-dd1d-722f2cec659c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'reformers'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 82 (delta 37), reused 81 (delta 36), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (82/82), 288.38 KiB | 1.72 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1PHf026eXMd"
      },
      "outputs": [],
      "source": [
        "!unzip -q input.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lNEzQAweXMe"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK_5faoyeXMe"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "from nibabel.testing import data_path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio as iio\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "import PIL\n",
        "from PIL import Image\n",
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "X=np.zeros((len(glob.glob(src+imag+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  if x!=\"/content/input/train/images/coronacases_009_149.png\":\n",
        "    im=Image.open(x)\n",
        "    X[i,:,:,0]=im.resize((IMG_WIDTH,IMG_HEIGHT),resample=PIL.Image.NEAREST)\n",
        "mas=\"/Amasks/\"\n",
        "Y=np.zeros((len(glob.glob(src+mas+\"*.png\")),IMG_WIDTH,IMG_HEIGHT))\n",
        "for i,x in enumerate(sorted(glob.glob(src+mas+\"*.png\"))):\n",
        "  if x!=\"/content/input/train/Amasks/coronacases_009_149.png\":\n",
        "    im=Image.open(x)\n",
        "    im=np.array(im.resize((IMG_WIDTH,IMG_HEIGHT),resample=PIL.Image.NEAREST))\n",
        "    im[im==85]=1\n",
        "    im[im==170]=2\n",
        "    im[im==255]=3\n",
        "    Y[i,:,:]=im\n",
        "import tensorflow as tf\n",
        "print(Y.shape)\n",
        "print(np.unique(Y))\n",
        "Y=tf.keras.utils.to_categorical(Y)\n",
        "print(Y.shape)\n",
        "print(np.unique(Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "053cc1d1-5b2c-4175-8545-490eade411b3",
        "id": "gto5csKNeXMf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3520, 128, 128)\n",
            "[0. 1. 2. 3.]\n",
            "(3520, 128, 128, 4)\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1ef477-dda7-4864-ae02-02d2ddb4f162",
        "id": "ERZvEtmleXMf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "002\n",
            "003\n",
            "004\n",
            "005\n",
            "006\n",
            "007\n",
            "008\n",
            "009\n",
            "010\n",
            "10_85902_1\n",
            "10_85902_3\n",
            "14_85914_0\n",
            "27_86410_0\n",
            "29_86490_1\n",
            "29_86491_1\n",
            "36_86526_0\n",
            "40_86625_0\n",
            "4_85506_1\n",
            "7_85703_0\n"
          ]
        }
      ],
      "source": [
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "Siz=0\n",
        "id=0\n",
        "ri=0\n",
        "metadat=[]\n",
        "c=\"001\"\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  if x.find(\"radiopaedia\") == -1:\n",
        "    x=x[x.find(\"_\")+1:]\n",
        "    x=x[:x.find(\"_\")]\n",
        "  else:\n",
        "    x=x[x.find(\"_\")+1:]\n",
        "    x=x[:x.find(\"_\",9)]\n",
        "  if c!=x:\n",
        "    print(x)\n",
        "    metadat.append([id,Siz,ri])\n",
        "    ri=i\n",
        "    c=x\n",
        "    id+=1\n",
        "    Siz=0\n",
        "  Siz+=1\n",
        "metadat.append([id,Siz,ri])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAdFTmkneXMg"
      },
      "source": [
        "##New Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b1ae30-5e4c-4f91-f192-394f61292fcc",
        "id": "bzYzhx8neXMh"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  4  5  7  8  9 11 12 13 14 15 17 18 19] [ 3  6 10 16]\n",
            "[ 0  1  3  5  6  7  8  9 10 11 12 13 15 16 18 19] [ 2  4 14 17]\n",
            "[ 2  3  4  5  6  8  9 10 11 12 14 15 16 17 18 19] [ 0  1  7 13]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 16 17] [ 9 15 18 19]\n",
            "[ 0  1  2  3  4  6  7  9 10 13 14 15 16 17 18 19] [ 5  8 11 12]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "IDX=[x for x in range(10)]\n",
        "IDY=[x for x in range(10)]\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  print(train_index, val_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1ccL2VMeXMh"
      },
      "outputs": [],
      "source": [
        "for i,x in enumerate(train_index):\n",
        "  size=metadat[x][1]\n",
        "  ri=metadat[x][2]\n",
        "  if i == 0:\n",
        "    X_train=X[ri:ri+size]\n",
        "    Y_train=Y[ri:ri+size]\n",
        "  else:\n",
        "    X_train=np.concatenate((X_train,X[ri:ri+size]),axis=0)\n",
        "    Y_train=np.concatenate((Y_train,Y[ri:ri+size]),axis=0)\n",
        "for i,x in enumerate(val_index):\n",
        "  size=metadat[x][1]\n",
        "  ri=metadat[x][2]\n",
        "  if i == 0:\n",
        "    X_test=X[ri:ri+size]\n",
        "    Y_test=Y[ri:ri+size]\n",
        "  else:\n",
        "    X_test=np.concatenate((X_test,X[ri:ri+size]),axis=0)\n",
        "    Y_test=np.concatenate((Y_test,Y[ri:ri+size]),axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHKm0Y3seXMi"
      },
      "source": [
        "##Patch wise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/reformers/reformers/TFefficient_attention.py\n",
        "\n",
        "/content/reformers/reformers/TFutils.py"
      ],
      "metadata": {
        "id": "fRKHI3AjFEN8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKZ1B8SkeXMj"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "from importlib import reload\n",
        "from reformers.reformers.TFefficient_attention import TFLSHAttention,TFLSHSelfAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyrn4jj6eXMj"
      },
      "outputs": [],
      "source": [
        "def DiceMetric(y_true, y_pred):\n",
        "  smooth=1e-6\n",
        "  gama=2\n",
        "  y_true, y_pred = tf.cast(\n",
        "      y_true, dtype=tf.float32), tf.cast(y_pred, tf.float32)\n",
        "  nominator = 2 * \\\n",
        "      tf.reduce_sum(tf.multiply(y_pred, y_true)) + smooth\n",
        "  denominator = tf.reduce_sum(\n",
        "      y_pred ** gama) + tf.reduce_sum(y_true ** gama) + smooth\n",
        "  result = tf.divide(nominator, denominator)\n",
        "  return result\n",
        "def DiceLoss(y_true, y_pred):\n",
        "      result= 1- DiceMetric(y_true, y_pred)\n",
        "      return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR65AcCGeXMk"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
        "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "  return iou\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "  union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "  dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
        "  return dice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef_multilabel(y_true, y_pred, smooth=1):\n",
        "    dice=0\n",
        "    numLabels=y_true.shape[3]\n",
        "    for index in range(numLabels):\n",
        "      #None,128,128,1\n",
        "      y_t=tf.expand_dims(y_true[:,:,:,index],axis=3)\n",
        "      #None,128,128\n",
        "      y_p=tf.expand_dims(y_pred[:,:,:,index],axis=3)\n",
        "      dice += dice_coef(y_t, y_p)\n",
        "    return dice/numLabels # taking average"
      ],
      "metadata": {
        "id": "qdlob2CGeXMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_coef_multilabel(y_true, y_pred, smooth=1):\n",
        "    dice=0\n",
        "    numLabels=y_true.shape[3]\n",
        "    for index in range(numLabels):\n",
        "      y_t=tf.expand_dims(y_true[:,:,:,index],axis=3)\n",
        "      y_p=tf.expand_dims(y_pred[:,:,:,index],axis=3)\n",
        "      dice += iou_coef(y_t, y_p)\n",
        "    return dice/numLabels # taking average"
      ],
      "metadata": {
        "id": "AqUeT46_eXMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDyPqt0XeXMk"
      },
      "outputs": [],
      "source": [
        "def conv_block(X,f,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (3, 3), kernel_initializer='he_normal', padding='same', groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  s = tf.keras.layers.Conv2D(f[1], (1, 1), kernel_initializer='he_normal', padding='same')(X)\n",
        "  s = tf.keras.layers.BatchNormalization(axis=3)(s)\n",
        "  c = tf.keras.layers.Add()([c,s])\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return c,c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "_4M3UtKSeXMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten(M):\n",
        "  shapes=M.shape\n",
        "  s1=shapes[1]\n",
        "  s2=shapes[2]\n",
        "  s3=shapes[3]\n",
        "  flat=s1*s2\n",
        "  #M= tf.reshape(M,shape=[-1,-1,s3])\n",
        "  M=tf.reshape(M,shape=[-1, s1 * s2 , s3])\n",
        "  return M,s1,s2,s3"
      ],
      "metadata": {
        "id": "J4_xXVIpeXMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten_LSH(M,N,nheads,dimk,k=128):\n",
        "  M,s1,s2,s3= Flatten(M)\n",
        "  N,_,_,_= Flatten(N)\n",
        "  pm=TFLSHAttention(dropout=0.2)(M,M)\n",
        "  pm=tf.reshape(pm,[-1,s1,s2,s3])\n",
        "  return pm"
      ],
      "metadata": {
        "id": "QyfSy65GeXMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten_LSH(M,N,nheads,dimk,k=128):\n",
        "  M,s1,s2,s3= Flatten(M)\n",
        "  N,_,_,_= Flatten(N)\n",
        "  pm=TFLSHSelfAttention(s3,heads=1,dropout=0.2,bucket_size=8,n_hashes=1)(M)\n",
        "  pm=tf.reshape(pm,[-1,s1,s2,s3])\n",
        "  return pm"
      ],
      "metadata": {
        "id": "1cY9ItBZ24VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsHTf9NKeXMm"
      },
      "outputs": [],
      "source": [
        "def vit(X,Y,n_heads=16,psize=16,k=256,dim=\"4D\"):\n",
        "  npatch=int(X.shape[1]/psize)\n",
        "  psizey=int(psize/2)\n",
        "  kdim=int(X.shape[3]/n_heads)\n",
        "  Y=tf.keras.layers.Dense(X.shape[3])(Y)\n",
        "  if npatch==0:\n",
        "    pm=Flatten_LSH(X,Y,n_heads,kdim,k)\n",
        "    return pm\n",
        "  for i in range(npatch):\n",
        "    st=i*psize\n",
        "    sty=i*psizey\n",
        "    end=st+psize\n",
        "    endy=sty+psizey\n",
        "    for j in range(npatch):\n",
        "      st2=j*psize\n",
        "      end2=st2+psize\n",
        "      sty2=j*psizey\n",
        "      endy2=sty2+psizey\n",
        "      patch= X[:,st:end,st2:end2,:]\n",
        "      patch2= Y[:,sty:endy,sty2:endy2,:]\n",
        "      pm=Flatten_LSH(patch,patch2,n_heads,kdim,k)\n",
        "      if j==0:\n",
        "        A=pm\n",
        "      else:\n",
        "        A=tf.concat([A,pm],2)\n",
        "    if i==0:\n",
        "      V=A\n",
        "    else:\n",
        "      V=tf.concat([V,A],1)\n",
        "  return V\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMJwpwC3eXMn"
      },
      "source": [
        "### Vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n965rk_jeXMn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "  nheads=4\n",
        "  sizep=32\n",
        "  gr=4\n",
        "  kval=128\n",
        "  #Build the model\n",
        "  inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),batch_size=16)\n",
        "  s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "  #s= inputs\n",
        "  #Contraction path\n",
        "  c1,z1 = conv_block(s,[16,16],group=1)\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "\n",
        "  c2,z2 = conv_block(p1,[32,32],group=gr)\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "  c3,z3 = conv_block(p2,[64,64],0.2,group=gr)\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "  c4,z4 = conv_block(p3,[128,128],0.2,group=gr)\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "  c5,z5 = conv_block(p4,[256,256],0.3,group=gr)\n",
        "\n",
        "  #Expansive path\n",
        "\n",
        "  m1= vit(z4,z5,nheads,sizep,k=kval)\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "  u6 = tf.keras.layers.concatenate([u6, m1])\n",
        "  c6,z6 = conv_block(u6,[128,128],0.2,group=gr)\n",
        "\n",
        "  m2= vit(z3,z6,nheads,sizep,k=kval)\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "  u7 = tf.keras.layers.concatenate([u7, m2])\n",
        "  c7,z7 = conv_block(u7,[64,64],0.2,group=gr)\n",
        "\n",
        "  m3= vit(z2,z7,nheads,sizep,k=kval)\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "  u8 = tf.keras.layers.concatenate([u8, m3])\n",
        "  c8,z8 = conv_block(u8,[32,32],group=gr)\n",
        "\n",
        "  m4= vit(z1,z8,nheads,sizep,k=kval)\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "  u9 = tf.keras.layers.concatenate([u9, m4], axis=3)\n",
        "  c9,_ = conv_block(u9,[16,16],group=gr)\n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(4, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',iou_coef_multilabel,dice_coef_multilabel])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSH without patches"
      ],
      "metadata": {
        "id": "NJJrRizneXMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Linformer_lay(M,nheads,k=128):\n",
        "  s1=M.shape[1]\n",
        "  s2=M.shape[2]\n",
        "  s3=M.shape[3]\n",
        "  flat=s1*s2\n",
        "  M= tf.reshape(M,[-1,flat,s3])\n",
        "  kdim=int(s3/nheads)\n",
        "  layer=trax.layers.LSHSelfAttention(n_heads=nheads,d_qk=kdim,d_v=kdim,mode=\"train\")\n",
        "  layer=trax.AsKeras(layer,batch_size=16,dtype=tf.float64)\n",
        "  pm=layer((M,M))\n",
        "  pm=tf.reshape(pm,[-1,s1,s2,s3])\n",
        "  return pm"
      ],
      "metadata": {
        "id": "RAV4Xn-LeXMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "av0CCLfBeXMo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "  nheads=16\n",
        "  sizep=32\n",
        "  gr=4\n",
        "\n",
        "  #Build the model\n",
        "  inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "  s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "  #s= inputs\n",
        "  #Contraction path\n",
        "  c1,z1 = conv_block(s,[16,16],group=1)\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "\n",
        "  c2,z2 = conv_block(p1,[32,32],group=gr)\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "  c3,z3 = conv_block(p2,[64,64],0.2,group=gr)\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "  c4,z4 = conv_block(p3,[128,128],0.2,group=gr)\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "  c5,z5 = conv_block(p4,[256,256],0.3,group=gr)\n",
        "\n",
        "  #Expansive path\n",
        "\n",
        "  m1= Linformer_lay(z4,nheads)\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "  u6 = tf.keras.layers.concatenate([u6, m1])\n",
        "  c6,z6 = conv_block(u6,[128,128],0.2,group=gr)\n",
        "\n",
        "  m2= Linformer_lay(z3,nheads)\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "  u7 = tf.keras.layers.concatenate([u7, m2])\n",
        "  c7,z7 = conv_block(u7,[64,64],0.2,group=gr)\n",
        "\n",
        "  m3= Linformer_lay(z2,nheads)\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "  u8 = tf.keras.layers.concatenate([u8, m3])\n",
        "  c8,z8 = conv_block(u8,[32,32],group=gr)\n",
        "\n",
        "  m4= Linformer_lay(z1,nheads)\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "  u9 = tf.keras.layers.concatenate([u9, m4], axis=3)\n",
        "  c9,_ = conv_block(u9,[16,16],group=gr)\n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(4, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',iou_coef_multilabel,dice_coef_multilabel])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test"
      ],
      "metadata": {
        "id": "pFrS_beyeXMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=create_model()\n",
        "model.fit(X_train,Y_train,batch_size=16,epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "86350818-9e1c-4fde-9b79-435510c99488",
        "id": "M4YmFIaOeXMo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c2b0b6d8d41f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-d86607512ff6>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m#Expansive path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mm1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnheads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msizep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m   \u001b[0mu6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mu6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-e4b144790829>\u001b[0m in \u001b[0;36mvit\u001b[0;34m(X, Y, n_heads, psize, k, dim)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnpatch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFlatten_LSH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-a7a11282a730>\u001b[0m in \u001b[0;36mFlatten_LSH\u001b[0;34m(M, N, nheads, dimk, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mpm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTFLSHAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mpm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/reformers/reformers/TFefficient_attention.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, qk, v)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcausal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melse_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'dots'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mself_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbq_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbkv_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mdots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0mself_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'self_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"tflsh_attention_1\" (type TFLSHAttention).\n\nin user code:\n\n    File \"/content/reformers/reformers/TFefficient_attention.py\", line 169, in call  *\n        dots = tf.math.multiply(dots, tf.cast(self_mask, tf.float32)) + (1-tf.cast(self_mask, tf.float32)) * (- 1e5)\n\n    ValueError: Dimensions must be equal, but are 1024 and 64 for '{{node tflsh_attention_1/Mul_3}} = Mul[T=DT_FLOAT](tflsh_attention_1/mul_2, tflsh_attention_1/Cast_2)' with input shapes: [16,32,1024,2048], [16,32,64,128].\n\n\nCall arguments received by layer \"tflsh_attention_1\" (type TFLSHAttention):\n  • qk=tf.Tensor(shape=(16, 256, 128), dtype=float32)\n  • v=tf.Tensor(shape=(16, 256, 128), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores= model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f'Score for fold {0}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400ebb13-8687-41a5-eb26-4c53075761ee",
        "id": "kf1rJgFpeXMp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 0: loss of 0.02161642350256443; accuracy of 99.28983449935913% iou_coef_multilabel of 75.75774192810059% dice_coef_multilabel of 79.42734956741333%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch size=32 k=2:\n",
        "\n",
        "Score for fold 0: loss of 0.19930902123451233; accuracy of 94.81756091117859% iou_coef_multilabel of 67.01422333717346% dice_coef_multilabel of 75.7577657699585%\n"
      ],
      "metadata": {
        "id": "ClrTYms0eXMp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umJlW5OneXMp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYmFwJH-eXMq"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Patch test 5D"
      ],
      "metadata": {
        "id": "er4ndo-5eXMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=2"
      ],
      "metadata": {
        "id": "P0drlbD7eXMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba206e9-b413-4d0c-8cd0-322bce3dfbc9",
        "id": "GQ6ZmhO7eXMq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.018923498690128326; accuracy of 99.33900833129883% iou_coef_multilabel of 76.09699368476868% dice_coef_multilabel of 79.55656051635742%\n",
            "Score for fold 2: loss of 0.02973838523030281; accuracy of 99.06825423240662% iou_coef_multilabel of 76.13354325294495% dice_coef_multilabel of 80.5853009223938%\n",
            "Score for fold 3: loss of 0.03030165657401085; accuracy of 99.11888837814331% iou_coef_multilabel of 75.47945976257324% dice_coef_multilabel of 79.76462244987488%\n",
            "Score for fold 4: loss of 0.027371248230338097; accuracy of 99.03544187545776% iou_coef_multilabel of 74.86760020256042% dice_coef_multilabel of 80.22578358650208%\n",
            "Score for fold 5: loss of 0.024255475029349327; accuracy of 99.22391176223755% iou_coef_multilabel of 75.09616017341614% dice_coef_multilabel of 78.89301180839539%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef91f29-5f9d-4d6d-ec06-7c2c39660489",
        "id": "GS_OvjO_eXMr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.01604907028377056; accuracy of 99.4849443435669% iou_coef_multilabel of 82.25744366645813% dice_coef_multilabel of 85.06359457969666%\n",
            "Score for fold 2: loss of 0.035502493381500244; accuracy of 98.98368120193481% iou_coef_multilabel of 81.15251660346985% dice_coef_multilabel of 85.50392389297485%\n",
            "Score for fold 3: loss of 0.03146236762404442; accuracy of 99.13598895072937% iou_coef_multilabel of 80.20720481872559% dice_coef_multilabel of 84.49628949165344%\n",
            "Score for fold 4: loss of 0.029628699645400047; accuracy of 98.99090528488159% iou_coef_multilabel of 80.18351197242737% dice_coef_multilabel of 85.33194661140442%\n",
            "Score for fold 5: loss of 0.025924744084477425; accuracy of 99.26274418830872% iou_coef_multilabel of 79.02063727378845% dice_coef_multilabel of 82.51100778579712%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test 1 25 epochs:\n",
        "\n",
        "Este test se diferencia de los siguientes porque la primera capa del decoder, tenia una falla en el skip connection, como lo estaba estructurando este toma key y query del output de la capa del nivel y la del anterior, pero sin darme cuenta deje esa, como dos del mismo nivel.\n",
        "\n",
        "Score for fold 1: loss of 0.01725444197654724; accuracy of 99.44809079170227% iou_coef_multilabel of 76.75567865371704% dice_coef_multilabel of 79.90655899047852%\n",
        "\n",
        "Score for fold 2: loss of 0.026257488876581192; accuracy of 99.15213584899902% iou_coef_multilabel of 77.25991010665894% dice_coef_multilabel of 81.667959690094%\n",
        "\n",
        "Score for fold 3: loss of 0.029813755303621292; accuracy of 99.0189254283905% iou_coef_multilabel of 73.47208261489868% dice_coef_multilabel of 77.98171043395996%\n",
        "\n",
        "Score for fold 4: loss of 0.028865722939372063; accuracy of 98.88771772384644% iou_coef_multilabel of 73.73278737068176% dice_coef_multilabel of 79.40745949745178%\n",
        "\n",
        "Score for fold 5: loss of 0.02384837530553341; accuracy of 99.24745559692383% iou_coef_multilabel of 72.86607623100281% dice_coef_multilabel of 76.55618190765381%\n",
        "\n",
        "test 1 50 epochs:\n",
        "\n",
        "Score for fold 1: loss of 0.01484227366745472; accuracy of 99.52776432037354% iou_coef_multilabel of 83.22951197624207% dice_coef_multilabel of 85.81125140190125%\n",
        "\n",
        "Score for fold 2: loss of 0.03430720046162605; accuracy of 99.037766456604% iou_coef_multilabel of 81.77401423454285% dice_coef_multilabel of 86.07376217842102%\n",
        "\n",
        "Score for fold 3: loss of 0.02642207406461239; accuracy of 99.15657639503479% iou_coef_multilabel of 79.4792652130127% dice_coef_multilabel of 83.80299210548401%\n",
        "\n",
        "Score for fold 4: loss of 0.03244418650865555; accuracy of 98.78917336463928% iou_coef_multilabel of 76.53632164001465% dice_coef_multilabel of 82.26258158683777%\n",
        "\n",
        "Score for fold 5: loss of 0.02530766651034355; accuracy of 99.25082325935364% iou_coef_multilabel of 77.88779139518738% dice_coef_multilabel of 81.41918778419495%\n",
        "\n",
        "test 2 25 epochs:\n",
        "Desde aqui estan los kfolds con las capas correctamente implementadas.\n",
        "\n",
        "Score for fold 1: loss of 0.015737926587462425; accuracy of 99.46310520172119% iou_coef_multilabel of 78.279709815979% dice_coef_multilabel of 81.3614547252655%\n",
        "\n",
        "Score for fold 2: loss of 0.03170934319496155; accuracy of 98.95466566085815% iou_coef_multilabel of 75.30025839805603% dice_coef_multilabel of 79.98074293136597%\n",
        "\n",
        "Score for fold 3: loss of 0.027374574914574623; accuracy of 99.1090476512909% iou_coef_multilabel of 75.07091164588928% dice_coef_multilabel of 79.41552400588989%\n",
        "\n",
        "Score for fold 4: loss of 0.03620793670415878; accuracy of 98.70395064353943% iou_coef_multilabel of 72.66994714736938% dice_coef_multilabel of 78.63662838935852%\n",
        "\n",
        "Score for fold 5: loss of 0.02868451550602913; accuracy of 99.15916919708252% iou_coef_multilabel of 77.30659246444702% dice_coef_multilabel of 80.87429404258728%\n",
        "\n",
        "test 2 50 epochs:\n",
        "\n",
        "Score for fold 1: loss of 0.017423078417778015; accuracy of 99.4379997253418% iou_coef_multilabel of 77.40354537963867% dice_coef_multilabel of 80.43342232704163%\n",
        "\n",
        "Score for fold 2: loss of 0.038378071039915085; accuracy of 98.94863367080688% iou_coef_multilabel of 79.24267053604126% dice_coef_multilabel of 83.60227346420288%\n",
        "\n",
        "Score for fold 3: loss of 0.028568308800458908; accuracy of 99.16971921920776% iou_coef_multilabel of 80.07370233535767% dice_coef_multilabel of 84.15423035621643%\n",
        "\n",
        "Score for fold 4: loss of 0.03010973334312439; accuracy of 99.00146722793579% iou_coef_multilabel of 80.8301031589508% dice_coef_multilabel of 85.89409589767456%\n",
        "\n",
        "Score for fold 5: loss of 0.02312619984149933; accuracy of 99.28799271583557% iou_coef_multilabel of 79.67525124549866% dice_coef_multilabel of 83.12292695045471%\n"
      ],
      "metadata": {
        "id": "Jm-4a_4deXMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=256"
      ],
      "metadata": {
        "id": "NOAa2N1teXMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328b22fc-64d7-4970-87da-2b9867e7d106",
        "id": "Jlf2PXaweXMs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.016601325944066048; accuracy of 99.49246644973755% iou_coef_multilabel of 80.1440417766571% dice_coef_multilabel of 82.72783160209656%\n",
            "Score for fold 2: loss of 0.02792888507246971; accuracy of 99.11463856697083% iou_coef_multilabel of 77.49691009521484% dice_coef_multilabel of 81.86010122299194%\n",
            "Score for fold 3: loss of 0.033090461045503616; accuracy of 99.0357756614685% iou_coef_multilabel of 75.54389238357544% dice_coef_multilabel of 79.85571622848511%\n",
            "Score for fold 4: loss of 0.02735254541039467; accuracy of 99.02375340461731% iou_coef_multilabel of 75.38833618164062% dice_coef_multilabel of 80.59991002082825%\n",
            "Score for fold 5: loss of 0.02401789091527462; accuracy of 99.26612973213196% iou_coef_multilabel of 76.66497826576233% dice_coef_multilabel of 80.13312816619873%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "ee163453-4cde-4531-bfef-16e685603493",
        "id": "Zcr773mheXMs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.01717947982251644; accuracy of 99.4581937789917% iou_coef_multilabel of 79.65168952941895% dice_coef_multilabel of 82.61964917182922%\n",
            "Score for fold 2: loss of 0.03299105167388916; accuracy of 99.06346797943115% iou_coef_multilabel of 78.3797025680542% dice_coef_multilabel of 82.73652791976929%\n",
            "Score for fold 3: loss of 0.034237224608659744; accuracy of 99.15516972541809% iou_coef_multilabel of 78.44327688217163% dice_coef_multilabel of 82.67260193824768%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-09b93a07fbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSH with pytorch"
      ],
      "metadata": {
        "id": "ezdGP2BEoCeN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6gdhfY6-oI67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"1KJPU1D0ewHmU7Jzl1irq3Gb-JkUqV1VR&confirm=t\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67297c62-bc7d-420e-ec5b-516b27f3731a",
        "id": "SfrddOj4oYGr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KJPU1D0ewHmU7Jzl1irq3Gb-JkUqV1VR&confirm=t\n",
            "To: /content/input.zip\n",
            "100% 367M/367M [00:06<00:00, 60.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cerebroai/reformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00fafa62-15a4-4746-d161-aeecf32abdc6",
        "id": "-qRYvKZpoYGt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'reformers'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 82 (delta 37), reused 81 (delta 36), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (82/82), 288.38 KiB | 1007.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-upSL77oYGt"
      },
      "outputs": [],
      "source": [
        "!unzip -q input.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkX7VBeEoYGt"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WonpF0USoYGu"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "from nibabel.testing import data_path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio as iio\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "import PIL\n",
        "from PIL import Image\n",
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "X=np.zeros((len(glob.glob(src+imag+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  if x!=\"/content/input/train/images/coronacases_009_149.png\":\n",
        "    im=Image.open(x)\n",
        "    X[i,:,:,0]=im.resize((IMG_WIDTH,IMG_HEIGHT),resample=PIL.Image.NEAREST)\n",
        "mas=\"/Amasks/\"\n",
        "Y=np.zeros((len(glob.glob(src+mas+\"*.png\")),IMG_WIDTH,IMG_HEIGHT))\n",
        "for i,x in enumerate(sorted(glob.glob(src+mas+\"*.png\"))):\n",
        "  if x!=\"/content/input/train/Amasks/coronacases_009_149.png\":\n",
        "    im=Image.open(x)\n",
        "    im=np.array(im.resize((IMG_WIDTH,IMG_HEIGHT),resample=PIL.Image.NEAREST))\n",
        "    im[im==85]=1\n",
        "    im[im==170]=2\n",
        "    im[im==255]=3\n",
        "    Y[i,:,:]=im\n",
        "import tensorflow as tf\n",
        "print(Y.shape)\n",
        "print(np.unique(Y))\n",
        "Y=tf.keras.utils.to_categorical(Y)\n",
        "print(Y.shape)\n",
        "print(np.unique(Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7576260d-faa9-4e42-f446-9283585070f8",
        "id": "h36fUK_noYGu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3520, 128, 128)\n",
            "[0. 1. 2. 3.]\n",
            "(3520, 128, 128, 4)\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ff919e-2823-4cd6-9069-f9a5a65df4fc",
        "id": "5TzFFlwPoYGv"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "002\n",
            "003\n",
            "004\n",
            "005\n",
            "006\n",
            "007\n",
            "008\n",
            "009\n",
            "010\n",
            "10_85902_1\n",
            "10_85902_3\n",
            "14_85914_0\n",
            "27_86410_0\n",
            "29_86490_1\n",
            "29_86491_1\n",
            "36_86526_0\n",
            "40_86625_0\n",
            "4_85506_1\n",
            "7_85703_0\n"
          ]
        }
      ],
      "source": [
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "Siz=0\n",
        "id=0\n",
        "ri=0\n",
        "metadat=[]\n",
        "c=\"001\"\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  if x.find(\"radiopaedia\") == -1:\n",
        "    x=x[x.find(\"_\")+1:]\n",
        "    x=x[:x.find(\"_\")]\n",
        "  else:\n",
        "    x=x[x.find(\"_\")+1:]\n",
        "    x=x[:x.find(\"_\",9)]\n",
        "  if c!=x:\n",
        "    print(x)\n",
        "    metadat.append([id,Siz,ri])\n",
        "    ri=i\n",
        "    c=x\n",
        "    id+=1\n",
        "    Siz=0\n",
        "  Siz+=1\n",
        "metadat.append([id,Siz,ri])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC6MvoBIoYGv"
      },
      "source": [
        "##New Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445a7a32-33ad-4178-b495-7bc0f5d12966",
        "id": "SqUu_6P7oYGw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  4  5  7  8  9 11 12 13 14 15 17 18 19] [ 3  6 10 16]\n",
            "[ 0  1  3  5  6  7  8  9 10 11 12 13 15 16 18 19] [ 2  4 14 17]\n",
            "[ 2  3  4  5  6  8  9 10 11 12 14 15 16 17 18 19] [ 0  1  7 13]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 16 17] [ 9 15 18 19]\n",
            "[ 0  1  2  3  4  6  7  9 10 13 14 15 16 17 18 19] [ 5  8 11 12]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "IDX=[x for x in range(10)]\n",
        "IDY=[x for x in range(10)]\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  print(train_index, val_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDNswDFMoYGw"
      },
      "outputs": [],
      "source": [
        "for i,x in enumerate(train_index):\n",
        "  size=metadat[x][1]\n",
        "  ri=metadat[x][2]\n",
        "  if i == 0:\n",
        "    X_train=X[ri:ri+size]\n",
        "    Y_train=Y[ri:ri+size]\n",
        "  else:\n",
        "    X_train=np.concatenate((X_train,X[ri:ri+size]),axis=0)\n",
        "    Y_train=np.concatenate((Y_train,Y[ri:ri+size]),axis=0)\n",
        "for i,x in enumerate(val_index):\n",
        "  size=metadat[x][1]\n",
        "  ri=metadat[x][2]\n",
        "  if i == 0:\n",
        "    X_test=X[ri:ri+size]\n",
        "    Y_test=Y[ri:ri+size]\n",
        "  else:\n",
        "    X_test=np.concatenate((X_test,X[ri:ri+size]),axis=0)\n",
        "    Y_test=np.concatenate((Y_test,Y[ri:ri+size]),axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unet Base"
      ],
      "metadata": {
        "id": "113BUFAeoZd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        features = init_features\n",
        "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(\n",
        "            features * 16, features * 8, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
        "        self.upconv3 = nn.ConvTranspose2d(\n",
        "            features * 8, features * 4, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
        "        self.upconv2 = nn.ConvTranspose2d(\n",
        "            features * 4, features * 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
        "        self.upconv1 = nn.ConvTranspose2d(\n",
        "            features * 2, features, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
        "\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "        enc4 = self.encoder4(self.pool3(enc3))\n",
        "\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "        return torch.sigmoid(self.conv(dec1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )"
      ],
      "metadata": {
        "id": "haNtr0LboaEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSH attention with no attention between chunks as keras multihead subclass"
      ],
      "metadata": {
        "id": "Qbiwq0rKHdag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"1KJPU1D0ewHmU7Jzl1irq3Gb-JkUqV1VR&confirm=t\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f1d99b-b6b2-43ce-cd75-d11066fc03e4",
        "id": "a-BX8SLoI2Wu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KJPU1D0ewHmU7Jzl1irq3Gb-JkUqV1VR&confirm=t\n",
            "To: /content/input.zip\n",
            "100% 367M/367M [00:04<00:00, 74.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex0pbxLdI2Ww"
      },
      "outputs": [],
      "source": [
        "!unzip -q input.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8ZAoQWII2Ww"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtw5FDriI2Wx"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "from nibabel.testing import data_path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio as iio\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "import PIL\n",
        "from PIL import Image\n",
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "X=np.zeros((len(glob.glob(src+imag+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  if x!=\"/content/input/train/images/coronacases_009_149.png\":\n",
        "    im=Image.open(x)\n",
        "    X[i,:,:,0]=im.resize((IMG_WIDTH,IMG_HEIGHT),resample=PIL.Image.NEAREST)\n",
        "mas=\"/Amasks/\"\n",
        "Y=np.zeros((len(glob.glob(src+mas+\"*.png\")),IMG_WIDTH,IMG_HEIGHT))\n",
        "for i,x in enumerate(sorted(glob.glob(src+mas+\"*.png\"))):\n",
        "  if x!=\"/content/input/train/Amasks/coronacases_009_149.png\":\n",
        "    im=Image.open(x)\n",
        "    im=np.array(im.resize((IMG_WIDTH,IMG_HEIGHT),resample=PIL.Image.NEAREST))\n",
        "    im[im==85]=1\n",
        "    im[im==170]=2\n",
        "    im[im==255]=3\n",
        "    Y[i,:,:]=im\n",
        "import tensorflow as tf\n",
        "print(Y.shape)\n",
        "print(np.unique(Y))\n",
        "Y=tf.keras.utils.to_categorical(Y)\n",
        "print(Y.shape)\n",
        "print(np.unique(Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e72c877-0735-4760-8b04-e86077009f42",
        "id": "mu5trMBgI2Wx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3520, 128, 128)\n",
            "[0. 1. 2. 3.]\n",
            "(3520, 128, 128, 4)\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea1c05e-f853-41fc-f235-49cd07199068",
        "id": "XsDeC0BxI2Wy"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "002\n",
            "003\n",
            "004\n",
            "005\n",
            "006\n",
            "007\n",
            "008\n",
            "009\n",
            "010\n",
            "10_85902_1\n",
            "10_85902_3\n",
            "14_85914_0\n",
            "27_86410_0\n",
            "29_86490_1\n",
            "29_86491_1\n",
            "36_86526_0\n",
            "40_86625_0\n",
            "4_85506_1\n",
            "7_85703_0\n"
          ]
        }
      ],
      "source": [
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "Siz=0\n",
        "id=0\n",
        "ri=0\n",
        "metadat=[]\n",
        "c=\"001\"\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  if x.find(\"radiopaedia\") == -1:\n",
        "    x=x[x.find(\"_\")+1:]\n",
        "    x=x[:x.find(\"_\")]\n",
        "  else:\n",
        "    x=x[x.find(\"_\")+1:]\n",
        "    x=x[:x.find(\"_\",9)]\n",
        "  if c!=x:\n",
        "    print(x)\n",
        "    metadat.append([id,Siz,ri])\n",
        "    ri=i\n",
        "    c=x\n",
        "    id+=1\n",
        "    Siz=0\n",
        "  Siz+=1\n",
        "metadat.append([id,Siz,ri])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqn8h312I2Wz"
      },
      "source": [
        "##New Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90dd5890-45e4-4458-e8bd-7a783af73e3a",
        "id": "L4YXvn3tI2Wz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  4  5  7  8  9 11 12 13 14 15 17 18 19] [ 3  6 10 16]\n",
            "[ 0  1  3  5  6  7  8  9 10 11 12 13 15 16 18 19] [ 2  4 14 17]\n",
            "[ 2  3  4  5  6  8  9 10 11 12 14 15 16 17 18 19] [ 0  1  7 13]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 16 17] [ 9 15 18 19]\n",
            "[ 0  1  2  3  4  6  7  9 10 13 14 15 16 17 18 19] [ 5  8 11 12]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "IDX=[x for x in range(10)]\n",
        "IDY=[x for x in range(10)]\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  print(train_index, val_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU8hWheeI2W0"
      },
      "outputs": [],
      "source": [
        "for i,x in enumerate(train_index):\n",
        "  size=metadat[x][1]\n",
        "  ri=metadat[x][2]\n",
        "  if i == 0:\n",
        "    X_train=X[ri:ri+size]\n",
        "    Y_train=Y[ri:ri+size]\n",
        "  else:\n",
        "    X_train=np.concatenate((X_train,X[ri:ri+size]),axis=0)\n",
        "    Y_train=np.concatenate((Y_train,Y[ri:ri+size]),axis=0)\n",
        "for i,x in enumerate(val_index):\n",
        "  size=metadat[x][1]\n",
        "  ri=metadat[x][2]\n",
        "  if i == 0:\n",
        "    X_test=X[ri:ri+size]\n",
        "    Y_test=Y[ri:ri+size]\n",
        "  else:\n",
        "    X_test=np.concatenate((X_test,X[ri:ri+size]),axis=0)\n",
        "    Y_test=np.concatenate((Y_test,Y[ri:ri+size]),axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSH Attention init"
      ],
      "metadata": {
        "id": "-hiaYo2eJJHY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHlvgwPMrBYF"
      },
      "outputs": [],
      "source": [
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Keras-based multi-head attention layer.\"\"\"\n",
        "\n",
        "\n",
        "import collections\n",
        "import math\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import constraints\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras.engine.base_layer import Layer\n",
        "from keras.layers import activation\n",
        "from keras.layers import core\n",
        "from keras.layers import regularization\n",
        "from keras.utils import tf_utils\n",
        "\n",
        "# isort: off\n",
        "from tensorflow.python.platform import tf_logging as logging\n",
        "from tensorflow.python.util.tf_export import keras_export\n",
        "\n",
        "_CHR_IDX = string.ascii_lowercase\n",
        "\n",
        "def _build_attention_equation(rank, attn_axes):\n",
        "    \"\"\"Builds einsum equations for the attention computation.\n",
        "    Query, key, value inputs after projection are expected to have the shape as:\n",
        "    `(bs, <non-attention dims>, <attention dims>, num_heads, channels)`.\n",
        "    `bs` and `<non-attention dims>` are treated as `<batch dims>`.\n",
        "    The attention operations can be generalized:\n",
        "    (1) Query-key dot product:\n",
        "    `(<batch dims>, <query attention dims>, num_heads, channels), (<batch dims>,\n",
        "    <key attention dims>, num_heads, channels) -> (<batch dims>,\n",
        "    num_heads, <query attention dims>, <key attention dims>)`\n",
        "    (2) Combination:\n",
        "    `(<batch dims>, num_heads, <query attention dims>, <key attention dims>),\n",
        "    (<batch dims>, <value attention dims>, num_heads, channels) -> (<batch\n",
        "    dims>, <query attention dims>, num_heads, channels)`\n",
        "    Args:\n",
        "      rank: Rank of query, key, value tensors.\n",
        "      attn_axes: List/tuple of axes, `[-1, rank)`,\n",
        "        that attention will be applied to.\n",
        "    Returns:\n",
        "      Einsum equations.\n",
        "    \"\"\"\n",
        "    target_notation = _CHR_IDX[:rank]\n",
        "    # `batch_dims` includes the head dim.\n",
        "    batch_dims = tuple(np.delete(range(rank), attn_axes + (rank - 1,)))\n",
        "    letter_offset = rank\n",
        "    source_notation = \"\"\n",
        "    for i in range(rank):\n",
        "        if i in batch_dims or i == rank - 1:\n",
        "            source_notation += target_notation[i]\n",
        "        else:\n",
        "            source_notation += _CHR_IDX[letter_offset]\n",
        "            letter_offset += 1\n",
        "\n",
        "    product_notation = \"\".join(\n",
        "        [target_notation[i] for i in batch_dims]\n",
        "        + [target_notation[i] for i in attn_axes]\n",
        "        + [source_notation[i] for i in attn_axes]\n",
        "    )\n",
        "    dot_product_equation = \"%s,%s->%s\" % (\n",
        "        source_notation,\n",
        "        target_notation,\n",
        "        product_notation,\n",
        "    )\n",
        "    attn_scores_rank = len(product_notation)\n",
        "    combine_equation = \"%s,%s->%s\" % (\n",
        "        product_notation,\n",
        "        source_notation,\n",
        "        target_notation,\n",
        "    )\n",
        "    return dot_product_equation, combine_equation, attn_scores_rank\n",
        "\n",
        "\n",
        "def _build_proj_equation(free_dims, bound_dims, output_dims):\n",
        "    \"\"\"Builds an einsum equation for projections inside multi-head attention.\"\"\"\n",
        "    input_str = \"\"\n",
        "    kernel_str = \"\"\n",
        "    output_str = \"\"\n",
        "    bias_axes = \"\"\n",
        "    letter_offset = 0\n",
        "    for i in range(free_dims):\n",
        "        char = _CHR_IDX[i + letter_offset]\n",
        "        input_str += char\n",
        "        output_str += char\n",
        "\n",
        "    letter_offset += free_dims\n",
        "    for i in range(bound_dims):\n",
        "        char = _CHR_IDX[i + letter_offset]\n",
        "        input_str += char\n",
        "        kernel_str += char\n",
        "\n",
        "    letter_offset += bound_dims\n",
        "    for i in range(output_dims):\n",
        "        char = _CHR_IDX[i + letter_offset]\n",
        "        kernel_str += char\n",
        "        output_str += char\n",
        "        bias_axes += char\n",
        "    equation = f\"{input_str},{kernel_str}->{output_str}\"\n",
        "    return equation, bias_axes, len(output_str)\n",
        "\n",
        "\n",
        "def _get_output_shape(output_rank, known_last_dims):\n",
        "    return [None] * (output_rank - len(known_last_dims)) + list(known_last_dims)\n",
        "\n",
        "class Linformer(Layer):\n",
        "    \"\"\"MultiHeadAttention layer.\n",
        "    This is an implementation of multi-headed attention as described in the\n",
        "    paper \"Attention is all you Need\" (Vaswani et al., 2017).\n",
        "    If `query`, `key,` `value` are the same, then\n",
        "    this is self-attention. Each timestep in `query` attends to the\n",
        "    corresponding sequence in `key`, and returns a fixed-width vector.\n",
        "    This layer first projects `query`, `key` and `value`. These are\n",
        "    (effectively) a list of tensors of length `num_attention_heads`, where the\n",
        "    corresponding shapes are `(batch_size, <query dimensions>, key_dim)`,\n",
        "    `(batch_size, <key/value dimensions>, key_dim)`,\n",
        "    `(batch_size, <key/value dimensions>, value_dim)`.\n",
        "    Then, the query and key tensors are dot-producted and scaled. These are\n",
        "    softmaxed to obtain attention probabilities. The value tensors are then\n",
        "    interpolated by these probabilities, then concatenated back to a single\n",
        "    tensor.\n",
        "    Finally, the result tensor with the last dimension as value_dim can take an\n",
        "    linear projection and return.\n",
        "    When using `MultiHeadAttention` inside a custom layer, the custom layer must\n",
        "    implement its own `build()` method and call `MultiHeadAttention`'s\n",
        "    `_build_from_signature()` there.\n",
        "    This enables weights to be restored correctly when the model is loaded.\n",
        "    Examples:\n",
        "    Performs 1D cross-attention over two sequence inputs with an attention mask.\n",
        "    Returns the additional attention weights over heads.\n",
        "    >>> layer = MultiHeadAttention(num_heads=2, key_dim=2)\n",
        "    >>> target = tf.keras.Input(shape=[8, 16])\n",
        "    >>> source = tf.keras.Input(shape=[4, 16])\n",
        "    >>> output_tensor, weights = layer(target, source,\n",
        "    ...                                return_attention_scores=True)\n",
        "    >>> print(output_tensor.shape)\n",
        "    (None, 8, 16)\n",
        "    >>> print(weights.shape)\n",
        "    (None, 2, 8, 4)\n",
        "    Performs 2D self-attention over a 5D input tensor on axes 2 and 3.\n",
        "    >>> layer = MultiHeadAttention(\n",
        "    ...     num_heads=2, key_dim=2, attention_axes=(2, 3))\n",
        "    >>> input_tensor = tf.keras.Input(shape=[5, 3, 4, 16])\n",
        "    >>> output_tensor = layer(input_tensor, input_tensor)\n",
        "    >>> print(output_tensor.shape)\n",
        "    (None, 5, 3, 4, 16)\n",
        "    Args:\n",
        "      num_heads: Number of attention heads.\n",
        "      key_dim: Size of each attention head for query and key.\n",
        "      value_dim: Size of each attention head for value.\n",
        "      dropout: Dropout probability.\n",
        "      use_bias: Boolean, whether the dense layers use bias vectors/matrices.\n",
        "      output_shape: The expected shape of an output tensor, besides the batch\n",
        "        and sequence dims. If not specified, projects back to the key feature\n",
        "        dim.\n",
        "      attention_axes: axes over which the attention is applied. `None` means\n",
        "        attention over all axes, but batch, heads, and features.\n",
        "      kernel_initializer: Initializer for dense layer kernels.\n",
        "      bias_initializer: Initializer for dense layer biases.\n",
        "      kernel_regularizer: Regularizer for dense layer kernels.\n",
        "      bias_regularizer: Regularizer for dense layer biases.\n",
        "      activity_regularizer: Regularizer for dense layer activity.\n",
        "      kernel_constraint: Constraint for dense layer kernels.\n",
        "      bias_constraint: Constraint for dense layer kernels.\n",
        "    Call arguments:\n",
        "      query: Query `Tensor` of shape `(B, T, dim)`.\n",
        "      value: Value `Tensor` of shape `(B, S, dim)`.\n",
        "      key: Optional key `Tensor` of shape `(B, S, dim)`. If not given, will use\n",
        "        `value` for both `key` and `value`, which is the most common case.\n",
        "      attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n",
        "        attention to certain positions. The boolean mask specifies which query\n",
        "        elements can attend to which key elements, 1 indicates attention and 0\n",
        "        indicates no attention. Broadcasting can happen for the missing batch\n",
        "        dimensions and the head dimension.\n",
        "      return_attention_scores: A boolean to indicate whether the output should\n",
        "        be `(attention_output, attention_scores)` if `True`, or\n",
        "        `attention_output` if `False`. Defaults to `False`.\n",
        "      training: Python boolean indicating whether the layer should behave in\n",
        "        training mode (adding dropout) or in inference mode (no dropout).\n",
        "        Defaults to either using the training mode of the parent layer/model,\n",
        "        or False (inference) if there is no parent layer.\n",
        "      use_causal_mask: A boolean to indicate whether to apply a causal mask to\n",
        "        prevent tokens from attending to future tokens (e.g., used in a decoder\n",
        "        Transformer).\n",
        "    Returns:\n",
        "      attention_output: The result of the computation, of shape `(B, T, E)`,\n",
        "        where `T` is for target sequence shapes and `E` is the query input last\n",
        "        dimension if `output_shape` is `None`. Otherwise, the multi-head outputs\n",
        "        are projected to the shape specified by `output_shape`.\n",
        "      attention_scores: [Optional] multi-head attention coefficients over\n",
        "        attention axes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_heads,\n",
        "        key_dim,\n",
        "        value_dim=None,\n",
        "        dropout=0.0,\n",
        "        use_bias=True,\n",
        "        output_shape=None,\n",
        "        attention_axes=None,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None,\n",
        "        k_value=32,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self._num_heads = num_heads\n",
        "        self._key_dim = key_dim\n",
        "        self._value_dim = value_dim if value_dim else key_dim\n",
        "        self._dropout = dropout\n",
        "        self._use_bias = use_bias\n",
        "        self.k_value = k_value\n",
        "        self._output_shape = output_shape\n",
        "        self._kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self._bias_initializer = initializers.get(bias_initializer)\n",
        "        self._kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self._bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self._activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self._kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self._bias_constraint = constraints.get(bias_constraint)\n",
        "        if attention_axes is not None and not isinstance(\n",
        "            attention_axes, collections.abc.Sized\n",
        "        ):\n",
        "            self._attention_axes = (attention_axes,)\n",
        "        else:\n",
        "            self._attention_axes = attention_axes\n",
        "        self._built_from_signature = False\n",
        "        self._query_shape, self._key_shape, self._value_shape = None, None, None\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"num_heads\": self._num_heads,\n",
        "            \"key_dim\": self._key_dim,\n",
        "            \"value_dim\": self._value_dim,\n",
        "            \"dropout\": self._dropout,\n",
        "            \"use_bias\": self._use_bias,\n",
        "            \"output_shape\": self._output_shape,\n",
        "            \"attention_axes\": self._attention_axes,\n",
        "            \"kernel_initializer\": initializers.serialize(\n",
        "                self._kernel_initializer\n",
        "            ),\n",
        "            \"bias_initializer\": initializers.serialize(self._bias_initializer),\n",
        "            \"kernel_regularizer\": regularizers.serialize(\n",
        "                self._kernel_regularizer\n",
        "            ),\n",
        "            \"bias_regularizer\": regularizers.serialize(self._bias_regularizer),\n",
        "            \"activity_regularizer\": regularizers.serialize(\n",
        "                self._activity_regularizer\n",
        "            ),\n",
        "            \"kernel_constraint\": constraints.serialize(self._kernel_constraint),\n",
        "            \"bias_constraint\": constraints.serialize(self._bias_constraint),\n",
        "            \"query_shape\": self._query_shape,\n",
        "            \"key_shape\": self._key_shape,\n",
        "            \"value_shape\": self._value_shape,\n",
        "        }\n",
        "        base_config = super().get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        # If the layer has a different build() function from the Keras default,\n",
        "        # we need to trigger the customized build to create weights.\n",
        "        query_shape = config.pop(\"query_shape\")\n",
        "        key_shape = config.pop(\"key_shape\")\n",
        "        value_shape = config.pop(\"value_shape\")\n",
        "        layer = cls(**config)\n",
        "        if None in [query_shape, key_shape, value_shape]:\n",
        "            logging.warning(\n",
        "                \"One of dimensions of the input shape is missing. It \"\n",
        "                \"should have been memorized when the layer was serialized. \"\n",
        "                \"%s is created without weights.\",\n",
        "                str(cls),\n",
        "            )\n",
        "        else:\n",
        "            layer._build_from_signature(query_shape, value_shape, key_shape)\n",
        "        return layer\n",
        "\n",
        "    def _build_from_signature(self, query, value, key=None):\n",
        "        \"\"\"Builds layers and variables.\n",
        "        Once the method is called, self._built_from_signature will be set to\n",
        "        True.\n",
        "        Args:\n",
        "          query: Query tensor or TensorShape.\n",
        "          value: Value tensor or TensorShape.\n",
        "          key: Key tensor or TensorShape.\n",
        "        \"\"\"\n",
        "        self._built_from_signature = True\n",
        "        if hasattr(query, \"shape\"):\n",
        "            self._query_shape = tf.TensorShape(query.shape)\n",
        "        else:\n",
        "            self._query_shape = tf.TensorShape(query)\n",
        "        if hasattr(value, \"shape\"):\n",
        "            self._value_shape = tf.TensorShape(value.shape)\n",
        "        else:\n",
        "            self._value_shape = tf.TensorShape(value)\n",
        "        if key is None:\n",
        "            self._key_shape = self._value_shape\n",
        "        elif hasattr(key, \"shape\"):\n",
        "            self._key_shape = tf.TensorShape(key.shape)\n",
        "        else:\n",
        "            self._key_shape = tf.TensorShape(key)\n",
        "\n",
        "        # Any setup work performed only once should happen in an `init_scope`\n",
        "        # to avoid creating symbolic Tensors that will later pollute any eager\n",
        "        # operations.\n",
        "        with tf_utils.maybe_init_scope(self):\n",
        "            free_dims = self._query_shape.rank - 1\n",
        "            einsum_equation, bias_axes, output_rank = _build_proj_equation(\n",
        "                free_dims, bound_dims=1, output_dims=2\n",
        "            )\n",
        "            self._query_dense = core.EinsumDense(\n",
        "                einsum_equation,\n",
        "                output_shape=_get_output_shape(\n",
        "                    output_rank - 1, [self._num_heads, self._key_dim]\n",
        "                ),\n",
        "                bias_axes=bias_axes if self._use_bias else None,\n",
        "                name=\"query\",\n",
        "                **self._get_common_kwargs_for_sublayer(),\n",
        "            )\n",
        "            einsum_equation, bias_axes, output_rank = _build_proj_equation(\n",
        "                self._key_shape.rank - 1, bound_dims=1, output_dims=2\n",
        "            )\n",
        "            self._key_dense = core.EinsumDense(\n",
        "                einsum_equation,\n",
        "                output_shape=_get_output_shape(\n",
        "                    output_rank - 1, [self._num_heads, self._key_dim]\n",
        "                ),\n",
        "                bias_axes=bias_axes if self._use_bias else None,\n",
        "                name=\"key\",\n",
        "                **self._get_common_kwargs_for_sublayer(),\n",
        "            )\n",
        "            self._proj=tf.keras.layers.EinsumDense(\"bjhd,kj->bkhd\",output_shape=(self.k_value,None,None))\n",
        "\n",
        "            einsum_equation, bias_axes, output_rank = _build_proj_equation(\n",
        "                self._value_shape.rank - 1, bound_dims=1, output_dims=2\n",
        "            )\n",
        "            self._value_dense = core.EinsumDense(\n",
        "                einsum_equation,\n",
        "                output_shape=_get_output_shape(\n",
        "                    output_rank - 1, [self._num_heads, self._value_dim]\n",
        "                ),\n",
        "                bias_axes=bias_axes if self._use_bias else None,\n",
        "                name=\"value\",\n",
        "                **self._get_common_kwargs_for_sublayer(),\n",
        "            )\n",
        "\n",
        "            # Builds the attention computations for multi-head dot product\n",
        "            # attention.  These computations could be wrapped into the keras\n",
        "            # attention layer once it supports mult-head einsum computations.\n",
        "            self._build_attention(output_rank)\n",
        "            self._output_dense = self._make_output_dense(\n",
        "                free_dims,\n",
        "                self._get_common_kwargs_for_sublayer(),\n",
        "                \"attention_output\",\n",
        "            )\n",
        "\n",
        "    def _get_common_kwargs_for_sublayer(self):\n",
        "        common_kwargs = dict(\n",
        "            kernel_regularizer=self._kernel_regularizer,\n",
        "            bias_regularizer=self._bias_regularizer,\n",
        "            activity_regularizer=self._activity_regularizer,\n",
        "            kernel_constraint=self._kernel_constraint,\n",
        "            bias_constraint=self._bias_constraint,\n",
        "        )\n",
        "        # Create new clone of kernel/bias initializer, so that we don't reuse\n",
        "        # the initializer instance, which could lead to same init value since\n",
        "        # initializer is stateless.\n",
        "        kernel_initializer = self._kernel_initializer.__class__.from_config(\n",
        "            self._kernel_initializer.get_config()\n",
        "        )\n",
        "        bias_initializer = self._bias_initializer.__class__.from_config(\n",
        "            self._bias_initializer.get_config()\n",
        "        )\n",
        "        common_kwargs[\"kernel_initializer\"] = kernel_initializer\n",
        "        common_kwargs[\"bias_initializer\"] = bias_initializer\n",
        "        return common_kwargs\n",
        "\n",
        "    def _make_output_dense(self, free_dims, common_kwargs, name=None):\n",
        "        \"\"\"Builds the output projection matrix.\n",
        "        Args:\n",
        "          free_dims: Number of free dimensions for einsum equation building.\n",
        "          common_kwargs: Common keyword arguments for einsum layer.\n",
        "          name: Name for the projection layer.\n",
        "        Returns:\n",
        "          Projection layer.\n",
        "        \"\"\"\n",
        "        if self._output_shape:\n",
        "            if not isinstance(self._output_shape, collections.abc.Sized):\n",
        "                output_shape = [self._output_shape]\n",
        "            else:\n",
        "                output_shape = self._output_shape\n",
        "        else:\n",
        "            output_shape = [self._query_shape[-1]]\n",
        "        einsum_equation, bias_axes, output_rank = _build_proj_equation(\n",
        "            free_dims, bound_dims=2, output_dims=len(output_shape)\n",
        "        )\n",
        "        return core.EinsumDense(\n",
        "            einsum_equation,\n",
        "            output_shape=_get_output_shape(output_rank - 1, output_shape),\n",
        "            bias_axes=bias_axes if self._use_bias else None,\n",
        "            name=name,\n",
        "            **common_kwargs,\n",
        "        )\n",
        "\n",
        "    def _build_attention(self, rank):\n",
        "        \"\"\"Builds multi-head dot-product attention computations.\n",
        "        This function builds attributes necessary for `_compute_attention` to\n",
        "        customize attention computation to replace the default dot-product\n",
        "        attention.\n",
        "        Args:\n",
        "          rank: the rank of query, key, value tensors.\n",
        "        \"\"\"\n",
        "        if self._attention_axes is None:\n",
        "            self._attention_axes = tuple(range(1, rank - 2))\n",
        "        else:\n",
        "            self._attention_axes = tuple(self._attention_axes)\n",
        "        (\n",
        "            self._dot_product_equation,\n",
        "            self._combine_equation,\n",
        "            attn_scores_rank,\n",
        "        ) = _build_attention_equation(rank, attn_axes=self._attention_axes)\n",
        "        norm_axes = tuple(\n",
        "            range(\n",
        "                attn_scores_rank - len(self._attention_axes), attn_scores_rank\n",
        "            )\n",
        "        )\n",
        "        self._softmax = activation.Softmax(axis=norm_axes)\n",
        "        self._dropout_layer = regularization.Dropout(rate=self._dropout)\n",
        "\n",
        "    def _masked_softmax(self, attention_scores, attention_mask=None):\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        # `attention_scores` = [B, N, T, S]\n",
        "        if attention_mask is not None:\n",
        "            # The expand dim happens starting from the `num_heads` dimension,\n",
        "            # (<batch_dims>, num_heads, <query_attention_dims,\n",
        "            # key_attention_dims>)\n",
        "            mask_expansion_axis = -len(self._attention_axes) * 2 - 1\n",
        "            for _ in range(\n",
        "                len(attention_scores.shape) - len(attention_mask.shape)\n",
        "            ):\n",
        "                attention_mask = tf.expand_dims(\n",
        "                    attention_mask, axis=mask_expansion_axis\n",
        "                )\n",
        "        return self._softmax(attention_scores, attention_mask)\n",
        "\n",
        "    def _compute_attention(\n",
        "        self, query, key, value, attention_mask=None, training=None\n",
        "    ):\n",
        "        \"\"\"Applies Dot-product attention with query, key, value tensors.\n",
        "        This function defines the computation inside `call` with projected\n",
        "        multi-head Q, K, V inputs. Users can override this function for\n",
        "        customized attention implementation.\n",
        "        Args:\n",
        "          query: Projected query `Tensor` of shape `(B, T, N, key_dim)`.\n",
        "          key: Projected key `Tensor` of shape `(B, S, N, key_dim)`.\n",
        "          value: Projected value `Tensor` of shape `(B, S, N, value_dim)`.\n",
        "          attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n",
        "            attention to certain positions. It is generally not needed if the\n",
        "            `query` and `value` (and/or `key`) are masked.\n",
        "          training: Python boolean indicating whether the layer should behave in\n",
        "            training mode (adding dropout) or in inference mode (doing nothing).\n",
        "        Returns:\n",
        "          attention_output: Multi-headed outputs of attention computation.\n",
        "          attention_scores: Multi-headed attention weights.\n",
        "        \"\"\"\n",
        "        # Note: Applying scalar multiply at the smaller end of einsum improves\n",
        "        # XLA performance, but may introduce slight numeric differences in\n",
        "        # the Transformer attention head.\n",
        "        query = tf.multiply(query, 1.0 / math.sqrt(float(self._key_dim)))\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw\n",
        "        # attention scores.\n",
        "        attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
        "        attention_scores = self._masked_softmax(\n",
        "            attention_scores, attention_mask\n",
        "        )\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_scores_dropout = self._dropout_layer(\n",
        "            attention_scores, training=training\n",
        "        )\n",
        "\n",
        "        # `context_layer` = [B, T, N, H]\n",
        "        attention_output = tf.einsum(\n",
        "            self._combine_equation, attention_scores_dropout, value\n",
        "        )\n",
        "        #import sys\n",
        "        #sys.exit()\n",
        "        return attention_output, attention_scores\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        query,\n",
        "        value,\n",
        "        key=None,\n",
        "        attention_mask=None,\n",
        "        return_attention_scores=False,\n",
        "        training=None,\n",
        "        use_causal_mask=False,\n",
        "    ):\n",
        "        attention_mask = self._compute_attention_mask(\n",
        "            query,\n",
        "            value,\n",
        "            key=key,\n",
        "            attention_mask=attention_mask,\n",
        "            use_causal_mask=use_causal_mask,\n",
        "        )\n",
        "\n",
        "        if not self._built_from_signature:\n",
        "            self._build_from_signature(query=query, value=value, key=key)\n",
        "        if key is None:\n",
        "            key = value\n",
        "\n",
        "        query_is_ragged = isinstance(query, tf.RaggedTensor)\n",
        "        if query_is_ragged:\n",
        "            query_lengths = query.nested_row_lengths()\n",
        "            query = query.to_tensor()\n",
        "\n",
        "        key_is_ragged = isinstance(key, tf.RaggedTensor)\n",
        "        value_is_ragged = isinstance(value, tf.RaggedTensor)\n",
        "        if key_is_ragged and value_is_ragged:\n",
        "            # Ensure they have the same shape.\n",
        "            bounding_shape = tf.math.maximum(\n",
        "                key.bounding_shape(), value.bounding_shape()\n",
        "            )\n",
        "            key = key.to_tensor(shape=bounding_shape)\n",
        "            value = value.to_tensor(shape=bounding_shape)\n",
        "        elif key_is_ragged:\n",
        "            key = key.to_tensor(shape=tf.shape(value))\n",
        "        elif value_is_ragged:\n",
        "            value = value.to_tensor(shape=tf.shape(key))\n",
        "\n",
        "        #   N = `num_attention_heads`\n",
        "        #   H = `size_per_head`\n",
        "        # `query` = [B, T, N ,H]\n",
        "        query = self._query_dense(query)\n",
        "        # `key` = [B, S, N, H]\n",
        "        key = self._key_dense(key)\n",
        "        key = self._proj(key)\n",
        "        # `value` = [B, S, N, H]\n",
        "        value = self._value_dense(value)\n",
        "        value = self._proj(value)\n",
        "        attention_output, attention_scores = self._compute_attention(\n",
        "            query, key, value, attention_mask, training\n",
        "        )\n",
        "        attention_output = self._output_dense(attention_output)\n",
        "\n",
        "        if query_is_ragged:\n",
        "            attention_output = tf.RaggedTensor.from_tensor(\n",
        "                attention_output, lengths=query_lengths\n",
        "            )\n",
        "\n",
        "        if return_attention_scores:\n",
        "            return attention_output, attention_scores\n",
        "        return attention_output\n",
        "\n",
        "    def _compute_attention_mask(\n",
        "        self, query, value, key=None, attention_mask=None, use_causal_mask=False\n",
        "    ):\n",
        "        \"\"\"Computes the attention mask, using the Keras masks of the inputs.\n",
        "        * The `query`'s mask is reshaped from [B, T] to [B, T, 1].\n",
        "        * The `value`'s mask is reshaped from [B, S] to [B, 1, S].\n",
        "        * The `key`'s mask is reshaped from [B, S] to [B, 1, S]. The `key`'s\n",
        "          mask is ignored if `key` is `None` or if `key is value`.\n",
        "        * If `use_causal_mask=True`, then the causal mask is computed. Its shape\n",
        "          is [1, T, S].\n",
        "        All defined masks are merged using a logical AND operation (`&`).\n",
        "        In general, if the `query` and `value` are masked, then there is no need\n",
        "        to define the `attention_mask`.\n",
        "        Args:\n",
        "          query: Projected query `Tensor` of shape `(B, T, N, key_dim)`.\n",
        "          key: Projected key `Tensor` of shape `(B, T, N, key_dim)`.\n",
        "          value: Projected value `Tensor` of shape `(B, T, N, value_dim)`.\n",
        "          attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n",
        "            attention to certain positions.\n",
        "          use_causal_mask: A boolean to indicate whether to apply a causal mask\n",
        "            to prevent tokens from attending to future tokens (e.g., used in a\n",
        "            decoder Transformer).\n",
        "        Returns:\n",
        "          attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n",
        "            attention to certain positions, based on the Keras masks of the\n",
        "            `query`, `key`, `value`, and `attention_mask` tensors, and the\n",
        "            causal mask if `use_causal_mask=True`.\n",
        "        \"\"\"\n",
        "        query_mask = getattr(query, \"_keras_mask\", None)\n",
        "        value_mask = getattr(value, \"_keras_mask\", None)\n",
        "        key_mask = getattr(key, \"_keras_mask\", None)\n",
        "        auto_mask = None\n",
        "        if query_mask is not None:\n",
        "            query_mask = tf.cast(query_mask, tf.bool)  # defensive casting\n",
        "            # B = batch size, T = max query length\n",
        "            auto_mask = query_mask[:, :, tf.newaxis]  # shape is [B, T, 1]\n",
        "        if value_mask is not None:\n",
        "            value_mask = tf.cast(value_mask, tf.bool)  # defensive casting\n",
        "            # B = batch size, S == max value length\n",
        "            mask = value_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n",
        "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
        "        if key_mask is not None:\n",
        "            key_mask = tf.cast(key_mask, tf.bool)  # defensive casting\n",
        "            # B == batch size, S == max key length == max value length\n",
        "            mask = key_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n",
        "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
        "        if use_causal_mask:\n",
        "            # the shape of the causal mask is [1, T, S]\n",
        "            mask = self._compute_causal_mask(query, value)\n",
        "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
        "        if auto_mask is not None:\n",
        "            # merge attention_mask & automatic mask, to shape [B, T, S]\n",
        "            attention_mask = (\n",
        "                auto_mask\n",
        "                if attention_mask is None\n",
        "                else tf.cast(attention_mask, bool) & auto_mask\n",
        "            )\n",
        "        return attention_mask\n",
        "\n",
        "    def _compute_causal_mask(self, query, value=None):\n",
        "        \"\"\"Computes a causal mask (e.g., for masked self-attention layers).\n",
        "        For example, if query and value both contain sequences of length 4,\n",
        "        this function returns a boolean `Tensor` equal to:\n",
        "        ```\n",
        "        [[[True,  False, False, False],\n",
        "          [True,  True,  False, False],\n",
        "          [True,  True,  True,  False],\n",
        "          [True,  True,  True,  True]]]\n",
        "        ```\n",
        "        Args:\n",
        "          query: query `Tensor` of shape `(B, T, ...)`.\n",
        "          value: value `Tensor` of shape `(B, S, ...)` (optional, defaults to\n",
        "          query).\n",
        "        Returns:\n",
        "          mask: a boolean `Tensor` of shape [1, T, S] containing a lower\n",
        "                triangular matrix of shape [T, S].\n",
        "        \"\"\"\n",
        "        q_seq_length = tf.shape(query)[1]\n",
        "        v_seq_length = q_seq_length if value is None else tf.shape(value)[1]\n",
        "        return tf.linalg.band_part(  # creates a lower triangular matrix\n",
        "            tf.ones((1, q_seq_length, v_seq_length), tf.bool), -1, 0\n",
        "        )\n",
        "\n",
        "    def compute_output_shape(self, query_shape, value_shape, key_shape=None):\n",
        "\n",
        "        if key_shape is None:\n",
        "            key_shape = value_shape\n",
        "\n",
        "        query_shape = tf.TensorShape(query_shape)\n",
        "        value_shape = tf.TensorShape(value_shape)\n",
        "        key_shape = tf.TensorShape(key_shape)\n",
        "\n",
        "        if query_shape[-1] != value_shape[-1]:\n",
        "            raise ValueError(\n",
        "                \"The last dimension of `query_shape` and `value_shape` \"\n",
        "                f\"must be equal, but are {query_shape[-1]}, {value_shape[-1]}. \"\n",
        "                \"Received: query_shape={query_shape}, value_shape={value_shape}\"\n",
        "            )\n",
        "\n",
        "        if value_shape[1:-1] != key_shape[1:-1]:\n",
        "            raise ValueError(\n",
        "                \"All dimensions of `value` and `key`, except the last one, \"\n",
        "                f\"must be equal. Received {value_shape} and \"\n",
        "                f\"{key_shape}\"\n",
        "            )\n",
        "\n",
        "        if self._output_shape:\n",
        "            return query_shape[:-1].concatenate(self._output_shape)\n",
        "\n",
        "        return query_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSH Attention as keras multihead subclass"
      ],
      "metadata": {
        "id": "yuU1I__9PLzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers.attention.multi_head_attention import MultiHeadAttention\n",
        "from keras.utils import tf_utils\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSHAttention(MultiHeadAttention):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    self.n_buckets= kwargs.pop('n_buckets', 4)\n",
        "    super().__init__(*args, **kwargs)\n",
        "  def _build_from_signature(self, query, value, key=None):\n",
        "    with tf_utils.maybe_init_scope(self):\n",
        "      self._hash=tf.keras.layers.EinsumDense(\"bjhd,dc->bjhc\",output_shape=(None,None,self.n_buckets // 2))\n",
        "      self.lsh_proj=tf.random.normal\n",
        "    super()._build_from_signature(query, value, key=None)\n",
        "\n",
        "  def call(\n",
        "        self,\n",
        "        query,\n",
        "        value,\n",
        "        key=None,\n",
        "        attention_mask=None,\n",
        "        return_attention_scores=False,\n",
        "        training=None,\n",
        "        use_causal_mask=False,\n",
        "        ):\n",
        "        attention_mask = self._compute_attention_mask(\n",
        "            query,\n",
        "            value,\n",
        "            key=key,\n",
        "            attention_mask=attention_mask,\n",
        "            use_causal_mask=use_causal_mask,\n",
        "        )\n",
        "\n",
        "        if not self._built_from_signature:\n",
        "            self._build_from_signature(query=query, value=value, key=key)\n",
        "        if key is None:\n",
        "            key = value\n",
        "\n",
        "        query_is_ragged = isinstance(query, tf.RaggedTensor)\n",
        "        if query_is_ragged:\n",
        "            query_lengths = query.nested_row_lengths()\n",
        "            query = query.to_tensor()\n",
        "\n",
        "        key_is_ragged = isinstance(key, tf.RaggedTensor)\n",
        "        value_is_ragged = isinstance(value, tf.RaggedTensor)\n",
        "        if key_is_ragged and value_is_ragged:\n",
        "            # Ensure they have the same shape.\n",
        "            bounding_shape = tf.math.maximum(\n",
        "                key.bounding_shape(), value.bounding_shape()\n",
        "            )\n",
        "            key = key.to_tensor(shape=bounding_shape)\n",
        "            value = value.to_tensor(shape=bounding_shape)\n",
        "        elif key_is_ragged:\n",
        "            key = key.to_tensor(shape=tf.shape(value))\n",
        "        elif value_is_ragged:\n",
        "            value = value.to_tensor(shape=tf.shape(key))\n",
        "\n",
        "        #   N = `num_attention_heads`\n",
        "        #   H = `size_per_head`\n",
        "        # `query` = [B, T, N ,H]\n",
        "        query = self._query_dense(query)\n",
        "        # `key` = [B, S, N, H]\n",
        "        key = query\n",
        "        # `value` = [B, S, N, H]\n",
        "        value = self._value_dense(value)\n",
        "        for i in range(value.shape[2]):\n",
        "          #here we make the rotation matrix, that will hash the vectors\n",
        "          random_rot=self.lsh_proj([value.shape[-1],self.n_buckets // 2])\n",
        "          #hash=self._hash(value)\n",
        "\n",
        "          #here we make the rotation using dot product, and making the buckets\n",
        "          hash=tf.matmul(value[:,:,i,:],random_rot)\n",
        "          hash=tf.concat([hash,-hash],axis=-1)\n",
        "\n",
        "          #here we make each token be clasified to a bucket\n",
        "          buckets=tf.math.argmax(hash,axis=-1)\n",
        "\n",
        "          #This is the index that will sort the inputs, and is made by sorting the buckets\n",
        "          index=tf.argsort(buckets,axis=-1)\n",
        "\n",
        "          #here we sort the main inputs usinf the index\n",
        "          sv=tf.gather(value[:,:,i,:],index,axis=1,batch_dims=-1)\n",
        "          sq=sk=tf.gather(query[:,:,i,:],index,axis=1,batch_dims=-1)\n",
        "          #And chunk the inputs based on how many buckets we have\n",
        "          sv=tf.split(sv, self.n_buckets, axis=1)\n",
        "          sq=tf.split(sq, self.n_buckets, axis=1)\n",
        "          j=0\n",
        "          for v,q in zip(sv,sq):\n",
        "            attention_output, attention_scores = self._compute_attention(\n",
        "                q[:,:,None,:], q[:,:,None,:], v[:,:,None,:], attention_mask, training\n",
        "            )\n",
        "            if j==0:\n",
        "              att=attention_output\n",
        "            else:\n",
        "              att=tf.concat([att,attention_output],axis=1)\n",
        "            j+=1\n",
        "          attention_output=att\n",
        "          if i==0:\n",
        "            att_o=attention_output\n",
        "          else:\n",
        "            att_o=tf.concat([att_o,attention_output],axis=2)\n",
        "        attention_output = att_o\n",
        "        index=tf.argsort(index,axis=-1)\n",
        "        attention_output = tf.gather(attention_output, index,axis=1,batch_dims=-1)\n",
        "        attention_output = self._output_dense(attention_output)\n",
        "        if query_is_ragged:\n",
        "            attention_output = tf.RaggedTensor.from_tensor(\n",
        "                attention_output, lengths=query_lengths\n",
        "        )\n",
        "        if return_attention_scores:\n",
        "            return attention_output, attention_scores\n",
        "        return attention_output"
      ],
      "metadata": {
        "id": "UhMT80KNPLCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers.attention.multi_head_attention import MultiHeadAttention\n",
        "from keras.utils import tf_utils\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSHAttention(MultiHeadAttention):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    self.n_buckets= kwargs.pop('n_buckets', 4)\n",
        "    super().__init__(*args, **kwargs)\n",
        "  def _build_from_signature(self, query, value, key=None):\n",
        "    with tf_utils.maybe_init_scope(self):\n",
        "      self.lsh_proj=tf.random.normal\n",
        "    super()._build_from_signature(query, value, key=None)\n",
        "\n",
        "  def call(\n",
        "        self,\n",
        "        query,\n",
        "        value,\n",
        "        key=None,\n",
        "        attention_mask=None,\n",
        "        return_attention_scores=False,\n",
        "        training=None,\n",
        "        use_causal_mask=False,\n",
        "        ):\n",
        "        attention_mask = self._compute_attention_mask(\n",
        "            query,\n",
        "            value,\n",
        "            key=key,\n",
        "            attention_mask=attention_mask,\n",
        "            use_causal_mask=use_causal_mask,\n",
        "        )\n",
        "\n",
        "        if not self._built_from_signature:\n",
        "            self._build_from_signature(query=query, value=value, key=key)\n",
        "        if key is None:\n",
        "            key = value\n",
        "\n",
        "        query_is_ragged = isinstance(query, tf.RaggedTensor)\n",
        "        if query_is_ragged:\n",
        "            query_lengths = query.nested_row_lengths()\n",
        "            query = query.to_tensor()\n",
        "\n",
        "        key_is_ragged = isinstance(key, tf.RaggedTensor)\n",
        "        value_is_ragged = isinstance(value, tf.RaggedTensor)\n",
        "        if key_is_ragged and value_is_ragged:\n",
        "            # Ensure they have the same shape.\n",
        "            bounding_shape = tf.math.maximum(\n",
        "                key.bounding_shape(), value.bounding_shape()\n",
        "            )\n",
        "            key = key.to_tensor(shape=bounding_shape)\n",
        "            value = value.to_tensor(shape=bounding_shape)\n",
        "        elif key_is_ragged:\n",
        "            key = key.to_tensor(shape=tf.shape(value))\n",
        "        elif value_is_ragged:\n",
        "            value = value.to_tensor(shape=tf.shape(key))\n",
        "\n",
        "        #   N = `num_attention_heads`\n",
        "        #   H = `size_per_head`\n",
        "        # `query` = [B, T, N ,H]\n",
        "        query = self._query_dense(query)\n",
        "        # `key` = [B, S, N, H]\n",
        "        key = query\n",
        "        # `value` = [B, S, N, H]\n",
        "        value = self._value_dense(value)\n",
        "        for i in range(value.shape[2]):\n",
        "          #here we make the rotation matrix, that will hash the vectors\n",
        "          random_rot=self.lsh_proj([value.shape[-1],self.n_buckets // 2])\n",
        "          #hash=self._hash(value)\n",
        "\n",
        "          #here we make the rotation using dot product, and making the buckets\n",
        "          hash=tf.matmul(value[:,:,i,:],random_rot)\n",
        "          hash=tf.concat([hash,-hash],axis=-1)\n",
        "\n",
        "          #here we make each token be clasified to a bucket\n",
        "          buckets=tf.math.argmax(hash,axis=-1)\n",
        "\n",
        "          #This is the index that will sort the inputs, and is made by sorting the buckets\n",
        "          index=tf.argsort(buckets,axis=-1)\n",
        "\n",
        "          #here we sort the main inputs usinf the index\n",
        "          sv=tf.gather(value[:,:,i,:],index,axis=1,batch_dims=-1)\n",
        "          sq=sk=tf.gather(query[:,:,i,:],index,axis=1,batch_dims=-1)\n",
        "          #And chunk the inputs based on how many buckets we have\n",
        "\n",
        "          j=0\n",
        "          chunk_size=int(sv.shape[1]/self.n_buckets)\n",
        "          for j in range(self.n_buckets):\n",
        "            q=sq[:,j*chunk_size:(j+1)*chunk_size,:]\n",
        "            v=sv[:,j*chunk_size:(j+1)*chunk_size,:]\n",
        "            attention_output, attention_scores = self._compute_attention(\n",
        "                q[:,:,None,:], q[:,:,None,:], v[:,:,None,:], attention_mask, training\n",
        "            )\n",
        "            if j==0:\n",
        "              att=attention_output\n",
        "            else:\n",
        "              att=tf.concat([att,attention_output],axis=1)\n",
        "          attention_output=att\n",
        "          if i==0:\n",
        "            att_o=attention_output\n",
        "          else:\n",
        "            att_o=tf.concat([att_o,attention_output],axis=2)\n",
        "        attention_output = att_o\n",
        "        attention_output = self._output_dense(attention_output)\n",
        "        if query_is_ragged:\n",
        "            attention_output = tf.RaggedTensor.from_tensor(\n",
        "                attention_output, lengths=query_lengths\n",
        "        )\n",
        "        if return_attention_scores:\n",
        "            return attention_output, attention_scores\n",
        "        return attention_output"
      ],
      "metadata": {
        "id": "MqxDD_D1mJGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKms-Jo8H-kn"
      },
      "source": [
        "##Patch wise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUySwAEoH-ko"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W65NvnvZH-kp"
      },
      "outputs": [],
      "source": [
        "def DiceMetric(y_true, y_pred):\n",
        "  smooth=1e-6\n",
        "  gama=2\n",
        "  y_true, y_pred = tf.cast(\n",
        "      y_true, dtype=tf.float32), tf.cast(y_pred, tf.float32)\n",
        "  nominator = 2 * \\\n",
        "      tf.reduce_sum(tf.multiply(y_pred, y_true)) + smooth\n",
        "  denominator = tf.reduce_sum(\n",
        "      y_pred ** gama) + tf.reduce_sum(y_true ** gama) + smooth\n",
        "  result = tf.divide(nominator, denominator)\n",
        "  return result\n",
        "def DiceLoss(y_true, y_pred):\n",
        "      result= 1- DiceMetric(y_true, y_pred)\n",
        "      return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kli_5DCBH-kp"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
        "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "  return iou\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "  union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "  dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
        "  return dice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef_multilabel(y_true, y_pred, smooth=1):\n",
        "    dice=0\n",
        "    numLabels=y_true.shape[3]\n",
        "    for index in range(numLabels):\n",
        "      #None,128,128,1\n",
        "      y_t=tf.expand_dims(y_true[:,:,:,index],axis=3)\n",
        "      #None,128,128\n",
        "      y_p=tf.expand_dims(y_pred[:,:,:,index],axis=3)\n",
        "      dice += dice_coef(y_t, y_p)\n",
        "    return dice/numLabels # taking average"
      ],
      "metadata": {
        "id": "LmLKTdyUH-kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_coef_multilabel(y_true, y_pred, smooth=1):\n",
        "    dice=0\n",
        "    numLabels=y_true.shape[3]\n",
        "    for index in range(numLabels):\n",
        "      y_t=tf.expand_dims(y_true[:,:,:,index],axis=3)\n",
        "      y_p=tf.expand_dims(y_pred[:,:,:,index],axis=3)\n",
        "      dice += iou_coef(y_t, y_p)\n",
        "    return dice/numLabels # taking average"
      ],
      "metadata": {
        "id": "oopp7EhGH-kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cih6HuiDH-kr"
      },
      "outputs": [],
      "source": [
        "def conv_block(X,f,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (3, 3), kernel_initializer='he_normal', padding='same', groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  s = tf.keras.layers.Conv2D(f[1], (1, 1), kernel_initializer='he_normal', padding='same')(X)\n",
        "  s = tf.keras.layers.BatchNormalization(axis=3)(s)\n",
        "  c = tf.keras.layers.Add()([c,s])\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return c,c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "zx_Lky4g-HLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten(M):\n",
        "  s1=M.shape[1]\n",
        "  s2=M.shape[2]\n",
        "  s3=M.shape[3]\n",
        "  flat=s1*s2\n",
        "  M= tf.reshape(M,[-1,flat,s3])\n",
        "  return M,s1,s2,s3"
      ],
      "metadata": {
        "id": "criSasUmEUSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten_LSH(M,N,nheads,dimk,k=128):\n",
        "  M,s1,s2,s3= Flatten(M)\n",
        "  N,_,_,_= Flatten(N)\n",
        "  pm=LSHAttention(num_heads=nheads,key_dim=dimk,dropout=0.2,n_buckets=k)(M,M)\n",
        "  pm=tf.reshape(pm,[-1,s1,s2,s3])\n",
        "  return pm"
      ],
      "metadata": {
        "id": "0NfKBfC9D1CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaBbrDNpD1CL"
      },
      "outputs": [],
      "source": [
        "def vit(X,Y,n_heads=16,psize=16,k=256,dim=\"4D\"):\n",
        "  npatch=int(X.shape[1]/psize)\n",
        "  psizey=int(psize/2)\n",
        "  kdim=int(X.shape[3]/n_heads)\n",
        "  Y=tf.keras.layers.Dense(X.shape[3])(Y)\n",
        "  if npatch==0:\n",
        "    pm=Flatten_LSH(X,Y,n_heads,kdim,k)\n",
        "    return pm\n",
        "  for i in range(npatch):\n",
        "    st=i*psize\n",
        "    sty=i*psizey\n",
        "    end=st+psize\n",
        "    endy=sty+psizey\n",
        "    for j in range(npatch):\n",
        "      st2=j*psize\n",
        "      end2=st2+psize\n",
        "      sty2=j*psizey\n",
        "      endy2=sty2+psizey\n",
        "      patch= X[:,st:end,st2:end2,:]\n",
        "      patch2= Y[:,sty:endy,sty2:endy2,:]\n",
        "      pm=Flatten_LSH(patch,patch2,n_heads,kdim,k)\n",
        "      if j==0:\n",
        "        A=pm\n",
        "      else:\n",
        "        A=tf.concat([A,pm],2)\n",
        "    if i==0:\n",
        "      V=A\n",
        "    else:\n",
        "      V=tf.concat([V,A],1)\n",
        "  return V\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORXKkrPRH-kx"
      },
      "source": [
        "### Vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h9vieygH-kx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "  nheads=4\n",
        "  sizep=32\n",
        "  gr=4\n",
        "  kval=4\n",
        "  #Build the model\n",
        "  inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "  s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "  #s= inputs\n",
        "  #Contraction path\n",
        "  c1,z1 = conv_block(s,[16,16],group=1)\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "\n",
        "  c2,z2 = conv_block(p1,[32,32],group=gr)\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "  c3,z3 = conv_block(p2,[64,64],0.2,group=gr)\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "  c4,z4 = conv_block(p3,[128,128],0.2,group=gr)\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "  c5,z5 = conv_block(p4,[256,256],0.3,group=gr)\n",
        "\n",
        "  #Expansive path\n",
        "  m1= vit(z4,z5,nheads,sizep,k=kval)\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "  u6 = tf.keras.layers.concatenate([u6, m1])\n",
        "  c6,z6 = conv_block(u6,[128,128],0.2,group=gr)\n",
        "\n",
        "  m2= vit(z3,z6,nheads,sizep,k=kval)\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "  u7 = tf.keras.layers.concatenate([u7, m2])\n",
        "  c7,z7 = conv_block(u7,[64,64],0.2,group=gr)\n",
        "\n",
        "  m3= vit(z2,z7,nheads,sizep,k=kval)\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "  u8 = tf.keras.layers.concatenate([u8, m3])\n",
        "  c8,z8 = conv_block(u8,[32,32],group=gr)\n",
        "\n",
        "  m4= vit(z1,z8,nheads,sizep,k=kval)\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "  u9 = tf.keras.layers.concatenate([u9, m4], axis=3)\n",
        "  c9,_ = conv_block(u9,[16,16],group=gr)\n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(4, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',iou_coef_multilabel,dice_coef_multilabel])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSH without Patches"
      ],
      "metadata": {
        "id": "vUN1FbBxpx23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten(M):\n",
        "  s1=M.shape[1]\n",
        "  s2=M.shape[2]\n",
        "  s3=M.shape[3]\n",
        "  flat=s1*s2\n",
        "  M= tf.reshape(M,[-1,flat,s3])\n",
        "  return M,s1,s2,s3"
      ],
      "metadata": {
        "id": "AOWw_y4D4cMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LSH_lay(M,nheads,k=128,nbuckets=4):\n",
        "  M,s1,s2,s3= Flatten(M)\n",
        "  dimk=int(M.shape[2]/nheads)\n",
        "  pm=LSHAttention(num_heads=nheads,key_dim=dimk,dropout=0.2,n_buckets=nbuckets)(M,M)\n",
        "  pm=tf.reshape(pm,[-1,s1,s2,s3])\n",
        "  return pm"
      ],
      "metadata": {
        "id": "qi15V9Ihp8SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-3KKmhCp4Ue"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "  nheads=4\n",
        "  sizep=32\n",
        "  gr=4\n",
        "\n",
        "  #Build the model\n",
        "  inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "  s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "  #s= inputs\n",
        "  #Contraction path\n",
        "  c1,z1 = conv_block(s,[16,16],group=1)\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "\n",
        "  c2,z2 = conv_block(p1,[32,32],group=gr)\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "  c3,z3 = conv_block(p2,[64,64],0.2,group=gr)\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "  c4,z4 = conv_block(p3,[128,128],0.2,group=gr)\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "  c5,z5 = conv_block(p4,[256,256],0.3,group=gr)\n",
        "\n",
        "  #Expansive path\n",
        "\n",
        "  m1= LSH_lay(z4,nheads)\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "  u6 = tf.keras.layers.concatenate([u6, m1])\n",
        "  c6,z6 = conv_block(u6,[128,128],0.2,group=gr)\n",
        "\n",
        "  m2= LSH_lay(z3,nheads,nbuckets=8)\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "  u7 = tf.keras.layers.concatenate([u7, m2])\n",
        "  c7,z7 = conv_block(u7,[64,64],0.2,group=gr)\n",
        "\n",
        "  m3= LSH_lay(z2,nheads,nbuckets=8)\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "  u8 = tf.keras.layers.concatenate([u8, m3])\n",
        "  c8,z8 = conv_block(u8,[32,32],group=gr)\n",
        "\n",
        "  m4= LSH_lay(z1,nheads,nbuckets=32)\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "  u9 = tf.keras.layers.concatenate([u9, m4], axis=3)\n",
        "  c9,_ = conv_block(u9,[16,16],group=gr)\n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(4, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',iou_coef_multilabel,dice_coef_multilabel])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test"
      ],
      "metadata": {
        "id": "HlE3bWkIpvDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=create_model()\n",
        "model.fit(X_train,Y_train,batch_size=16,epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UGu9XXsJmbg",
        "outputId": "66f27497-c3a0-44e2-dda7-971c47b49647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "158/158 [==============================] - 454s 875ms/step - loss: 0.2368 - accuracy: 0.9364 - iou_coef_multilabel: 0.3757 - dice_coef_multilabel: 0.4452\n",
            "Epoch 2/25\n",
            "158/158 [==============================] - 127s 806ms/step - loss: 0.0523 - accuracy: 0.9863 - iou_coef_multilabel: 0.5403 - dice_coef_multilabel: 0.5984\n",
            "Epoch 3/25\n",
            "158/158 [==============================] - 127s 803ms/step - loss: 0.0356 - accuracy: 0.9898 - iou_coef_multilabel: 0.5898 - dice_coef_multilabel: 0.6427\n",
            "Epoch 4/25\n",
            "158/158 [==============================] - 127s 807ms/step - loss: 0.0286 - accuracy: 0.9913 - iou_coef_multilabel: 0.6189 - dice_coef_multilabel: 0.6692\n",
            "Epoch 5/25\n",
            "158/158 [==============================] - 127s 802ms/step - loss: 0.0245 - accuracy: 0.9922 - iou_coef_multilabel: 0.6402 - dice_coef_multilabel: 0.6887\n",
            "Epoch 6/25\n",
            "158/158 [==============================] - 127s 803ms/step - loss: 0.0221 - accuracy: 0.9928 - iou_coef_multilabel: 0.6557 - dice_coef_multilabel: 0.7027\n",
            "Epoch 7/25\n",
            "158/158 [==============================] - 127s 802ms/step - loss: 0.0208 - accuracy: 0.9931 - iou_coef_multilabel: 0.6670 - dice_coef_multilabel: 0.7131\n",
            "Epoch 8/25\n",
            "158/158 [==============================] - 127s 802ms/step - loss: 0.0193 - accuracy: 0.9935 - iou_coef_multilabel: 0.6788 - dice_coef_multilabel: 0.7238\n",
            "Epoch 9/25\n",
            "158/158 [==============================] - 127s 803ms/step - loss: 0.0184 - accuracy: 0.9936 - iou_coef_multilabel: 0.6873 - dice_coef_multilabel: 0.7316\n",
            "Epoch 10/25\n",
            "158/158 [==============================] - 127s 802ms/step - loss: 0.0177 - accuracy: 0.9938 - iou_coef_multilabel: 0.6965 - dice_coef_multilabel: 0.7401\n",
            "Epoch 11/25\n",
            "158/158 [==============================] - 127s 801ms/step - loss: 0.0170 - accuracy: 0.9940 - iou_coef_multilabel: 0.7044 - dice_coef_multilabel: 0.7475\n",
            "Epoch 12/25\n",
            "158/158 [==============================] - 126s 799ms/step - loss: 0.0165 - accuracy: 0.9941 - iou_coef_multilabel: 0.7121 - dice_coef_multilabel: 0.7546\n",
            "Epoch 13/25\n",
            "158/158 [==============================] - 126s 800ms/step - loss: 0.0160 - accuracy: 0.9943 - iou_coef_multilabel: 0.7199 - dice_coef_multilabel: 0.7620\n",
            "Epoch 14/25\n",
            "158/158 [==============================] - 127s 801ms/step - loss: 0.0155 - accuracy: 0.9944 - iou_coef_multilabel: 0.7268 - dice_coef_multilabel: 0.7684\n",
            "Epoch 15/25\n",
            "158/158 [==============================] - 126s 800ms/step - loss: 0.0153 - accuracy: 0.9945 - iou_coef_multilabel: 0.7330 - dice_coef_multilabel: 0.7744\n",
            "Epoch 16/25\n",
            "158/158 [==============================] - 126s 799ms/step - loss: 0.0149 - accuracy: 0.9946 - iou_coef_multilabel: 0.7385 - dice_coef_multilabel: 0.7794\n",
            "Epoch 17/25\n",
            "158/158 [==============================] - 126s 795ms/step - loss: 0.0147 - accuracy: 0.9946 - iou_coef_multilabel: 0.7456 - dice_coef_multilabel: 0.7863\n",
            "Epoch 18/25\n",
            "158/158 [==============================] - 126s 799ms/step - loss: 0.0144 - accuracy: 0.9947 - iou_coef_multilabel: 0.7503 - dice_coef_multilabel: 0.7908\n",
            "Epoch 19/25\n",
            "158/158 [==============================] - 126s 799ms/step - loss: 0.0141 - accuracy: 0.9948 - iou_coef_multilabel: 0.7579 - dice_coef_multilabel: 0.7981\n",
            "Epoch 20/25\n",
            "158/158 [==============================] - 126s 797ms/step - loss: 0.0142 - accuracy: 0.9947 - iou_coef_multilabel: 0.7562 - dice_coef_multilabel: 0.7964\n",
            "Epoch 21/25\n",
            "158/158 [==============================] - 126s 800ms/step - loss: 0.0141 - accuracy: 0.9947 - iou_coef_multilabel: 0.7630 - dice_coef_multilabel: 0.8030\n",
            "Epoch 22/25\n",
            "158/158 [==============================] - 126s 799ms/step - loss: 0.0136 - accuracy: 0.9949 - iou_coef_multilabel: 0.7713 - dice_coef_multilabel: 0.8110\n",
            "Epoch 23/25\n",
            "158/158 [==============================] - 126s 797ms/step - loss: 0.0134 - accuracy: 0.9950 - iou_coef_multilabel: 0.7764 - dice_coef_multilabel: 0.8157\n",
            "Epoch 24/25\n",
            "158/158 [==============================] - 126s 798ms/step - loss: 0.0132 - accuracy: 0.9950 - iou_coef_multilabel: 0.7804 - dice_coef_multilabel: 0.8196\n",
            "Epoch 25/25\n",
            "158/158 [==============================] - 126s 797ms/step - loss: 0.0131 - accuracy: 0.9950 - iou_coef_multilabel: 0.7846 - dice_coef_multilabel: 0.8234\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff23d9adab0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for split version, time for execution 42 m\n",
        "\n",
        "patched version time for execution 34 m"
      ],
      "metadata": {
        "id": "UBnt5OP2nQEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores= model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f'Score for fold {0}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yNkgZfLmnD8",
        "outputId": "220dfc67-5397-4d16-cdb9-3e983cf99477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 0: loss of 0.023588653653860092; accuracy of 99.25824999809265% iou_coef_multilabel of 75.87804794311523% dice_coef_multilabel of 79.55738306045532%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch size=32 k=32:\n",
        "\n",
        "Score for fold 0: loss of 0.02660856954753399; accuracy of 99.21053647994995% iou_coef_multilabel of 73.97453188896179% dice_coef_multilabel of 77.59955525398254%\n",
        "\n",
        "No Patch k=128:\n",
        "\n",
        "Score for fold 0: loss of 0.03675605729222298; accuracy of 98.8860547542572% iou_coef_multilabel of 69.78949904441833% dice_coef_multilabel of 74.2724359035492%\n",
        "\n",
        "Patch size=32 k=256:\n",
        "Score for fold 0: loss of 0.11757280677556992; accuracy of 96.79576754570007% iou_coef_multilabel of 71.6090202331543% dice_coef_multilabel of 79.81376647949219%\n"
      ],
      "metadata": {
        "id": "OQ_noHHMsOEk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2D-muOYe_Pj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trswxiGSe_Pl"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Patch test"
      ],
      "metadata": {
        "id": "qWRqddndzFCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=32"
      ],
      "metadata": {
        "id": "4T-tvQ42fpKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qUsIi9Se4PD",
        "outputId": "1f0ee790-e664-4eee-c81d-e35012365ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.029409149661660194; accuracy of 98.91234040260315% iou_coef_multilabel of 70.78478932380676% dice_coef_multilabel of 75.16862750053406%\n",
            "Score for fold 2: loss of 0.042917650192976; accuracy of 98.51773381233215% iou_coef_multilabel of 70.23463249206543% dice_coef_multilabel of 75.7128119468689%\n",
            "Score for fold 3: loss of 0.04444853588938713; accuracy of 98.51000308990479% iou_coef_multilabel of 67.47883558273315% dice_coef_multilabel of 72.66407012939453%\n",
            "Score for fold 4: loss of 0.10042478889226913; accuracy of 96.02788090705872% iou_coef_multilabel of 55.91818690299988% dice_coef_multilabel of 63.355553150177%\n",
            "Score for fold 5: loss of 0.03272783383727074; accuracy of 98.82147312164307% iou_coef_multilabel of 69.75324749946594% dice_coef_multilabel of 74.68957304954529%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u-iwkU7t4ak",
        "outputId": "0c504f0d-d2d5-4752-d341-f7a58c773d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.025224272161722183; accuracy of 99.0780770778656% iou_coef_multilabel of 75.7142961025238% dice_coef_multilabel of 79.58106994628906%\n",
            "Score for fold 2: loss of 0.04713413491845131; accuracy of 98.5433280467987% iou_coef_multilabel of 74.99583959579468% dice_coef_multilabel of 80.19270896911621%\n",
            "Score for fold 3: loss of 0.04239453375339508; accuracy of 98.56003522872925% iou_coef_multilabel of 71.22631072998047% dice_coef_multilabel of 76.35141015052795%\n",
            "Score for fold 4: loss of 0.04546702280640602; accuracy of 98.31485748291016% iou_coef_multilabel of 70.64926028251648% dice_coef_multilabel of 77.11712121963501%\n",
            "Score for fold 5: loss of 0.032865818589925766; accuracy of 98.83249998092651% iou_coef_multilabel of 71.10702991485596% dice_coef_multilabel of 75.85053443908691%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=256"
      ],
      "metadata": {
        "id": "Gp5y4WBGfweq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328b22fc-64d7-4970-87da-2b9867e7d106",
        "id": "2kmNTemGfvkE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.016601325944066048; accuracy of 99.49246644973755% iou_coef_multilabel of 80.1440417766571% dice_coef_multilabel of 82.72783160209656%\n",
            "Score for fold 2: loss of 0.02792888507246971; accuracy of 99.11463856697083% iou_coef_multilabel of 77.49691009521484% dice_coef_multilabel of 81.86010122299194%\n",
            "Score for fold 3: loss of 0.033090461045503616; accuracy of 99.0357756614685% iou_coef_multilabel of 75.54389238357544% dice_coef_multilabel of 79.85571622848511%\n",
            "Score for fold 4: loss of 0.02735254541039467; accuracy of 99.02375340461731% iou_coef_multilabel of 75.38833618164062% dice_coef_multilabel of 80.59991002082825%\n",
            "Score for fold 5: loss of 0.02401789091527462; accuracy of 99.26612973213196% iou_coef_multilabel of 76.66497826576233% dice_coef_multilabel of 80.13312816619873%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "ee163453-4cde-4531-bfef-16e685603493",
        "id": "i2HqP5AsfvkH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.01717947982251644; accuracy of 99.4581937789917% iou_coef_multilabel of 79.65168952941895% dice_coef_multilabel of 82.61964917182922%\n",
            "Score for fold 2: loss of 0.03299105167388916; accuracy of 99.06346797943115% iou_coef_multilabel of 78.3797025680542% dice_coef_multilabel of 82.73652791976929%\n",
            "Score for fold 3: loss of 0.034237224608659744; accuracy of 99.15516972541809% iou_coef_multilabel of 78.44327688217163% dice_coef_multilabel of 82.67260193824768%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-09b93a07fbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####No Patch test"
      ],
      "metadata": {
        "id": "dbVD7hu9zIad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60653fbf-aeeb-451c-dcdc-c37c1b1a6ccf",
        "id": "kOYSXDX_zOMg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.02731938473880291; accuracy of 99.00254607200623% iou_coef_multilabel of 71.55993580818176% dice_coef_multilabel of 75.51640272140503%\n",
            "Score for fold 2: loss of 0.04416176304221153; accuracy of 98.46460819244385% iou_coef_multilabel of 70.76845169067383% dice_coef_multilabel of 76.32638216018677%\n",
            "Score for fold 3: loss of 0.04237723350524902; accuracy of 98.45744967460632% iou_coef_multilabel of 67.4326241016388% dice_coef_multilabel of 72.71857857704163%\n",
            "Score for fold 4: loss of 0.04793655872344971; accuracy of 98.23458194732666% iou_coef_multilabel of 68.04465651512146% dice_coef_multilabel of 74.47894811630249%\n",
            "Score for fold 5: loss of 0.0348425917327404; accuracy of 98.7302839756012% iou_coef_multilabel of 65.84467887878418% dice_coef_multilabel of 70.64203023910522%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "9c7dd46a-f675-468d-8126-6fabf5e3bbbc",
        "id": "QTKk58bXzOMi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-09b93a07fbe5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9-gnhHg7mVW"
      },
      "source": [
        "##Model data augmented kfold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocj4dk1_7uDf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"vertical\"),\n",
        "  tf.keras.layers.RandomRotation(0.1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ifq3F_K-7mVc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOTJFgoH7mVc"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRrgKSAz7mVc"
      },
      "outputs": [],
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((X_fold, Y_fold))\n",
        "  # Apply the data augmentation pipeline to both X_train and Y_train\n",
        "  augmented_train_data = train_data.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "  # Separate X_train and Y_train from the augmented train data\n",
        "  X_train_augmented = augmented_train_data.map(lambda x, y: x)\n",
        "  Y_train_augmented = augmented_train_data.map(lambda x, y: y)\n",
        "\n",
        "  X_train_augmented = np.asarray(list(X_train_augmented.as_numpy_iterator()))\n",
        "  Y_train_augmented = np.asarray(list(Y_train_augmented.as_numpy_iterator()))\n",
        "\n",
        "  X_train_combined = np.concatenate([X_fold, X_train_augmented], axis=0)\n",
        "  Y_train_combined = np.concatenate([Y_fold, Y_train_augmented], axis=0)\n",
        "  model.fit(X_train_combined,Y_train_combined,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr59x7qJ7mVc",
        "outputId": "8626b608-fbd4-4c80-c009-a8d7f5ab8795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.06248067319393158; accuracy of 97.74013757705688% iou_coef_multilabel of 69.58065629005432% dice_coef_multilabel of 75.24264454841614%\n",
            "Score for fold 2: loss of 0.07446722686290741; accuracy of 97.424978017807% iou_coef_multilabel of 66.99366569519043% dice_coef_multilabel of 73.48106503486633%\n",
            "Score for fold 3: loss of 0.07256180793046951; accuracy of 97.48387932777405% iou_coef_multilabel of 64.70680236816406% dice_coef_multilabel of 70.94796895980835%\n",
            "Score for fold 4: loss of 0.06639942526817322; accuracy of 97.35667705535889% iou_coef_multilabel of 60.659801959991455% dice_coef_multilabel of 67.65385866165161%\n",
            "Score for fold 5: loss of 0.06580083817243576; accuracy of 97.68750071525574% iou_coef_multilabel of 59.561049938201904% dice_coef_multilabel of 65.57979583740234%\n"
          ]
        }
      ],
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((X_fold, Y_fold))\n",
        "  # Apply the data augmentation pipeline to both X_train and Y_train\n",
        "  augmented_train_data = train_data.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "  # Separate X_train and Y_train from the augmented train data\n",
        "  X_train_augmented = augmented_train_data.map(lambda x, y: x)\n",
        "  Y_train_augmented = augmented_train_data.map(lambda x, y: y)\n",
        "\n",
        "  X_train_augmented = np.asarray(list(X_train_augmented.as_numpy_iterator()))\n",
        "  Y_train_augmented = np.asarray(list(Y_train_augmented.as_numpy_iterator()))\n",
        "\n",
        "  X_train_combined = np.concatenate([X_fold, X_train_augmented], axis=0)\n",
        "  Y_train_combined = np.concatenate([Y_fold, Y_train_augmented], axis=0)\n",
        "  model.fit(X_train_combined,Y_train_combined,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxF74NqRTnYL"
      },
      "source": [
        "##Model data augmented kfold Fixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcZiNs0HTnYR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"vertical\"),\n",
        "  tf.keras.layers.RandomRotation(0.1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf9mFXu2TnYR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFb761bWTnYR"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "795ca727-865e-48a0-b64b-158404a4c6a6",
        "id": "GraQHW6qTnYR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.01390768215060234; accuracy of 99.5705783367157% iou_coef_multilabel of 86.49618029594421% dice_coef_multilabel of 89.0194833278656%\n",
            "Score for fold 2: loss of 0.03675416111946106; accuracy of 98.97904992103577% iou_coef_multilabel of 79.32537794113159% dice_coef_multilabel of 83.57661962509155%\n",
            "Score for fold 3: loss of 0.029099980369210243; accuracy of 99.24059510231018% iou_coef_multilabel of 80.83962798118591% dice_coef_multilabel of 84.87486839294434%\n",
            "Score for fold 4: loss of 0.023593006655573845; accuracy of 99.0794837474823% iou_coef_multilabel of 81.77911639213562% dice_coef_multilabel of 86.97380423545837%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-38a73e033f07>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mX_train_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_augmented\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mY_train_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_augmented\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_combined\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train_combined\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "  X__2 = np.concatenate([X_fold, Y_fold], axis=-1)\n",
        "  X__2 = tf.data.Dataset.from_tensor_slices((X__2))\n",
        "  augmented_train_data = X__2.map(lambda x: data_augmentation(x, training=True))\n",
        "\n",
        "  # Separate X_train and Y_train from the augmented train data\n",
        "  X_train_augmented = augmented_train_data.map(lambda x: x)\n",
        "  X_train_augmented = np.asarray(list(X_train_augmented.as_numpy_iterator()))\n",
        "  Y_train_augmented = X_train_augmented[:,:,:,1:5]\n",
        "  X_train_augmented = X_train_augmented[:,:,:,0]\n",
        "\n",
        "  X_train_combined = np.concatenate([X_fold, X_train_augmented[:,:,:,None]], axis=0)\n",
        "  Y_train_combined = np.concatenate([Y_fold, Y_train_augmented], axis=0)\n",
        "  model.fit(X_train_combined,Y_train_combined,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTzHLJ8PTnYR"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ac2eb2-682c-497c-8732-4766bb847d72",
        "id": "abm6yrrdTnYS"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.013969536870718002; accuracy of 99.5184600353241% iou_coef_multilabel of 78.77731919288635% dice_coef_multilabel of 81.8413496017456%\n",
            "Score for fold 2: loss of 0.029770037159323692; accuracy of 99.06414747238159% iou_coef_multilabel of 80.31871914863586% dice_coef_multilabel of 84.64120626449585%\n",
            "Score for fold 3: loss of 0.026543816551566124; accuracy of 99.26268458366394% iou_coef_multilabel of 81.27678036689758% dice_coef_multilabel of 85.34112572669983%\n",
            "Score for fold 4: loss of 0.02282973751425743; accuracy of 99.13150072097778% iou_coef_multilabel of 81.2670886516571% dice_coef_multilabel of 86.49913668632507%\n",
            "Score for fold 5: loss of 0.02242366410791874; accuracy of 99.32538270950317% iou_coef_multilabel of 75.33347010612488% dice_coef_multilabel of 78.96603345870972%\n"
          ]
        }
      ],
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "  X__2 = np.concatenate([X_fold, Y_fold], axis=-1)\n",
        "  X__2 = tf.data.Dataset.from_tensor_slices((X__2))\n",
        "  augmented_train_data = X__2.map(lambda x: data_augmentation(x, training=True))\n",
        "\n",
        "  # Separate X_train and Y_train from the augmented train data\n",
        "  X_train_augmented = augmented_train_data.map(lambda x: x)\n",
        "  X_train_augmented = np.asarray(list(X_train_augmented.as_numpy_iterator()))\n",
        "  Y_train_augmented = X_train_augmented[:,:,:,1:5]\n",
        "  X_train_augmented = X_train_augmented[:,:,:,0]\n",
        "\n",
        "  X_train_combined = np.concatenate([X_fold, X_train_augmented[:,:,:,None]], axis=0)\n",
        "  Y_train_combined = np.concatenate([Y_fold, Y_train_augmented], axis=0)\n",
        "  model.fit(X_train_combined,Y_train_combined,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bHgVMw0RHdm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSH attention with attention between chunks as keras multihead subclass"
      ],
      "metadata": {
        "id": "y5nOI8HwQ1AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"1KJPU1D0ewHmU7Jzl1irq3Gb-JkUqV1VR&confirm=t\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa72de6-e8e1-46e0-8d4a-f22cde1ff315",
        "id": "4MRLC4lZQ1AX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KJPU1D0ewHmU7Jzl1irq3Gb-JkUqV1VR&confirm=t\n",
            "To: /content/input.zip\n",
            "100% 367M/367M [00:02<00:00, 159MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EGTWPUiQ1AY",
        "outputId": "12f8924b-ff83-447d-d090-001b3f586b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace input/train/masks/coronacases_009_38.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip -q input.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J68DSvLHQ1AY"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f26-769cQ1AZ"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "from nibabel.testing import data_path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio as iio\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "import PIL\n",
        "from PIL import Image\n",
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "X=np.zeros((len(glob.glob(src+imag+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  if x!=\"/content/input/train/images/coronacases_009_149.png\":\n",
        "    im=Image.open(x)\n",
        "    X[i,:,:,0]=im.resize((IMG_WIDTH,IMG_HEIGHT),resample=PIL.Image.NEAREST)\n",
        "mas=\"/Amasks/\"\n",
        "Y=np.zeros((len(glob.glob(src+mas+\"*.png\")),IMG_WIDTH,IMG_HEIGHT))\n",
        "for i,x in enumerate(sorted(glob.glob(src+mas+\"*.png\"))):\n",
        "  if x!=\"/content/input/train/Amasks/coronacases_009_149.png\":\n",
        "    im=Image.open(x)\n",
        "    im=np.array(im.resize((IMG_WIDTH,IMG_HEIGHT),resample=PIL.Image.NEAREST))\n",
        "    im[im==85]=1\n",
        "    im[im==170]=2\n",
        "    im[im==255]=3\n",
        "    Y[i,:,:]=im\n",
        "import tensorflow as tf\n",
        "print(Y.shape)\n",
        "print(np.unique(Y))\n",
        "Y=tf.keras.utils.to_categorical(Y)\n",
        "print(Y.shape)\n",
        "print(np.unique(Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ec681e-dd03-4fa8-c2fe-7dccdcd197c0",
        "id": "OhvgONEsQ1Aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3520, 128, 128)\n",
            "[0. 1. 2. 3.]\n",
            "(3520, 128, 128, 4)\n",
            "[0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f6e745-c1e8-40a2-af6d-68e5762b6622",
        "id": "08TIzX2RQ1Aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "002\n",
            "003\n",
            "004\n",
            "005\n",
            "006\n",
            "007\n",
            "008\n",
            "009\n",
            "010\n",
            "10_85902_1\n",
            "10_85902_3\n",
            "14_85914_0\n",
            "27_86410_0\n",
            "29_86490_1\n",
            "29_86491_1\n",
            "36_86526_0\n",
            "40_86625_0\n",
            "4_85506_1\n",
            "7_85703_0\n"
          ]
        }
      ],
      "source": [
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "Siz=0\n",
        "id=0\n",
        "ri=0\n",
        "metadat=[]\n",
        "c=\"001\"\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  if x.find(\"radiopaedia\") == -1:\n",
        "    x=x[x.find(\"_\")+1:]\n",
        "    x=x[:x.find(\"_\")]\n",
        "  else:\n",
        "    x=x[x.find(\"_\")+1:]\n",
        "    x=x[:x.find(\"_\",9)]\n",
        "  if c!=x:\n",
        "    print(x)\n",
        "    metadat.append([id,Siz,ri])\n",
        "    ri=i\n",
        "    c=x\n",
        "    id+=1\n",
        "    Siz=0\n",
        "  Siz+=1\n",
        "metadat.append([id,Siz,ri])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KefDGBThQ1Ab"
      },
      "source": [
        "##New Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12f3d34-b397-41ff-8314-0078569afa98",
        "id": "pcq1X9HiQ1Ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  2  4  5  7  8  9 11 12 13 14 15 17 18 19] [ 3  6 10 16]\n",
            "[ 0  1  3  5  6  7  8  9 10 11 12 13 15 16 18 19] [ 2  4 14 17]\n",
            "[ 2  3  4  5  6  8  9 10 11 12 14 15 16 17 18 19] [ 0  1  7 13]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 16 17] [ 9 15 18 19]\n",
            "[ 0  1  2  3  4  6  7  9 10 13 14 15 16 17 18 19] [ 5  8 11 12]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "IDX=[x for x in range(10)]\n",
        "IDY=[x for x in range(10)]\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  print(train_index, val_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOtctupmQ1Ac"
      },
      "outputs": [],
      "source": [
        "for i,x in enumerate(train_index):\n",
        "  size=metadat[x][1]\n",
        "  ri=metadat[x][2]\n",
        "  if i == 0:\n",
        "    X_train=X[ri:ri+size]\n",
        "    Y_train=Y[ri:ri+size]\n",
        "  else:\n",
        "    X_train=np.concatenate((X_train,X[ri:ri+size]),axis=0)\n",
        "    Y_train=np.concatenate((Y_train,Y[ri:ri+size]),axis=0)\n",
        "for i,x in enumerate(val_index):\n",
        "  size=metadat[x][1]\n",
        "  ri=metadat[x][2]\n",
        "  if i == 0:\n",
        "    X_test=X[ri:ri+size]\n",
        "    Y_test=Y[ri:ri+size]\n",
        "  else:\n",
        "    X_test=np.concatenate((X_test,X[ri:ri+size]),axis=0)\n",
        "    Y_test=np.concatenate((Y_test,Y[ri:ri+size]),axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSH Attention as keras multihead subclass"
      ],
      "metadata": {
        "id": "8n63iStbQ1Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.gen_math_ops import sqrt_eager_fallback\n",
        "import collections\n",
        "import math\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers.attention.multi_head_attention import MultiHeadAttention\n",
        "from keras.utils import tf_utils\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LSHAttention(MultiHeadAttention):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    self.n_buckets= kwargs.pop('n_buckets', 4)\n",
        "    super().__init__(*args, **kwargs)\n",
        "  def _build_from_signature(self, query, value, key=None):\n",
        "    with tf_utils.maybe_init_scope(self):\n",
        "      self._hash=tf.keras.layers.EinsumDense(\"bjhd,dc->bjhc\",output_shape=(None,None,self.n_buckets // 2))\n",
        "      self.lsh_proj=tf.random.normal\n",
        "    super()._build_from_signature(query, value, key=None)\n",
        "\n",
        "  def call(\n",
        "        self,\n",
        "        query,\n",
        "        value,\n",
        "        key=None,\n",
        "        attention_mask=None,\n",
        "        return_attention_scores=False,\n",
        "        training=None,\n",
        "        use_causal_mask=False,\n",
        "        ):\n",
        "        attention_mask = self._compute_attention_mask(\n",
        "            query,\n",
        "            value,\n",
        "            key=key,\n",
        "            attention_mask=attention_mask,\n",
        "            use_causal_mask=use_causal_mask,\n",
        "        )\n",
        "\n",
        "        if not self._built_from_signature:\n",
        "            self._build_from_signature(query=query, value=value, key=key)\n",
        "        if key is None:\n",
        "            key = value\n",
        "\n",
        "        query_is_ragged = isinstance(query, tf.RaggedTensor)\n",
        "        if query_is_ragged:\n",
        "            query_lengths = query.nested_row_lengths()\n",
        "            query = query.to_tensor()\n",
        "\n",
        "        key_is_ragged = isinstance(key, tf.RaggedTensor)\n",
        "        value_is_ragged = isinstance(value, tf.RaggedTensor)\n",
        "        if key_is_ragged and value_is_ragged:\n",
        "            # Ensure they have the same shape.\n",
        "            bounding_shape = tf.math.maximum(\n",
        "                key.bounding_shape(), value.bounding_shape()\n",
        "            )\n",
        "            key = key.to_tensor(shape=bounding_shape)\n",
        "            value = value.to_tensor(shape=bounding_shape)\n",
        "        elif key_is_ragged:\n",
        "            key = key.to_tensor(shape=tf.shape(value))\n",
        "        elif value_is_ragged:\n",
        "            value = value.to_tensor(shape=tf.shape(key))\n",
        "\n",
        "        #   N = `num_attention_heads`\n",
        "        #   H = `size_per_head`\n",
        "        # `query` = [B, T, N ,H]\n",
        "        query = self._query_dense(query)\n",
        "        # `key` = [B, S, N, H]\n",
        "        key = query\n",
        "        # `value` = [B, S, N, H]\n",
        "        value = self._value_dense(value)\n",
        "        for i in range(value.shape[2]):\n",
        "          auxAtt=tf.zeros_like(value[:,:,i,:])[:,:,None,:]\n",
        "          #here we make the rotation matrix, that will hash the vectors\n",
        "          random_rot=self.lsh_proj([value.shape[-1],self.n_buckets // 2])\n",
        "          #hash=self._hash(value)\n",
        "\n",
        "          #here we make the rotation using dot product, and making the buckets\n",
        "          hash=tf.matmul(value[:,:,i,:],random_rot)\n",
        "          hash=tf.concat([hash,-hash],axis=-1)\n",
        "\n",
        "          #here we make each token be clasified to a bucket\n",
        "          buckets=tf.math.argmax(hash,axis=-1)\n",
        "\n",
        "          #This is the index that will sort the inputs, and is made by sorting the buckets\n",
        "          index=tf.argsort(buckets,axis=-1)\n",
        "\n",
        "          #here we sort the main inputs usinf the index\n",
        "          sv=tf.gather(value[:,:,i,:],index,axis=1,batch_dims=-1)\n",
        "          sq=sk=tf.gather(query[:,:,i,:],index,axis=1,batch_dims=-1)\n",
        "          buckets=tf.gather(buckets,index,axis=1,batch_dims=-1)\n",
        "          #And chunk the inputs based on how many buckets we have\n",
        "          chunk_size=int(sv.shape[1]/self.n_buckets)\n",
        "\n",
        "          for j in range(self.n_buckets):\n",
        "            if j==0:\n",
        "              v=sv[:,j*chunk_size:(j+2)*chunk_size,:]\n",
        "              b=buckets[:,j*chunk_size:(j+2)*chunk_size]\n",
        "              q=sq[:,j*chunk_size:(j+2)*chunk_size,:]\n",
        "            elif j==self.n_buckets-1:\n",
        "              v=sv[:,(j-1)*chunk_size:(j+1)*chunk_size,:]\n",
        "              b=buckets[:,(j-1)*chunk_size:(j+1)*chunk_size]\n",
        "              q=sq[:,(j-1)*chunk_size:(j+1)*chunk_size,:]\n",
        "            else:\n",
        "              v=sv[:,(j-1)*chunk_size:(j+2)*chunk_size,:]\n",
        "              b=buckets[:,(j-1)*chunk_size:(j+2)*chunk_size]\n",
        "              q=sq[:,(j-1)*chunk_size:(j+2)*chunk_size,:]\n",
        "            mask = tf.cast(tf.equal(b, j), tf.float32)\n",
        "            mask = tf.expand_dims(mask, axis=-1)\n",
        "            mask = tf.repeat(mask, repeats=v.shape[-1], axis=-1)\n",
        "            v=v*mask\n",
        "            q=q*mask\n",
        "            attention_output, attention_scores = self._compute_attention(\n",
        "                q[:,:,None,:], q[:,:,None,:], v[:,:,None,:], attention_mask, training\n",
        "            )\n",
        "            if j==0 or j==1:\n",
        "              newatt=tf.pad(attention_output,[[0,0],[0,chunk_size*(self.n_buckets-2-j)],[0,0], [0,0]])\n",
        "              auxAtt=tf.add(auxAtt,newatt)\n",
        "              del newatt\n",
        "            elif j==self.n_buckets-1:\n",
        "              newatt=tf.pad(attention_output,[[0,0],[chunk_size*(j-1),0],[0,0], [0,0]])\n",
        "              auxAtt=tf.add(auxAtt,newatt)\n",
        "            else:\n",
        "              if j-1 != 0:\n",
        "                newatt=tf.pad(attention_output,[[0,0],[chunk_size*(j-1),0],[0,0], [0,0]])\n",
        "                if self.n_buckets-2-j !=0:\n",
        "                  newatt=tf.pad(newatt,[[0,0],[0,chunk_size*(self.n_buckets-2-j)],[0,0], [0,0]])\n",
        "              auxAtt=tf.add(auxAtt,newatt)\n",
        "          attention_output=auxAtt\n",
        "          if i==0:\n",
        "            att_o=attention_output\n",
        "          else:\n",
        "            att_o=tf.concat([att_o,attention_output],axis=2)\n",
        "        attention_output = att_o\n",
        "        attention_output = self._output_dense(attention_output)\n",
        "        if query_is_ragged:\n",
        "            attention_output = tf.RaggedTensor.from_tensor(\n",
        "                attention_output, lengths=query_lengths\n",
        "        )\n",
        "        if return_attention_scores:\n",
        "            return attention_output, attention_scores\n",
        "        return attention_output"
      ],
      "metadata": {
        "id": "HLShGV68UYoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yx0AAA4Q1An"
      },
      "source": [
        "##Patch wise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xaf84_vQ1Ao"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vunjNHQgQ1Ap"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
        "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
        "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
        "  return iou\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "  union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "  dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
        "  return dice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef_multilabel(y_true, y_pred, smooth=1):\n",
        "    dice=0\n",
        "    numLabels=y_true.shape[3]\n",
        "    for index in range(numLabels):\n",
        "      #None,128,128,1\n",
        "      y_t=tf.expand_dims(y_true[:,:,:,index],axis=3)\n",
        "      #None,128,128\n",
        "      y_p=tf.expand_dims(y_pred[:,:,:,index],axis=3)\n",
        "      dice += dice_coef(y_t, y_p)\n",
        "    return dice/numLabels # taking average"
      ],
      "metadata": {
        "id": "R9t8NpyfQ1Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_coef_multilabel(y_true, y_pred, smooth=1):\n",
        "    dice=0\n",
        "    numLabels=y_true.shape[3]\n",
        "    for index in range(numLabels):\n",
        "      y_t=tf.expand_dims(y_true[:,:,:,index],axis=3)\n",
        "      y_p=tf.expand_dims(y_pred[:,:,:,index],axis=3)\n",
        "      dice += iou_coef(y_t, y_p)\n",
        "    return dice/numLabels # taking average"
      ],
      "metadata": {
        "id": "KdPD-DggQ1Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOPXtopgQ1Ar"
      },
      "outputs": [],
      "source": [
        "def conv_block(X,f,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (3, 3), kernel_initializer='he_normal', padding='same', groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  s = tf.keras.layers.Conv2D(f[1], (1, 1), kernel_initializer='he_normal', padding='same')(X)\n",
        "  s = tf.keras.layers.BatchNormalization(axis=3)(s)\n",
        "  c = tf.keras.layers.Add()([c,s])\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return c,c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "CxpUTRx1Q1Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten(M):\n",
        "  s1=M.shape[1]\n",
        "  s2=M.shape[2]\n",
        "  s3=M.shape[3]\n",
        "  flat=s1*s2\n",
        "  M= tf.reshape(M,[-1,flat,s3])\n",
        "  return M,s1,s2,s3"
      ],
      "metadata": {
        "id": "kieiQzMpQ1As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten_LSH(M,N,nheads,dimk,k=128):\n",
        "  M,s1,s2,s3= Flatten(M)\n",
        "  N,_,_,_= Flatten(N)\n",
        "  pm=LSHAttention(num_heads=nheads,key_dim=dimk,dropout=0.2,n_buckets=k)(M,M)\n",
        "  pm=tf.reshape(pm,[-1,s1,s2,s3])\n",
        "  return pm"
      ],
      "metadata": {
        "id": "cUqeL_qXQ1Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9CP-mP6Q1Av"
      },
      "outputs": [],
      "source": [
        "def vit(X,Y,n_heads=16,psize=16,k=256,dim=\"4D\"):\n",
        "  npatch=int(X.shape[1]/psize)\n",
        "  psizey=int(psize/2)\n",
        "  kdim=int(X.shape[3]/n_heads)\n",
        "  Y=tf.keras.layers.Dense(X.shape[3])(Y)\n",
        "  if npatch==0:\n",
        "    pm=Flatten_LSH(X,Y,n_heads,kdim,k)\n",
        "    return pm\n",
        "  for i in range(npatch):\n",
        "    st=i*psize\n",
        "    sty=i*psizey\n",
        "    end=st+psize\n",
        "    endy=sty+psizey\n",
        "    for j in range(npatch):\n",
        "      st2=j*psize\n",
        "      end2=st2+psize\n",
        "      sty2=j*psizey\n",
        "      endy2=sty2+psizey\n",
        "      patch= X[:,st:end,st2:end2,:]\n",
        "      patch2= Y[:,sty:endy,sty2:endy2,:]\n",
        "      pm=Flatten_LSH(patch,patch2,n_heads,kdim,k)\n",
        "      if j==0:\n",
        "        A=pm\n",
        "      else:\n",
        "        A=tf.concat([A,pm],2)\n",
        "    if i==0:\n",
        "      V=A\n",
        "    else:\n",
        "      V=tf.concat([V,A],1)\n",
        "  return V\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJjJIH_NQ1Aw"
      },
      "source": [
        "### Vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "io9DYs5qQ1Ax"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "  nheads=8\n",
        "  sizep=16\n",
        "  gr=4\n",
        "  #Build the model\n",
        "  inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "  s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "  #s= inputs\n",
        "  #Contraction path\n",
        "  c1,z1 = conv_block(s,[16,16],group=1)\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "\n",
        "  c2,z2 = conv_block(p1,[32,32],group=gr)\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "  c3,z3 = conv_block(p2,[64,64],0.2,group=gr)\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "  c4,z4 = conv_block(p3,[128,128],0.2,group=gr)\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "  c5,z5 = conv_block(p4,[256,256],0.3,group=gr)\n",
        "\n",
        "  #Expansive path\n",
        "  m1= vit(z4,z5,nheads,sizep,k=4)\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "  u6 = tf.keras.layers.concatenate([u6, m1])\n",
        "  c6,z6 = conv_block(u6,[128,128],0.2,group=gr)\n",
        "\n",
        "  m2= vit(z3,z6,nheads,sizep,k=4)\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "  u7 = tf.keras.layers.concatenate([u7, m2])\n",
        "  c7,z7 = conv_block(u7,[64,64],0.2,group=gr)\n",
        "\n",
        "  m3= vit(z2,z7,nheads,sizep,k=4)\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "  u8 = tf.keras.layers.concatenate([u8, m3])\n",
        "  c8,z8 = conv_block(u8,[32,32],group=gr)\n",
        "\n",
        "  m4= vit(z1,z8,nheads,sizep,k=4)\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "  u9 = tf.keras.layers.concatenate([u9, m4], axis=3)\n",
        "  c9,_ = conv_block(u9,[16,16],group=gr)\n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(4, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',iou_coef_multilabel,dice_coef_multilabel])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSH without Patches"
      ],
      "metadata": {
        "id": "zYp5B-SHQ1Ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Flatten(M):\n",
        "  s1=M.shape[1]\n",
        "  s2=M.shape[2]\n",
        "  s3=M.shape[3]\n",
        "  flat=s1*s2\n",
        "  M= tf.reshape(M,[-1,flat,s3])\n",
        "  return M,s1,s2,s3"
      ],
      "metadata": {
        "id": "NEV3XYGsQ1Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LSH_lay(M,nheads,k=128,nbuckets=4):\n",
        "  M,s1,s2,s3= Flatten(M)\n",
        "  dimk=int(M.shape[2]/nheads)\n",
        "  pm=LSHAttention(num_heads=nheads,key_dim=dimk,dropout=0.2,n_buckets=nbuckets)(M,M)\n",
        "  pm=tf.reshape(pm,[-1,s1,s2,s3])\n",
        "  return pm"
      ],
      "metadata": {
        "id": "8j5m5cpJQ1Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbrt0diMQ1Az"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "  nheads=4\n",
        "  sizep=32\n",
        "  gr=4\n",
        "\n",
        "  #Build the model\n",
        "  inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "  s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "  #s= inputs\n",
        "  #Contraction path\n",
        "  c1,z1 = conv_block(s,[16,16],group=1)\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "\n",
        "  c2,z2 = conv_block(p1,[32,32],group=gr)\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "  c3,z3 = conv_block(p2,[64,64],0.2,group=gr)\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "  c4,z4 = conv_block(p3,[128,128],0.2,group=gr)\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "  c5,z5 = conv_block(p4,[256,256],0.3,group=gr)\n",
        "\n",
        "  #Expansive path\n",
        "\n",
        "  m1= LSH_lay(z4,nheads)\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "  u6 = tf.keras.layers.concatenate([u6, m1])\n",
        "  c6,z6 = conv_block(u6,[128,128],0.2,group=gr)\n",
        "\n",
        "  m2= LSH_lay(z3,nheads,nbuckets=8)\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "  u7 = tf.keras.layers.concatenate([u7, m2])\n",
        "  c7,z7 = conv_block(u7,[64,64],0.2,group=gr)\n",
        "\n",
        "  m3= LSH_lay(z2,nheads,nbuckets=8)\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "  u8 = tf.keras.layers.concatenate([u8, m3])\n",
        "  c8,z8 = conv_block(u8,[32,32],group=gr)\n",
        "\n",
        "  m4= LSH_lay(z1,nheads,nbuckets=32)\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "  u9 = tf.keras.layers.concatenate([u9, m4], axis=3)\n",
        "  c9,_ = conv_block(u9,[16,16],group=gr)\n",
        "\n",
        "  outputs = tf.keras.layers.Conv2D(4, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',iou_coef_multilabel,dice_coef_multilabel])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test"
      ],
      "metadata": {
        "id": "p_hLJw2AQ1A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=create_model()\n",
        "model.fit(X_train,Y_train,batch_size=16,epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf1a1a9-1541-4492-9418-982d508b61d1",
        "id": "kW401R9DQ1A0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for split version, time for execution 42 m\n",
        "\n",
        "patched version time for execution 34 m"
      ],
      "metadata": {
        "id": "zpNebdi6Q1A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores= model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f'Score for fold {0}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "389af71a-0957-4ef5-c58a-4e70dec07b54",
        "id": "Xd6jmeLUQ1A1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 0: loss of 0.036873139441013336; accuracy of 98.70224595069885% iou_coef_multilabel of 68.26137900352478% dice_coef_multilabel of 72.85516262054443%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Patch size=32 k=32:\n",
        "\n",
        "Score for fold 0: loss of 0.02660856954753399; accuracy of 99.21053647994995% iou_coef_multilabel of 73.97453188896179% dice_coef_multilabel of 77.59955525398254%\n",
        "\n",
        "No Patch k=128:\n",
        "\n",
        "Score for fold 0: loss of 0.03675605729222298; accuracy of 98.8860547542572% iou_coef_multilabel of 69.78949904441833% dice_coef_multilabel of 74.2724359035492%\n",
        "\n",
        "Patch size=32 k=256:\n",
        "Score for fold 0: loss of 0.11757280677556992; accuracy of 96.79576754570007% iou_coef_multilabel of 71.6090202331543% dice_coef_multilabel of 79.81376647949219%\n"
      ],
      "metadata": {
        "id": "us07qkOEQ1A1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP27QaORQ1A1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4k5pg03Q1A1"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Patch test"
      ],
      "metadata": {
        "id": "9Na_9K-dQ1A2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=32"
      ],
      "metadata": {
        "id": "A3DxP9O2Q1A2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0ee790-e664-4eee-c81d-e35012365ff1",
        "id": "ZKoAAmH6Q1A2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.029409149661660194; accuracy of 98.91234040260315% iou_coef_multilabel of 70.78478932380676% dice_coef_multilabel of 75.16862750053406%\n",
            "Score for fold 2: loss of 0.042917650192976; accuracy of 98.51773381233215% iou_coef_multilabel of 70.23463249206543% dice_coef_multilabel of 75.7128119468689%\n",
            "Score for fold 3: loss of 0.04444853588938713; accuracy of 98.51000308990479% iou_coef_multilabel of 67.47883558273315% dice_coef_multilabel of 72.66407012939453%\n",
            "Score for fold 4: loss of 0.10042478889226913; accuracy of 96.02788090705872% iou_coef_multilabel of 55.91818690299988% dice_coef_multilabel of 63.355553150177%\n",
            "Score for fold 5: loss of 0.03272783383727074; accuracy of 98.82147312164307% iou_coef_multilabel of 69.75324749946594% dice_coef_multilabel of 74.68957304954529%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c504f0d-d2d5-4752-d341-f7a58c773d5c",
        "id": "Fk5KCCB_Q1A3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.025224272161722183; accuracy of 99.0780770778656% iou_coef_multilabel of 75.7142961025238% dice_coef_multilabel of 79.58106994628906%\n",
            "Score for fold 2: loss of 0.04713413491845131; accuracy of 98.5433280467987% iou_coef_multilabel of 74.99583959579468% dice_coef_multilabel of 80.19270896911621%\n",
            "Score for fold 3: loss of 0.04239453375339508; accuracy of 98.56003522872925% iou_coef_multilabel of 71.22631072998047% dice_coef_multilabel of 76.35141015052795%\n",
            "Score for fold 4: loss of 0.04546702280640602; accuracy of 98.31485748291016% iou_coef_multilabel of 70.64926028251648% dice_coef_multilabel of 77.11712121963501%\n",
            "Score for fold 5: loss of 0.032865818589925766; accuracy of 98.83249998092651% iou_coef_multilabel of 71.10702991485596% dice_coef_multilabel of 75.85053443908691%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "k=256"
      ],
      "metadata": {
        "id": "XZF0W1TwQ1A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328b22fc-64d7-4970-87da-2b9867e7d106",
        "id": "HaYsCNF-Q1A4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.016601325944066048; accuracy of 99.49246644973755% iou_coef_multilabel of 80.1440417766571% dice_coef_multilabel of 82.72783160209656%\n",
            "Score for fold 2: loss of 0.02792888507246971; accuracy of 99.11463856697083% iou_coef_multilabel of 77.49691009521484% dice_coef_multilabel of 81.86010122299194%\n",
            "Score for fold 3: loss of 0.033090461045503616; accuracy of 99.0357756614685% iou_coef_multilabel of 75.54389238357544% dice_coef_multilabel of 79.85571622848511%\n",
            "Score for fold 4: loss of 0.02735254541039467; accuracy of 99.02375340461731% iou_coef_multilabel of 75.38833618164062% dice_coef_multilabel of 80.59991002082825%\n",
            "Score for fold 5: loss of 0.02401789091527462; accuracy of 99.26612973213196% iou_coef_multilabel of 76.66497826576233% dice_coef_multilabel of 80.13312816619873%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "ee163453-4cde-4531-bfef-16e685603493",
        "id": "9IUxVtqNQ1A4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.01717947982251644; accuracy of 99.4581937789917% iou_coef_multilabel of 79.65168952941895% dice_coef_multilabel of 82.61964917182922%\n",
            "Score for fold 2: loss of 0.03299105167388916; accuracy of 99.06346797943115% iou_coef_multilabel of 78.3797025680542% dice_coef_multilabel of 82.73652791976929%\n",
            "Score for fold 3: loss of 0.034237224608659744; accuracy of 99.15516972541809% iou_coef_multilabel of 78.44327688217163% dice_coef_multilabel of 82.67260193824768%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-09b93a07fbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####No Patch test"
      ],
      "metadata": {
        "id": "JVmR6H3NQ1A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60653fbf-aeeb-451c-dcdc-c37c1b1a6ccf",
        "id": "8aeikf9-Q1A5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.02731938473880291; accuracy of 99.00254607200623% iou_coef_multilabel of 71.55993580818176% dice_coef_multilabel of 75.51640272140503%\n",
            "Score for fold 2: loss of 0.04416176304221153; accuracy of 98.46460819244385% iou_coef_multilabel of 70.76845169067383% dice_coef_multilabel of 76.32638216018677%\n",
            "Score for fold 3: loss of 0.04237723350524902; accuracy of 98.45744967460632% iou_coef_multilabel of 67.4326241016388% dice_coef_multilabel of 72.71857857704163%\n",
            "Score for fold 4: loss of 0.04793655872344971; accuracy of 98.23458194732666% iou_coef_multilabel of 68.04465651512146% dice_coef_multilabel of 74.47894811630249%\n",
            "Score for fold 5: loss of 0.0348425917327404; accuracy of 98.7302839756012% iou_coef_multilabel of 65.84467887878418% dice_coef_multilabel of 70.64203023910522%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(metadat,metadat):\n",
        "  model = create_model()\n",
        "  for i,x in enumerate(train_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      X_fold=X[ri:ri+size]\n",
        "      Y_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      X_fold=np.concatenate((X_fold,X[ri:ri+size]),axis=0)\n",
        "      Y_fold=np.concatenate((Y_fold,Y[ri:ri+size]),axis=0)\n",
        "  for i,x in enumerate(val_index):\n",
        "    size=metadat[x][1]\n",
        "    ri=metadat[x][2]\n",
        "    if i == 0:\n",
        "      Xtest_fold=X[ri:ri+size]\n",
        "      Ytest_fold=Y[ri:ri+size]\n",
        "    else:\n",
        "      Xtest_fold=np.concatenate((Xtest_fold,X[ri:ri+size]),axis=0)\n",
        "      Ytest_fold=np.concatenate((Ytest_fold,Y[ri:ri+size]),axis=0)\n",
        "\n",
        "\n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,verbose=0)\n",
        "\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}% {model.metrics_names[3]} of {scores[3]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "9c7dd46a-f675-468d-8126-6fabf5e3bbbc",
        "id": "XoVQfd5IQ1A5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-09b93a07fbe5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}